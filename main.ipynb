{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from features.dblp import run as dblp_extract\n",
    "from features.delicious import run as delicious_extract\n",
    "from features.movielens import run as movielens_extract\n",
    "from features.autoencoder import train_encoder\n",
    "from models.NpGlm import NpGlm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'dblp'\n",
    "delta = 1\n",
    "observation_window = 6\n",
    "n_snapshots = 6\n",
    "censoring_ratio = 0.5\n",
    "epochs = 1000\n",
    "latent_factor = 2\n",
    "max_iter = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:57:28: generating papers ...\n",
      "20:57:36: parsing dataset ...\n",
      "20:57:36: generating samples ...\n",
      "20:57:37: extracting ...\n",
      "20:57:38: parsing dataset ...\n",
      "20:57:38: extracting ...\n",
      "20:57:39: parsing dataset ...\n",
      "20:57:39: extracting ...\n",
      "20:57:40: parsing dataset ...\n",
      "20:57:40: extracting ...\n",
      "20:57:40: parsing dataset ...\n",
      "20:57:40: extracting ...\n",
      "20:57:41: parsing dataset ...\n",
      "20:57:41: extracting ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3410, 6, 19)\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = {\n",
    "    'dblp': dblp_extract,\n",
    "    'delicious': delicious_extract,\n",
    "    'movielens': movielens_extract,\n",
    "}[dataset]\n",
    "\n",
    "X, Y, T = feature_extractor(\n",
    "    delta=delta,\n",
    "    observation_window=observation_window,\n",
    "    n_snapshots=n_snapshots,\n",
    "    censoring_ratio=censoring_ratio,\n",
    ")\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, T_train, T_test = train_test_split(X, Y, T, test_size=0.2, stratify=Y, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 1s 133ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9931e-04\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9791e-04\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9628e-04\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9467e-04\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9346e-04\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9192e-04\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.9040e-04\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8911e-04\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.8769e-04\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8651e-04\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8560e-04\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8406e-04\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8271e-04\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8126e-04\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.8014e-04\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7914e-04\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7793e-04\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7687e-04\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7573e-04\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7449e-04\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7368e-04\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7258e-04\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7161e-04\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.7063e-04\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6963e-04\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6854e-04\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6774e-04\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6687e-04\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6562e-04\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6509e-04\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6403e-04\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6304e-04\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6244e-04\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6151e-04\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.6058e-04\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5971e-04\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5885e-04\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5792e-04\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5693e-04\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5640e-04\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.5529e-04\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 9.5447e-04\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5390e-04\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5294e-04\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5222e-04\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5153e-04\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.5071e-04\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.4999e-04\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.4936e-04\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.4841e-04\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.4754e-04\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0011 - val_loss: 9.4715e-04\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4634e-04\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4551e-04\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4475e-04\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4364e-04\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4288e-04\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4188e-04\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4122e-04\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4058e-04\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.4006e-04\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3935e-04\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3851e-04\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3766e-04\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3700e-04\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3621e-04\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3559e-04\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3492e-04\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3440e-04\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3375e-04\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.3316e-04\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3214e-04\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3155e-04\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.3057e-04\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2978e-04\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2902e-04\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2843e-04\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2756e-04\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2718e-04\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2667e-04\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2568e-04\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2509e-04\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2408e-04\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.2331e-04\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2252e-04\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2179e-04\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2090e-04\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.2013e-04\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.1926e-04\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.1878e-04\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.1785e-04\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.1699e-04\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.1599e-04\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 9.1538e-04\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0010 - val_loss: 9.1488e-04\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9912e-04 - val_loss: 9.1455e-04\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9787e-04 - val_loss: 9.1347e-04\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9645e-04 - val_loss: 9.1265e-04\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9505e-04 - val_loss: 9.1186e-04\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9353e-04 - val_loss: 9.1129e-04\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9222e-04 - val_loss: 9.1019e-04\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.9058e-04 - val_loss: 9.0906e-04\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.8903e-04 - val_loss: 9.0836e-04\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.8761e-04 - val_loss: 9.0715e-04\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.8619e-04 - val_loss: 9.0620e-04\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.8459e-04 - val_loss: 9.0531e-04\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.8296e-04 - val_loss: 9.0423e-04\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.8154e-04 - val_loss: 9.0309e-04\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.8009e-04 - val_loss: 9.0289e-04\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.7893e-04 - val_loss: 9.0104e-04\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.7717e-04 - val_loss: 9.0030e-04\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.7559e-04 - val_loss: 8.9991e-04\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.7421e-04 - val_loss: 8.9854e-04\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.7282e-04 - val_loss: 8.9727e-04\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.7093e-04 - val_loss: 8.9597e-04\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.6931e-04 - val_loss: 8.9516e-04\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.6765e-04 - val_loss: 8.9417e-04\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.6614e-04 - val_loss: 8.9301e-04\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.6428e-04 - val_loss: 8.9144e-04\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.6255e-04 - val_loss: 8.9061e-04\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.6089e-04 - val_loss: 8.8942e-04\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.5928e-04 - val_loss: 8.8845e-04\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.5770e-04 - val_loss: 8.8757e-04\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.5616e-04 - val_loss: 8.8645e-04\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.5447e-04 - val_loss: 8.8560e-04\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.5299e-04 - val_loss: 8.8403e-04\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.5130e-04 - val_loss: 8.8331e-04\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4979e-04 - val_loss: 8.8215e-04\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4832e-04 - val_loss: 8.8082e-04\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4650e-04 - val_loss: 8.8054e-04\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4543e-04 - val_loss: 8.7876e-04\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4360e-04 - val_loss: 8.7735e-04\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4182e-04 - val_loss: 8.7622e-04\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.4035e-04 - val_loss: 8.7558e-04\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3910e-04 - val_loss: 8.7414e-04\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3750e-04 - val_loss: 8.7360e-04\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3631e-04 - val_loss: 8.7258e-04\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3488e-04 - val_loss: 8.7098e-04\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3309e-04 - val_loss: 8.6993e-04\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3146e-04 - val_loss: 8.6888e-04\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.3000e-04 - val_loss: 8.6754e-04\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.2841e-04 - val_loss: 8.6675e-04\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.2711e-04 - val_loss: 8.6640e-04\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.2611e-04 - val_loss: 8.6517e-04\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.2495e-04 - val_loss: 8.6467e-04\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.2363e-04 - val_loss: 8.6308e-04\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.2196e-04 - val_loss: 8.6126e-04\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.2058e-04 - val_loss: 8.6016e-04\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1938e-04 - val_loss: 8.5875e-04\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1780e-04 - val_loss: 8.5870e-04\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1655e-04 - val_loss: 8.5799e-04\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1534e-04 - val_loss: 8.5633e-04\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1372e-04 - val_loss: 8.5504e-04\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1269e-04 - val_loss: 8.5361e-04\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1127e-04 - val_loss: 8.5410e-04\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.1089e-04 - val_loss: 8.5234e-04\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0867e-04 - val_loss: 8.5124e-04\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0778e-04 - val_loss: 8.5183e-04\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0733e-04 - val_loss: 8.5066e-04\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0594e-04 - val_loss: 8.5061e-04\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0590e-04 - val_loss: 8.4941e-04\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0380e-04 - val_loss: 8.4773e-04\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0247e-04 - val_loss: 8.4769e-04\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0168e-04 - val_loss: 8.4800e-04\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0099e-04 - val_loss: 8.4757e-04\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 9.0108e-04 - val_loss: 8.4566e-04\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.9914e-04 - val_loss: 8.4670e-04\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9802e-04 - val_loss: 8.4791e-04\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9984e-04 - val_loss: 8.4375e-04\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9602e-04 - val_loss: 8.4210e-04\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.9444e-04 - val_loss: 8.4125e-04\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9338e-04 - val_loss: 8.4117e-04\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9268e-04 - val_loss: 8.4097e-04\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9179e-04 - val_loss: 8.4123e-04\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.9093e-04 - val_loss: 8.3986e-04\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8977e-04 - val_loss: 8.3902e-04\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8850e-04 - val_loss: 8.3815e-04\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8764e-04 - val_loss: 8.3725e-04\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.8664e-04 - val_loss: 8.3759e-04\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8622e-04 - val_loss: 8.3651e-04\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8489e-04 - val_loss: 8.3588e-04\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8429e-04 - val_loss: 8.3513e-04\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8323e-04 - val_loss: 8.3519e-04\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8296e-04 - val_loss: 8.3372e-04\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8121e-04 - val_loss: 8.3363e-04\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8060e-04 - val_loss: 8.3275e-04\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7965e-04 - val_loss: 8.3341e-04\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7998e-04 - val_loss: 8.3307e-04\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7822e-04 - val_loss: 8.3496e-04\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.8060e-04 - val_loss: 8.3218e-04\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7730e-04 - val_loss: 8.3682e-04\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7913e-04 - val_loss: 8.3526e-04\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7920e-04 - val_loss: 8.3286e-04\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7655e-04 - val_loss: 8.3260e-04\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7472e-04 - val_loss: 8.3076e-04\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7336e-04 - val_loss: 8.2954e-04\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7226e-04 - val_loss: 8.2885e-04\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7127e-04 - val_loss: 8.2841e-04\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.7052e-04 - val_loss: 8.2798e-04\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6972e-04 - val_loss: 8.2740e-04\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6920e-04 - val_loss: 8.2728e-04\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6829e-04 - val_loss: 8.2689e-04\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6749e-04 - val_loss: 8.2679e-04\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6682e-04 - val_loss: 8.2654e-04\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6668e-04 - val_loss: 8.2612e-04\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.6559e-04 - val_loss: 8.2625e-04\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6454e-04 - val_loss: 8.2558e-04\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6415e-04 - val_loss: 8.2516e-04\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6325e-04 - val_loss: 8.2549e-04\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6264e-04 - val_loss: 8.2506e-04\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6255e-04 - val_loss: 8.2364e-04\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6134e-04 - val_loss: 8.2380e-04\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.6075e-04 - val_loss: 8.2353e-04\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5987e-04 - val_loss: 8.2344e-04\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5913e-04 - val_loss: 8.2229e-04\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5798e-04 - val_loss: 8.2187e-04\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 8.5822e-04 - val_loss: 8.2384e-04\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5955e-04 - val_loss: 8.2166e-04\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5672e-04 - val_loss: 8.2494e-04\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5830e-04 - val_loss: 8.2168e-04\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5552e-04 - val_loss: 8.2086e-04\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5525e-04 - val_loss: 8.2282e-04\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5499e-04 - val_loss: 8.2085e-04\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.5404e-04 - val_loss: 8.2089e-04\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5505e-04 - val_loss: 8.1984e-04\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5260e-04 - val_loss: 8.2139e-04\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5208e-04 - val_loss: 8.2018e-04\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5133e-04 - val_loss: 8.2006e-04\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5139e-04 - val_loss: 8.1970e-04\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5222e-04 - val_loss: 8.1761e-04\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5064e-04 - val_loss: 8.1789e-04\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.5031e-04 - val_loss: 8.1769e-04\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4879e-04 - val_loss: 8.1701e-04\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4899e-04 - val_loss: 8.1703e-04\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4904e-04 - val_loss: 8.1659e-04\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4773e-04 - val_loss: 8.1675e-04\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4716e-04 - val_loss: 8.1765e-04\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4665e-04 - val_loss: 8.1753e-04\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4496e-04 - val_loss: 8.1731e-04\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4421e-04 - val_loss: 8.1561e-04\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4271e-04 - val_loss: 8.1454e-04\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4164e-04 - val_loss: 8.1426e-04\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4095e-04 - val_loss: 8.1481e-04\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.4059e-04 - val_loss: 8.1454e-04\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3984e-04 - val_loss: 8.1441e-04\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3934e-04 - val_loss: 8.1401e-04\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3872e-04 - val_loss: 8.1293e-04\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3786e-04 - val_loss: 8.1227e-04\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3713e-04 - val_loss: 8.1210e-04\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3679e-04 - val_loss: 8.1207e-04\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3644e-04 - val_loss: 8.1200e-04\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3571e-04 - val_loss: 8.1165e-04\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3485e-04 - val_loss: 8.1170e-04\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3463e-04 - val_loss: 8.1220e-04\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3436e-04 - val_loss: 8.1162e-04\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3333e-04 - val_loss: 8.1143e-04\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3350e-04 - val_loss: 8.1077e-04\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3216e-04 - val_loss: 8.1028e-04\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3149e-04 - val_loss: 8.1031e-04\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3129e-04 - val_loss: 8.1058e-04\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.3067e-04 - val_loss: 8.0924e-04\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2961e-04 - val_loss: 8.1011e-04\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2936e-04 - val_loss: 8.0950e-04\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2851e-04 - val_loss: 8.0948e-04\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2811e-04 - val_loss: 8.0917e-04\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2767e-04 - val_loss: 8.0985e-04\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2815e-04 - val_loss: 8.0867e-04\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2642e-04 - val_loss: 8.0821e-04\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2611e-04 - val_loss: 8.0750e-04\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2531e-04 - val_loss: 8.0714e-04\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2463e-04 - val_loss: 8.0714e-04\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2441e-04 - val_loss: 8.0741e-04\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2360e-04 - val_loss: 8.0667e-04\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2322e-04 - val_loss: 8.0880e-04\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2387e-04 - val_loss: 8.0675e-04\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2276e-04 - val_loss: 8.0581e-04\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2146e-04 - val_loss: 8.0595e-04\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2118e-04 - val_loss: 8.0622e-04\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2085e-04 - val_loss: 8.0705e-04\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2164e-04 - val_loss: 8.0540e-04\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1966e-04 - val_loss: 8.0629e-04\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1909e-04 - val_loss: 8.0516e-04\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1881e-04 - val_loss: 8.0475e-04\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1781e-04 - val_loss: 8.0449e-04\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1783e-04 - val_loss: 8.0524e-04\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1823e-04 - val_loss: 8.0991e-04\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.2025e-04 - val_loss: 8.0593e-04\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1759e-04 - val_loss: 8.0352e-04\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.1521e-04 - val_loss: 8.0445e-04\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.1533e-04 - val_loss: 8.0358e-04\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1419e-04 - val_loss: 8.0277e-04\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1347e-04 - val_loss: 8.0197e-04\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1318e-04 - val_loss: 8.0250e-04\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1234e-04 - val_loss: 8.0265e-04\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1208e-04 - val_loss: 8.0202e-04\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1104e-04 - val_loss: 8.0156e-04\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1096e-04 - val_loss: 8.0335e-04\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1295e-04 - val_loss: 8.0406e-04\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1491e-04 - val_loss: 8.0262e-04\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1315e-04 - val_loss: 8.0272e-04\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1109e-04 - val_loss: 8.0118e-04\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1004e-04 - val_loss: 8.0242e-04\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0954e-04 - val_loss: 8.0153e-04\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0851e-04 - val_loss: 8.0170e-04\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1171e-04 - val_loss: 8.0476e-04\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1286e-04 - val_loss: 8.0353e-04\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.1170e-04 - val_loss: 8.0160e-04\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0750e-04 - val_loss: 8.0535e-04\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.1026e-04 - val_loss: 8.0181e-04\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0711e-04 - val_loss: 8.0195e-04\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0601e-04 - val_loss: 8.0083e-04\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0564e-04 - val_loss: 8.0219e-04\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0529e-04 - val_loss: 8.0024e-04\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0393e-04 - val_loss: 8.0086e-04\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0382e-04 - val_loss: 8.0111e-04\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0378e-04 - val_loss: 7.9979e-04\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0289e-04 - val_loss: 7.9928e-04\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0276e-04 - val_loss: 8.0084e-04\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0253e-04 - val_loss: 8.0063e-04\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0351e-04 - val_loss: 8.0212e-04\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0543e-04 - val_loss: 8.0891e-04\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0734e-04 - val_loss: 8.0132e-04\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0263e-04 - val_loss: 8.0084e-04\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8.0076e-04 - val_loss: 7.9971e-04\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9974e-04 - val_loss: 7.9612e-04\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9852e-04 - val_loss: 7.9880e-04\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9836e-04 - val_loss: 7.9678e-04\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9712e-04 - val_loss: 7.9688e-04\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9662e-04 - val_loss: 7.9677e-04\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9688e-04 - val_loss: 7.9631e-04\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9620e-04 - val_loss: 7.9601e-04\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9590e-04 - val_loss: 7.9647e-04\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9514e-04 - val_loss: 7.9533e-04\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9434e-04 - val_loss: 7.9566e-04\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9367e-04 - val_loss: 7.9438e-04\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9307e-04 - val_loss: 7.9411e-04\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9268e-04 - val_loss: 7.9461e-04\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9211e-04 - val_loss: 7.9402e-04\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9158e-04 - val_loss: 7.9345e-04\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9099e-04 - val_loss: 7.9313e-04\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9062e-04 - val_loss: 7.9295e-04\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.9026e-04 - val_loss: 7.9342e-04\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8989e-04 - val_loss: 7.9338e-04\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8956e-04 - val_loss: 7.9241e-04\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8910e-04 - val_loss: 7.9206e-04\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8882e-04 - val_loss: 7.9210e-04\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8835e-04 - val_loss: 7.9241e-04\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8796e-04 - val_loss: 7.9221e-04\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8739e-04 - val_loss: 7.9133e-04\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8686e-04 - val_loss: 7.9097e-04\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8634e-04 - val_loss: 7.9091e-04\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8597e-04 - val_loss: 7.9134e-04\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8605e-04 - val_loss: 7.9081e-04\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8557e-04 - val_loss: 7.9032e-04\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8548e-04 - val_loss: 7.8995e-04\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8479e-04 - val_loss: 7.8993e-04\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8481e-04 - val_loss: 7.9166e-04\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8432e-04 - val_loss: 7.9081e-04\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8360e-04 - val_loss: 7.9084e-04\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8324e-04 - val_loss: 7.8896e-04\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8269e-04 - val_loss: 7.8941e-04\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8208e-04 - val_loss: 7.8950e-04\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8172e-04 - val_loss: 7.8939e-04\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8128e-04 - val_loss: 7.8969e-04\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8173e-04 - val_loss: 7.8869e-04\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8146e-04 - val_loss: 7.9139e-04\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8161e-04 - val_loss: 7.9005e-04\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.8059e-04 - val_loss: 7.8848e-04\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7948e-04 - val_loss: 7.8785e-04\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7890e-04 - val_loss: 7.8825e-04\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.7887e-04 - val_loss: 7.8853e-04\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7840e-04 - val_loss: 7.8862e-04\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.7803e-04 - val_loss: 7.8969e-04\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7867e-04 - val_loss: 7.8762e-04\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7713e-04 - val_loss: 7.8756e-04\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7667e-04 - val_loss: 7.8707e-04\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7605e-04 - val_loss: 7.8773e-04\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.7654e-04 - val_loss: 7.8766e-04\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7610e-04 - val_loss: 7.8705e-04\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7508e-04 - val_loss: 7.8626e-04\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7479e-04 - val_loss: 7.8863e-04\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7612e-04 - val_loss: 7.8638e-04\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7392e-04 - val_loss: 7.8782e-04\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7459e-04 - val_loss: 7.8593e-04\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7397e-04 - val_loss: 7.8582e-04\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7345e-04 - val_loss: 7.8736e-04\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7292e-04 - val_loss: 7.8616e-04\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7305e-04 - val_loss: 7.8530e-04\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7244e-04 - val_loss: 7.8767e-04\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7315e-04 - val_loss: 7.8476e-04\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7214e-04 - val_loss: 7.8506e-04\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7110e-04 - val_loss: 7.8554e-04\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7093e-04 - val_loss: 7.8547e-04\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7038e-04 - val_loss: 7.8526e-04\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.7010e-04 - val_loss: 7.8477e-04\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6939e-04 - val_loss: 7.8531e-04\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6886e-04 - val_loss: 7.8682e-04\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6898e-04 - val_loss: 7.8518e-04\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6878e-04 - val_loss: 7.8563e-04\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6879e-04 - val_loss: 7.8637e-04\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6997e-04 - val_loss: 7.8441e-04\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.6774e-04 - val_loss: 7.8371e-04\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6692e-04 - val_loss: 7.8309e-04\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6648e-04 - val_loss: 7.8552e-04\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6735e-04 - val_loss: 7.8440e-04\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6791e-04 - val_loss: 7.8418e-04\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6595e-04 - val_loss: 7.8303e-04\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6515e-04 - val_loss: 7.8383e-04\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6524e-04 - val_loss: 7.8164e-04\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6404e-04 - val_loss: 7.8189e-04\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6341e-04 - val_loss: 7.8180e-04\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6323e-04 - val_loss: 7.8125e-04\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6323e-04 - val_loss: 7.8222e-04\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6252e-04 - val_loss: 7.8044e-04\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6209e-04 - val_loss: 7.8181e-04\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6193e-04 - val_loss: 7.8005e-04\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6187e-04 - val_loss: 7.8107e-04\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6211e-04 - val_loss: 7.8430e-04\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6276e-04 - val_loss: 7.8633e-04\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6469e-04 - val_loss: 7.8041e-04\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6262e-04 - val_loss: 7.8040e-04\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6041e-04 - val_loss: 7.8214e-04\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6054e-04 - val_loss: 7.8074e-04\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.6036e-04 - val_loss: 7.7988e-04\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5896e-04 - val_loss: 7.8062e-04\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5842e-04 - val_loss: 7.7980e-04\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5809e-04 - val_loss: 7.7963e-04\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5792e-04 - val_loss: 7.7964e-04\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5814e-04 - val_loss: 7.8001e-04\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5751e-04 - val_loss: 7.7926e-04\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5745e-04 - val_loss: 7.8057e-04\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5724e-04 - val_loss: 7.7938e-04\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5686e-04 - val_loss: 7.7927e-04\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5711e-04 - val_loss: 7.7919e-04\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5599e-04 - val_loss: 7.7990e-04\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5609e-04 - val_loss: 7.7984e-04\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5538e-04 - val_loss: 7.7771e-04\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5400e-04 - val_loss: 7.7843e-04\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5418e-04 - val_loss: 7.7784e-04\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5440e-04 - val_loss: 7.8057e-04\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5420e-04 - val_loss: 7.7810e-04\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5342e-04 - val_loss: 7.7984e-04\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.5443e-04 - val_loss: 7.7715e-04\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.5222e-04 - val_loss: 7.7743e-04\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5197e-04 - val_loss: 7.7653e-04\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5154e-04 - val_loss: 7.7735e-04\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5230e-04 - val_loss: 7.7824e-04\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5159e-04 - val_loss: 7.7730e-04\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5121e-04 - val_loss: 7.7711e-04\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5056e-04 - val_loss: 7.7703e-04\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5001e-04 - val_loss: 7.7566e-04\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4984e-04 - val_loss: 7.7554e-04\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4936e-04 - val_loss: 7.7666e-04\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.4879e-04 - val_loss: 7.7677e-04\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4860e-04 - val_loss: 7.7535e-04\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.4858e-04 - val_loss: 7.7557e-04\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4804e-04 - val_loss: 7.7537e-04\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4794e-04 - val_loss: 7.7744e-04\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5244e-04 - val_loss: 7.7801e-04\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5092e-04 - val_loss: 7.7914e-04\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5008e-04 - val_loss: 7.8307e-04\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.5350e-04 - val_loss: 7.7639e-04\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4845e-04 - val_loss: 7.7537e-04\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4730e-04 - val_loss: 7.7844e-04\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4856e-04 - val_loss: 7.7689e-04\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4716e-04 - val_loss: 7.7379e-04\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4524e-04 - val_loss: 7.7527e-04\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4677e-04 - val_loss: 7.7480e-04\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4628e-04 - val_loss: 7.7407e-04\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4364e-04 - val_loss: 7.7382e-04\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4293e-04 - val_loss: 7.7361e-04\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4318e-04 - val_loss: 7.7246e-04\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4267e-04 - val_loss: 7.7328e-04\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4225e-04 - val_loss: 7.7391e-04\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4227e-04 - val_loss: 7.7427e-04\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4213e-04 - val_loss: 7.7410e-04\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4164e-04 - val_loss: 7.7159e-04\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4136e-04 - val_loss: 7.7253e-04\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4072e-04 - val_loss: 7.7287e-04\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4070e-04 - val_loss: 7.7309e-04\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4077e-04 - val_loss: 7.7230e-04\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4118e-04 - val_loss: 7.7296e-04\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4116e-04 - val_loss: 7.7164e-04\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4140e-04 - val_loss: 7.7345e-04\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3997e-04 - val_loss: 7.7346e-04\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4010e-04 - val_loss: 7.7340e-04\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.4124e-04 - val_loss: 7.7197e-04\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3991e-04 - val_loss: 7.7151e-04\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3882e-04 - val_loss: 7.6969e-04\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3868e-04 - val_loss: 7.7001e-04\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3725e-04 - val_loss: 7.7055e-04\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3668e-04 - val_loss: 7.7029e-04\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3626e-04 - val_loss: 7.7144e-04\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3644e-04 - val_loss: 7.7077e-04\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3623e-04 - val_loss: 7.7011e-04\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3549e-04 - val_loss: 7.7074e-04\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3498e-04 - val_loss: 7.7029e-04\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3501e-04 - val_loss: 7.7029e-04\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3464e-04 - val_loss: 7.7044e-04\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3370e-04 - val_loss: 7.7030e-04\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3462e-04 - val_loss: 7.7063e-04\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3386e-04 - val_loss: 7.6975e-04\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3396e-04 - val_loss: 7.6906e-04\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3267e-04 - val_loss: 7.6997e-04\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3329e-04 - val_loss: 7.6962e-04\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3237e-04 - val_loss: 7.7068e-04\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3336e-04 - val_loss: 7.6927e-04\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3174e-04 - val_loss: 7.6755e-04\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3274e-04 - val_loss: 7.6968e-04\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3187e-04 - val_loss: 7.7028e-04\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3170e-04 - val_loss: 7.6902e-04\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3054e-04 - val_loss: 7.6744e-04\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3037e-04 - val_loss: 7.6901e-04\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3188e-04 - val_loss: 7.7144e-04\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3285e-04 - val_loss: 7.6983e-04\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3133e-04 - val_loss: 7.6719e-04\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3035e-04 - val_loss: 7.6879e-04\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3211e-04 - val_loss: 7.6816e-04\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2985e-04 - val_loss: 7.7060e-04\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2925e-04 - val_loss: 7.6830e-04\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2841e-04 - val_loss: 7.6652e-04\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2747e-04 - val_loss: 7.6752e-04\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.2718e-04 - val_loss: 7.6581e-04\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2647e-04 - val_loss: 7.6622e-04\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2629e-04 - val_loss: 7.6592e-04\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2570e-04 - val_loss: 7.6611e-04\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2557e-04 - val_loss: 7.6770e-04\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2564e-04 - val_loss: 7.6647e-04\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2514e-04 - val_loss: 7.6587e-04\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2535e-04 - val_loss: 7.6575e-04\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2436e-04 - val_loss: 7.6520e-04\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2371e-04 - val_loss: 7.6548e-04\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2372e-04 - val_loss: 7.6511e-04\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2363e-04 - val_loss: 7.6558e-04\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2356e-04 - val_loss: 7.6523e-04\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2371e-04 - val_loss: 7.6572e-04\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.2363e-04 - val_loss: 7.6551e-04\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2356e-04 - val_loss: 7.6572e-04\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2316e-04 - val_loss: 7.6493e-04\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2241e-04 - val_loss: 7.6623e-04\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2244e-04 - val_loss: 7.6585e-04\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2197e-04 - val_loss: 7.6711e-04\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2197e-04 - val_loss: 7.6599e-04\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2195e-04 - val_loss: 7.6631e-04\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2193e-04 - val_loss: 7.6625e-04\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2193e-04 - val_loss: 7.6500e-04\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2109e-04 - val_loss: 7.6402e-04\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.2012e-04 - val_loss: 7.6468e-04\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1993e-04 - val_loss: 7.6328e-04\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1953e-04 - val_loss: 7.6277e-04\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1903e-04 - val_loss: 7.6190e-04\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1816e-04 - val_loss: 7.6421e-04\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1817e-04 - val_loss: 7.6226e-04\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1825e-04 - val_loss: 7.6174e-04\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1831e-04 - val_loss: 7.6335e-04\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.1931e-04 - val_loss: 7.6130e-04\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2303e-04 - val_loss: 7.6733e-04\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2120e-04 - val_loss: 7.6776e-04\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.3289e-04 - val_loss: 7.7084e-04\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2412e-04 - val_loss: 7.7444e-04\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2871e-04 - val_loss: 7.6967e-04\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.2247e-04 - val_loss: 7.6449e-04\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1960e-04 - val_loss: 7.6120e-04\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1830e-04 - val_loss: 7.6150e-04\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.1636e-04 - val_loss: 7.6188e-04\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1681e-04 - val_loss: 7.6233e-04\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1690e-04 - val_loss: 7.5991e-04\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1644e-04 - val_loss: 7.5932e-04\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1457e-04 - val_loss: 7.6145e-04\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1518e-04 - val_loss: 7.6287e-04\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1532e-04 - val_loss: 7.6257e-04\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1445e-04 - val_loss: 7.6172e-04\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1363e-04 - val_loss: 7.5870e-04\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1279e-04 - val_loss: 7.5945e-04\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1195e-04 - val_loss: 7.5977e-04\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1186e-04 - val_loss: 7.6155e-04\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1191e-04 - val_loss: 7.6028e-04\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1124e-04 - val_loss: 7.5976e-04\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.1095e-04 - val_loss: 7.5913e-04\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1050e-04 - val_loss: 7.5778e-04\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1025e-04 - val_loss: 7.5663e-04\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0971e-04 - val_loss: 7.5843e-04\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0939e-04 - val_loss: 7.5987e-04\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0936e-04 - val_loss: 7.6152e-04\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0993e-04 - val_loss: 7.6061e-04\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0905e-04 - val_loss: 7.5881e-04\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0914e-04 - val_loss: 7.6002e-04\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0895e-04 - val_loss: 7.5877e-04\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0810e-04 - val_loss: 7.5625e-04\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0783e-04 - val_loss: 7.5683e-04\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0746e-04 - val_loss: 7.5816e-04\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0776e-04 - val_loss: 7.5787e-04\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0663e-04 - val_loss: 7.5829e-04\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0653e-04 - val_loss: 7.5724e-04\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0580e-04 - val_loss: 7.5770e-04\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0573e-04 - val_loss: 7.5751e-04\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0597e-04 - val_loss: 7.5635e-04\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0527e-04 - val_loss: 7.5657e-04\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0477e-04 - val_loss: 7.5634e-04\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0479e-04 - val_loss: 7.5694e-04\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0464e-04 - val_loss: 7.5530e-04\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0399e-04 - val_loss: 7.5605e-04\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0422e-04 - val_loss: 7.5617e-04\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0396e-04 - val_loss: 7.5618e-04\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0276e-04 - val_loss: 7.5671e-04\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0235e-04 - val_loss: 7.5758e-04\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0264e-04 - val_loss: 7.5786e-04\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0251e-04 - val_loss: 7.5809e-04\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0297e-04 - val_loss: 7.5792e-04\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0279e-04 - val_loss: 7.5922e-04\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0412e-04 - val_loss: 7.5870e-04\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0379e-04 - val_loss: 7.5872e-04\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0334e-04 - val_loss: 7.5666e-04\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0147e-04 - val_loss: 7.5586e-04\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0104e-04 - val_loss: 7.5577e-04\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0114e-04 - val_loss: 7.5631e-04\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.0136e-04 - val_loss: 7.5596e-04\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9988e-04 - val_loss: 7.5491e-04\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.9902e-04 - val_loss: 7.5604e-04\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.9902e-04 - val_loss: 7.5441e-04\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9836e-04 - val_loss: 7.5481e-04\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9825e-04 - val_loss: 7.5481e-04\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9807e-04 - val_loss: 7.5373e-04\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9783e-04 - val_loss: 7.5425e-04\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9777e-04 - val_loss: 7.5424e-04\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9746e-04 - val_loss: 7.5423e-04\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.9727e-04 - val_loss: 7.5676e-04\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9746e-04 - val_loss: 7.5450e-04\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9701e-04 - val_loss: 7.5362e-04\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9636e-04 - val_loss: 7.5521e-04\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9658e-04 - val_loss: 7.5480e-04\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9618e-04 - val_loss: 7.5357e-04\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9544e-04 - val_loss: 7.5513e-04\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9521e-04 - val_loss: 7.5523e-04\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9580e-04 - val_loss: 7.5430e-04\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9533e-04 - val_loss: 7.5569e-04\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9543e-04 - val_loss: 7.5491e-04\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9502e-04 - val_loss: 7.5360e-04\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9417e-04 - val_loss: 7.5340e-04\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9339e-04 - val_loss: 7.5262e-04\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9300e-04 - val_loss: 7.5333e-04\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9370e-04 - val_loss: 7.5448e-04\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.9354e-04 - val_loss: 7.5502e-04\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9250e-04 - val_loss: 7.5312e-04\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9331e-04 - val_loss: 7.5311e-04\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9167e-04 - val_loss: 7.5507e-04\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9148e-04 - val_loss: 7.5415e-04\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9146e-04 - val_loss: 7.5563e-04\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9168e-04 - val_loss: 7.5359e-04\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9058e-04 - val_loss: 7.5531e-04\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.9190e-04 - val_loss: 7.5536e-04\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9202e-04 - val_loss: 7.5291e-04\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.9065e-04 - val_loss: 7.5386e-04\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8998e-04 - val_loss: 7.5563e-04\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8939e-04 - val_loss: 7.5440e-04\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8897e-04 - val_loss: 7.5462e-04\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8900e-04 - val_loss: 7.5668e-04\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8975e-04 - val_loss: 7.5614e-04\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8885e-04 - val_loss: 7.5334e-04\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8833e-04 - val_loss: 7.5363e-04\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8858e-04 - val_loss: 7.5426e-04\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8818e-04 - val_loss: 7.5281e-04\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8730e-04 - val_loss: 7.5269e-04\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8652e-04 - val_loss: 7.5157e-04\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8671e-04 - val_loss: 7.5212e-04\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8673e-04 - val_loss: 7.5240e-04\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8606e-04 - val_loss: 7.5420e-04\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8595e-04 - val_loss: 7.5202e-04\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8507e-04 - val_loss: 7.5174e-04\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8506e-04 - val_loss: 7.5406e-04\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8510e-04 - val_loss: 7.5132e-04\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8484e-04 - val_loss: 7.5184e-04\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8523e-04 - val_loss: 7.5226e-04\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8447e-04 - val_loss: 7.5190e-04\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8404e-04 - val_loss: 7.5160e-04\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8372e-04 - val_loss: 7.5263e-04\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8356e-04 - val_loss: 7.5164e-04\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8343e-04 - val_loss: 7.5216e-04\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8338e-04 - val_loss: 7.5476e-04\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.8361e-04 - val_loss: 7.5481e-04\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8287e-04 - val_loss: 7.5189e-04\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8171e-04 - val_loss: 7.5300e-04\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8198e-04 - val_loss: 7.5323e-04\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8123e-04 - val_loss: 7.5260e-04\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8141e-04 - val_loss: 7.5007e-04\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8103e-04 - val_loss: 7.5016e-04\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8102e-04 - val_loss: 7.5117e-04\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8115e-04 - val_loss: 7.5173e-04\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8085e-04 - val_loss: 7.5405e-04\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8243e-04 - val_loss: 7.5295e-04\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8297e-04 - val_loss: 7.5641e-04\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8287e-04 - val_loss: 7.5306e-04\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.8041e-04 - val_loss: 7.5135e-04\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7925e-04 - val_loss: 7.5080e-04\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7891e-04 - val_loss: 7.5097e-04\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7833e-04 - val_loss: 7.5164e-04\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7840e-04 - val_loss: 7.5292e-04\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7834e-04 - val_loss: 7.5315e-04\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7767e-04 - val_loss: 7.5061e-04\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7750e-04 - val_loss: 7.5063e-04\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7692e-04 - val_loss: 7.5054e-04\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7724e-04 - val_loss: 7.5279e-04\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.7666e-04 - val_loss: 7.5018e-04\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7622e-04 - val_loss: 7.5018e-04\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.7584e-04 - val_loss: 7.5125e-04\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.7571e-04 - val_loss: 7.5021e-04\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7580e-04 - val_loss: 7.5050e-04\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7551e-04 - val_loss: 7.5058e-04\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7558e-04 - val_loss: 7.5091e-04\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7483e-04 - val_loss: 7.5096e-04\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7420e-04 - val_loss: 7.5307e-04\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.7495e-04 - val_loss: 7.5235e-04\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7546e-04 - val_loss: 7.5131e-04\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7479e-04 - val_loss: 7.4980e-04\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7367e-04 - val_loss: 7.5141e-04\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7374e-04 - val_loss: 7.5127e-04\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7323e-04 - val_loss: 7.5008e-04\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7274e-04 - val_loss: 7.5057e-04\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7276e-04 - val_loss: 7.5080e-04\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7230e-04 - val_loss: 7.5057e-04\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7140e-04 - val_loss: 7.4920e-04\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7164e-04 - val_loss: 7.5006e-04\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7134e-04 - val_loss: 7.5089e-04\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7162e-04 - val_loss: 7.5077e-04\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7069e-04 - val_loss: 7.4891e-04\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7140e-04 - val_loss: 7.4777e-04\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.7075e-04 - val_loss: 7.5039e-04\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.7032e-04 - val_loss: 7.5139e-04\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6972e-04 - val_loss: 7.4977e-04\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6965e-04 - val_loss: 7.4892e-04\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.7020e-04 - val_loss: 7.5081e-04\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6860e-04 - val_loss: 7.4838e-04\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6846e-04 - val_loss: 7.4933e-04\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6802e-04 - val_loss: 7.5031e-04\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6799e-04 - val_loss: 7.4981e-04\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.6769e-04 - val_loss: 7.4978e-04\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6758e-04 - val_loss: 7.5035e-04\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.6730e-04 - val_loss: 7.4938e-04\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6760e-04 - val_loss: 7.5004e-04\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6806e-04 - val_loss: 7.5171e-04\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6989e-04 - val_loss: 7.4843e-04\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6819e-04 - val_loss: 7.5012e-04\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6724e-04 - val_loss: 7.5058e-04\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6554e-04 - val_loss: 7.4916e-04\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6536e-04 - val_loss: 7.4962e-04\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6506e-04 - val_loss: 7.5049e-04\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6483e-04 - val_loss: 7.5017e-04\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6462e-04 - val_loss: 7.4951e-04\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6453e-04 - val_loss: 7.5380e-04\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6533e-04 - val_loss: 7.5398e-04\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6420e-04 - val_loss: 7.5262e-04\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6401e-04 - val_loss: 7.5195e-04\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6448e-04 - val_loss: 7.5120e-04\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6317e-04 - val_loss: 7.5096e-04\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6256e-04 - val_loss: 7.5046e-04\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6292e-04 - val_loss: 7.5089e-04\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6335e-04 - val_loss: 7.4942e-04\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6239e-04 - val_loss: 7.5044e-04\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6155e-04 - val_loss: 7.4962e-04\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6157e-04 - val_loss: 7.5064e-04\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6146e-04 - val_loss: 7.5329e-04\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6177e-04 - val_loss: 7.5190e-04\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6408e-04 - val_loss: 7.5486e-04\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6437e-04 - val_loss: 7.5548e-04\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6316e-04 - val_loss: 7.5010e-04\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6093e-04 - val_loss: 7.4886e-04\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6040e-04 - val_loss: 7.5037e-04\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.6013e-04 - val_loss: 7.5097e-04\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5925e-04 - val_loss: 7.5085e-04\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5928e-04 - val_loss: 7.5259e-04\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5934e-04 - val_loss: 7.5200e-04\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5932e-04 - val_loss: 7.5241e-04\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5922e-04 - val_loss: 7.5227e-04\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5907e-04 - val_loss: 7.5051e-04\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5859e-04 - val_loss: 7.5116e-04\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5783e-04 - val_loss: 7.4939e-04\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5718e-04 - val_loss: 7.4884e-04\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5677e-04 - val_loss: 7.5149e-04\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5623e-04 - val_loss: 7.5171e-04\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5597e-04 - val_loss: 7.5208e-04\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5564e-04 - val_loss: 7.5064e-04\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5539e-04 - val_loss: 7.5033e-04\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5586e-04 - val_loss: 7.5158e-04\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5533e-04 - val_loss: 7.5214e-04\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5459e-04 - val_loss: 7.5303e-04\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5452e-04 - val_loss: 7.5354e-04\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.5487e-04 - val_loss: 7.5073e-04\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5410e-04 - val_loss: 7.5339e-04\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5401e-04 - val_loss: 7.5228e-04\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5401e-04 - val_loss: 7.5238e-04\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5367e-04 - val_loss: 7.4959e-04\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5345e-04 - val_loss: 7.5139e-04\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5351e-04 - val_loss: 7.5371e-04\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5282e-04 - val_loss: 7.5286e-04\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5233e-04 - val_loss: 7.5393e-04\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5216e-04 - val_loss: 7.5230e-04\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5218e-04 - val_loss: 7.5465e-04\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5285e-04 - val_loss: 7.5404e-04\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5253e-04 - val_loss: 7.5176e-04\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5205e-04 - val_loss: 7.5392e-04\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5227e-04 - val_loss: 7.5281e-04\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5205e-04 - val_loss: 7.5165e-04\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.5306e-04 - val_loss: 7.5223e-04\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5146e-04 - val_loss: 7.5493e-04\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5132e-04 - val_loss: 7.5514e-04\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5109e-04 - val_loss: 7.5678e-04\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5100e-04 - val_loss: 7.5591e-04\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5006e-04 - val_loss: 7.5425e-04\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4910e-04 - val_loss: 7.5382e-04\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4906e-04 - val_loss: 7.5534e-04\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4868e-04 - val_loss: 7.5302e-04\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4849e-04 - val_loss: 7.5372e-04\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4835e-04 - val_loss: 7.5273e-04\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4891e-04 - val_loss: 7.5322e-04\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4822e-04 - val_loss: 7.5508e-04\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.4794e-04 - val_loss: 7.5537e-04\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4753e-04 - val_loss: 7.5470e-04\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4800e-04 - val_loss: 7.5507e-04\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4856e-04 - val_loss: 7.5515e-04\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4756e-04 - val_loss: 7.5334e-04\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4660e-04 - val_loss: 7.5463e-04\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4679e-04 - val_loss: 7.5342e-04\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4656e-04 - val_loss: 7.5399e-04\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4783e-04 - val_loss: 7.5661e-04\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.5020e-04 - val_loss: 7.5533e-04\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4755e-04 - val_loss: 7.5354e-04\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4747e-04 - val_loss: 7.5597e-04\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4551e-04 - val_loss: 7.5403e-04\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4543e-04 - val_loss: 7.5409e-04\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4463e-04 - val_loss: 7.5509e-04\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4400e-04 - val_loss: 7.5591e-04\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4382e-04 - val_loss: 7.6013e-04\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4399e-04 - val_loss: 7.5472e-04\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4353e-04 - val_loss: 7.5755e-04\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4424e-04 - val_loss: 7.5618e-04\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4350e-04 - val_loss: 7.5793e-04\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4454e-04 - val_loss: 7.5844e-04\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.4340e-04 - val_loss: 7.5832e-04\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.4320e-04 - val_loss: 7.6126e-04\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4468e-04 - val_loss: 7.6440e-04\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4525e-04 - val_loss: 7.6692e-04\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4513e-04 - val_loss: 7.6244e-04\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4412e-04 - val_loss: 7.6024e-04\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.4309e-04 - val_loss: 7.6163e-04\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4288e-04 - val_loss: 7.6268e-04\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4389e-04 - val_loss: 7.5921e-04\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4279e-04 - val_loss: 7.5590e-04\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4387e-04 - val_loss: 7.5910e-04\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4219e-04 - val_loss: 7.5808e-04\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4180e-04 - val_loss: 7.5700e-04\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.4047e-04 - val_loss: 7.5447e-04\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3991e-04 - val_loss: 7.5509e-04\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3971e-04 - val_loss: 7.5511e-04\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3891e-04 - val_loss: 7.5893e-04\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3916e-04 - val_loss: 7.5946e-04\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3935e-04 - val_loss: 7.6105e-04\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3974e-04 - val_loss: 7.6079e-04\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3896e-04 - val_loss: 7.5882e-04\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3970e-04 - val_loss: 7.5822e-04\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3880e-04 - val_loss: 7.5741e-04\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3855e-04 - val_loss: 7.5830e-04\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3802e-04 - val_loss: 7.5761e-04\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3801e-04 - val_loss: 7.5826e-04\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3767e-04 - val_loss: 7.5744e-04\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3727e-04 - val_loss: 7.6061e-04\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3678e-04 - val_loss: 7.6011e-04\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3684e-04 - val_loss: 7.5945e-04\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3716e-04 - val_loss: 7.5998e-04\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3574e-04 - val_loss: 7.5972e-04\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3581e-04 - val_loss: 7.5974e-04\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3516e-04 - val_loss: 7.5971e-04\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3510e-04 - val_loss: 7.6189e-04\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3446e-04 - val_loss: 7.5948e-04\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3426e-04 - val_loss: 7.5775e-04\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3405e-04 - val_loss: 7.5896e-04\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3408e-04 - val_loss: 7.5868e-04\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3413e-04 - val_loss: 7.5926e-04\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3410e-04 - val_loss: 7.6143e-04\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3421e-04 - val_loss: 7.6213e-04\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3358e-04 - val_loss: 7.5853e-04\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3347e-04 - val_loss: 7.5890e-04\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3302e-04 - val_loss: 7.6256e-04\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3273e-04 - val_loss: 7.5998e-04\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3278e-04 - val_loss: 7.6266e-04\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3257e-04 - val_loss: 7.6323e-04\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3196e-04 - val_loss: 7.6282e-04\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3168e-04 - val_loss: 7.6480e-04\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3159e-04 - val_loss: 7.6384e-04\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3111e-04 - val_loss: 7.6297e-04\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3076e-04 - val_loss: 7.6097e-04\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3033e-04 - val_loss: 7.6043e-04\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3034e-04 - val_loss: 7.6053e-04\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.3029e-04 - val_loss: 7.6048e-04\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2993e-04 - val_loss: 7.6161e-04\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2958e-04 - val_loss: 7.6185e-04\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2973e-04 - val_loss: 7.6298e-04\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2963e-04 - val_loss: 7.6416e-04\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2913e-04 - val_loss: 7.6283e-04\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2898e-04 - val_loss: 7.6070e-04\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6.2877e-04 - val_loss: 7.6180e-04\n",
      "Autoencoder Training Loss: 0.0006\n"
     ]
    }
   ],
   "source": [
    "encoder, history = train_encoder(X_train, epochs=epochs, latent_factor=latent_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc1fef986a0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded, X_test_encoded = encoder.predict(X_train), encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \t train loss: 0.3192 \t val error: 2.2350\n",
      "Iteration 1: \t train loss: 0.3131 \t val error: 2.1911\n",
      "Iteration 2: \t train loss: 0.3078 \t val error: 2.1728\n",
      "Iteration 3: \t train loss: 0.3026 \t val error: 2.1728\n",
      "Iteration 4: \t train loss: 0.2973 \t val error: 2.1728\n",
      "Iteration 5: \t train loss: 0.2921 \t val error: 2.1728\n",
      "Iteration 6: \t train loss: 0.2869 \t val error: 2.1728\n",
      "Iteration 7: \t train loss: 0.2816 \t val error: 2.1728\n",
      "Iteration 8: \t train loss: 0.2764 \t val error: 2.1728\n",
      "Iteration 9: \t train loss: 0.2712 \t val error: 2.1735\n",
      "Iteration 10: \t train loss: 0.2660 \t val error: 2.1743\n",
      "Iteration 11: \t train loss: 0.2609 \t val error: 2.1751\n",
      "Iteration 12: \t train loss: 0.2557 \t val error: 2.1759\n",
      "Iteration 13: \t train loss: 0.2505 \t val error: 2.1763\n",
      "Iteration 14: \t train loss: 0.2453 \t val error: 2.1763\n",
      "Iteration 15: \t train loss: 0.2402 \t val error: 2.1763\n",
      "Iteration 16: \t train loss: 0.2351 \t val error: 2.1763\n",
      "Iteration 17: \t train loss: 0.2299 \t val error: 2.1763\n",
      "Iteration 18: \t train loss: 0.2248 \t val error: 2.1763\n",
      "Iteration 19: \t train loss: 0.2197 \t val error: 2.1763\n",
      "Iteration 20: \t train loss: 0.2146 \t val error: 2.1763\n",
      "Iteration 21: \t train loss: 0.2095 \t val error: 2.1836\n",
      "Iteration 22: \t train loss: 0.2044 \t val error: 2.1836\n",
      "Iteration 23: \t train loss: 0.1993 \t val error: 2.1836\n",
      "Iteration 24: \t train loss: 0.1942 \t val error: 2.1836\n",
      "Iteration 25: \t train loss: 0.1891 \t val error: 2.1836\n",
      "Iteration 26: \t train loss: 0.1841 \t val error: 2.1836\n",
      "Iteration 27: \t train loss: 0.1790 \t val error: 2.1836\n",
      "Iteration 28: \t train loss: 0.1740 \t val error: 2.1841\n",
      "Iteration 29: \t train loss: 0.1689 \t val error: 2.1857\n",
      "Iteration 30: \t train loss: 0.1639 \t val error: 2.1874\n",
      "Iteration 31: \t train loss: 0.1589 \t val error: 2.1890\n",
      "Iteration 32: \t train loss: 0.1539 \t val error: 2.1901\n",
      "Iteration 33: \t train loss: 0.1489 \t val error: 2.1901\n",
      "Iteration 34: \t train loss: 0.1439 \t val error: 2.1901\n",
      "Iteration 35: \t train loss: 0.1389 \t val error: 2.1901\n",
      "Iteration 36: \t train loss: 0.1339 \t val error: 2.1896\n",
      "Iteration 37: \t train loss: 0.1289 \t val error: 2.1881\n",
      "Iteration 38: \t train loss: 0.1240 \t val error: 2.1864\n",
      "Iteration 39: \t train loss: 0.1190 \t val error: 2.1849\n",
      "Iteration 40: \t train loss: 0.1141 \t val error: 2.1842\n",
      "Iteration 41: \t train loss: 0.1091 \t val error: 2.1836\n",
      "Iteration 42: \t train loss: 0.1042 \t val error: 2.1832\n",
      "Iteration 43: \t train loss: 0.0993 \t val error: 2.1832\n",
      "Iteration 44: \t train loss: 0.0943 \t val error: 2.1832\n",
      "Iteration 45: \t train loss: 0.0894 \t val error: 2.1832\n",
      "Iteration 46: \t train loss: 0.0845 \t val error: 2.1832\n",
      "Iteration 47: \t train loss: 0.0796 \t val error: 2.1832\n",
      "Iteration 48: \t train loss: 0.0748 \t val error: 2.1832\n",
      "Iteration 49: \t train loss: 0.0699 \t val error: 2.1832\n",
      "Iteration 50: \t train loss: 0.0650 \t val error: 2.1832\n",
      "Iteration 51: \t train loss: 0.0601 \t val error: 2.1832\n",
      "Iteration 52: \t train loss: 0.0553 \t val error: 2.1832\n",
      "Iteration 53: \t train loss: 0.0504 \t val error: 2.1832\n",
      "Iteration 54: \t train loss: 0.0456 \t val error: 2.1832\n",
      "Iteration 55: \t train loss: 0.0408 \t val error: 2.1832\n",
      "Iteration 56: \t train loss: 0.0360 \t val error: 2.1832\n",
      "Iteration 57: \t train loss: 0.0311 \t val error: 2.1832\n",
      "Iteration 58: \t train loss: 0.0263 \t val error: 2.1832\n",
      "Iteration 59: \t train loss: 0.0215 \t val error: 2.1832\n",
      "Iteration 60: \t train loss: 0.0167 \t val error: 2.1839\n",
      "Iteration 61: \t train loss: 0.0120 \t val error: 2.1820\n",
      "Iteration 62: \t train loss: 0.0072 \t val error: 2.1786\n",
      "Iteration 63: \t train loss: 0.0024 \t val error: 2.1793\n",
      "Iteration 64: \t train loss: -0.0023 \t val error: 2.1799\n",
      "Iteration 65: \t train loss: -0.0071 \t val error: 2.1806\n",
      "Iteration 66: \t train loss: -0.0118 \t val error: 2.1810\n",
      "Iteration 67: \t train loss: -0.0166 \t val error: 2.1810\n",
      "Iteration 68: \t train loss: -0.0213 \t val error: 2.1810\n",
      "Iteration 69: \t train loss: -0.0260 \t val error: 2.1810\n",
      "Iteration 70: \t train loss: -0.0307 \t val error: 2.1810\n",
      "Iteration 71: \t train loss: -0.0354 \t val error: 2.1810\n",
      "Iteration 72: \t train loss: -0.0401 \t val error: 2.1810\n",
      "Iteration 73: \t train loss: -0.0448 \t val error: 2.1810\n",
      "Iteration 74: \t train loss: -0.0495 \t val error: 2.1810\n",
      "Iteration 75: \t train loss: -0.0542 \t val error: 2.1810\n",
      "Iteration 76: \t train loss: -0.0589 \t val error: 2.1810\n",
      "Iteration 77: \t train loss: -0.0635 \t val error: 2.1810\n",
      "Iteration 78: \t train loss: -0.0682 \t val error: 2.1807\n",
      "Iteration 79: \t train loss: -0.0728 \t val error: 2.1800\n",
      "Iteration 80: \t train loss: -0.0775 \t val error: 2.1793\n",
      "Iteration 81: \t train loss: -0.0821 \t val error: 2.1786\n",
      "Iteration 82: \t train loss: -0.0867 \t val error: 2.1779\n",
      "Iteration 83: \t train loss: -0.0913 \t val error: 2.1772\n",
      "Iteration 84: \t train loss: -0.0959 \t val error: 2.1693\n",
      "Iteration 85: \t train loss: -0.1005 \t val error: 2.1693\n",
      "Iteration 86: \t train loss: -0.1051 \t val error: 2.1693\n",
      "Iteration 87: \t train loss: -0.1097 \t val error: 2.1693\n",
      "Iteration 88: \t train loss: -0.1143 \t val error: 2.1693\n",
      "Iteration 89: \t train loss: -0.1189 \t val error: 2.1693\n",
      "Iteration 90: \t train loss: -0.1234 \t val error: 2.1693\n",
      "Iteration 91: \t train loss: -0.1280 \t val error: 2.1693\n",
      "Iteration 92: \t train loss: -0.1325 \t val error: 2.1693\n",
      "Iteration 93: \t train loss: -0.1371 \t val error: 2.1693\n",
      "Iteration 94: \t train loss: -0.1416 \t val error: 2.1693\n",
      "Iteration 95: \t train loss: -0.1461 \t val error: 2.1693\n",
      "Iteration 96: \t train loss: -0.1507 \t val error: 2.1693\n",
      "Iteration 97: \t train loss: -0.1552 \t val error: 2.1693\n",
      "Iteration 98: \t train loss: -0.1597 \t val error: 2.1693\n",
      "Iteration 99: \t train loss: -0.1642 \t val error: 2.1693\n",
      "Iteration 100: \t train loss: -0.1687 \t val error: 2.1694\n",
      "Iteration 101: \t train loss: -0.1731 \t val error: 2.1696\n",
      "Iteration 102: \t train loss: -0.1776 \t val error: 2.1697\n",
      "Iteration 103: \t train loss: -0.1821 \t val error: 2.1697\n",
      "Iteration 104: \t train loss: -0.1865 \t val error: 2.1699\n",
      "Iteration 105: \t train loss: -0.1910 \t val error: 2.1702\n",
      "Iteration 106: \t train loss: -0.1954 \t val error: 2.1705\n",
      "Iteration 107: \t train loss: -0.1999 \t val error: 2.1709\n",
      "Iteration 108: \t train loss: -0.2043 \t val error: 2.1712\n",
      "Iteration 109: \t train loss: -0.2087 \t val error: 2.1715\n",
      "Iteration 110: \t train loss: -0.2131 \t val error: 2.1729\n",
      "Iteration 111: \t train loss: -0.2176 \t val error: 2.1755\n",
      "Iteration 112: \t train loss: -0.2220 \t val error: 2.1780\n",
      "Iteration 113: \t train loss: -0.2264 \t val error: 2.1792\n",
      "Iteration 114: \t train loss: -0.2307 \t val error: 2.1795\n",
      "Iteration 115: \t train loss: -0.2351 \t val error: 2.1798\n",
      "Iteration 116: \t train loss: -0.2395 \t val error: 2.1801\n",
      "Iteration 117: \t train loss: -0.2439 \t val error: 2.1804\n",
      "Iteration 118: \t train loss: -0.2482 \t val error: 2.1807\n",
      "Iteration 119: \t train loss: -0.2526 \t val error: 2.1810\n",
      "Iteration 120: \t train loss: -0.2569 \t val error: 2.1813\n",
      "Iteration 121: \t train loss: -0.2613 \t val error: 2.1816\n",
      "Iteration 122: \t train loss: -0.2656 \t val error: 2.1816\n",
      "Iteration 123: \t train loss: -0.2699 \t val error: 2.1816\n",
      "Iteration 124: \t train loss: -0.2742 \t val error: 2.1816\n",
      "Iteration 125: \t train loss: -0.2785 \t val error: 2.1816\n",
      "Iteration 126: \t train loss: -0.2828 \t val error: 2.1816\n",
      "Iteration 127: \t train loss: -0.2871 \t val error: 2.1816\n",
      "Iteration 128: \t train loss: -0.2914 \t val error: 2.1816\n",
      "Iteration 129: \t train loss: -0.2957 \t val error: 2.1816\n",
      "Iteration 130: \t train loss: -0.3000 \t val error: 2.1816\n",
      "Iteration 131: \t train loss: -0.3043 \t val error: 2.1816\n",
      "Iteration 132: \t train loss: -0.3085 \t val error: 2.1881\n",
      "Iteration 133: \t train loss: -0.3128 \t val error: 2.1868\n",
      "Iteration 134: \t train loss: -0.3170 \t val error: 2.1854\n",
      "Iteration 135: \t train loss: -0.3213 \t val error: 2.1854\n",
      "Iteration 136: \t train loss: -0.3255 \t val error: 2.1854\n",
      "Iteration 137: \t train loss: -0.3297 \t val error: 2.1854\n",
      "Iteration 138: \t train loss: -0.3339 \t val error: 2.1854\n",
      "Iteration 139: \t train loss: -0.3381 \t val error: 2.1854\n",
      "Iteration 140: \t train loss: -0.3424 \t val error: 2.1854\n",
      "Iteration 141: \t train loss: -0.3466 \t val error: 2.1854\n",
      "Iteration 142: \t train loss: -0.3507 \t val error: 2.1854\n",
      "Iteration 143: \t train loss: -0.3549 \t val error: 2.1854\n",
      "Iteration 144: \t train loss: -0.3591 \t val error: 2.1854\n",
      "Iteration 145: \t train loss: -0.3633 \t val error: 2.1854\n",
      "Iteration 146: \t train loss: -0.3674 \t val error: 2.1854\n",
      "Iteration 147: \t train loss: -0.3716 \t val error: 2.1854\n",
      "Iteration 148: \t train loss: -0.3757 \t val error: 2.1854\n",
      "Iteration 149: \t train loss: -0.3799 \t val error: 2.1854\n",
      "Iteration 150: \t train loss: -0.3840 \t val error: 2.1854\n",
      "Iteration 151: \t train loss: -0.3882 \t val error: 2.1854\n",
      "Iteration 152: \t train loss: -0.3923 \t val error: 2.1854\n",
      "Iteration 153: \t train loss: -0.3964 \t val error: 2.1854\n",
      "Iteration 154: \t train loss: -0.4005 \t val error: 2.1854\n",
      "Iteration 155: \t train loss: -0.4046 \t val error: 2.1854\n",
      "Iteration 156: \t train loss: -0.4087 \t val error: 2.1854\n",
      "Iteration 157: \t train loss: -0.4128 \t val error: 2.1854\n",
      "Iteration 158: \t train loss: -0.4169 \t val error: 2.1854\n",
      "Iteration 159: \t train loss: -0.4210 \t val error: 2.1854\n",
      "Iteration 160: \t train loss: -0.4250 \t val error: 2.1855\n",
      "Iteration 161: \t train loss: -0.4291 \t val error: 2.1856\n",
      "Iteration 162: \t train loss: -0.4331 \t val error: 2.1857\n",
      "Iteration 163: \t train loss: -0.4372 \t val error: 2.1858\n",
      "Iteration 164: \t train loss: -0.4412 \t val error: 2.1860\n",
      "Iteration 165: \t train loss: -0.4453 \t val error: 2.1861\n",
      "Iteration 166: \t train loss: -0.4493 \t val error: 2.1862\n",
      "Iteration 167: \t train loss: -0.4533 \t val error: 2.1862\n",
      "Iteration 168: \t train loss: -0.4573 \t val error: 2.1862\n",
      "Iteration 169: \t train loss: -0.4614 \t val error: 2.1862\n",
      "Iteration 170: \t train loss: -0.4654 \t val error: 2.1862\n",
      "Iteration 171: \t train loss: -0.4694 \t val error: 2.1936\n",
      "Iteration 172: \t train loss: -0.4733 \t val error: 2.1936\n",
      "Iteration 173: \t train loss: -0.4773 \t val error: 2.1936\n",
      "Iteration 174: \t train loss: -0.4813 \t val error: 2.1936\n",
      "Iteration 175: \t train loss: -0.4853 \t val error: 2.1936\n",
      "Iteration 176: \t train loss: -0.4892 \t val error: 2.1936\n",
      "Iteration 177: \t train loss: -0.4932 \t val error: 2.1936\n",
      "Iteration 178: \t train loss: -0.4971 \t val error: 2.1936\n",
      "Iteration 179: \t train loss: -0.5011 \t val error: 2.1936\n",
      "Iteration 180: \t train loss: -0.5050 \t val error: 2.1936\n",
      "Iteration 181: \t train loss: -0.5090 \t val error: 2.1936\n",
      "Iteration 182: \t train loss: -0.5129 \t val error: 2.1934\n",
      "Iteration 183: \t train loss: -0.5168 \t val error: 2.1931\n",
      "Iteration 184: \t train loss: -0.5207 \t val error: 2.1928\n",
      "Iteration 185: \t train loss: -0.5246 \t val error: 2.1928\n",
      "Iteration 186: \t train loss: -0.5285 \t val error: 2.1928\n",
      "Iteration 187: \t train loss: -0.5324 \t val error: 2.1928\n",
      "Iteration 188: \t train loss: -0.5363 \t val error: 2.1928\n",
      "Iteration 189: \t train loss: -0.5402 \t val error: 2.1928\n",
      "Iteration 190: \t train loss: -0.5441 \t val error: 2.1928\n",
      "Iteration 191: \t train loss: -0.5479 \t val error: 2.1928\n",
      "Iteration 192: \t train loss: -0.5518 \t val error: 2.1928\n",
      "Iteration 193: \t train loss: -0.5556 \t val error: 2.1928\n",
      "Iteration 194: \t train loss: -0.5595 \t val error: 2.1928\n",
      "Iteration 195: \t train loss: -0.5633 \t val error: 2.1928\n",
      "Iteration 196: \t train loss: -0.5672 \t val error: 2.1928\n",
      "Iteration 197: \t train loss: -0.5710 \t val error: 2.1928\n",
      "Iteration 198: \t train loss: -0.5748 \t val error: 2.1928\n",
      "Iteration 199: \t train loss: -0.5786 \t val error: 2.1928\n",
      "Iteration 200: \t train loss: -0.5824 \t val error: 2.1928\n",
      "Iteration 201: \t train loss: -0.5862 \t val error: 2.1928\n",
      "Iteration 202: \t train loss: -0.5900 \t val error: 2.1928\n",
      "Iteration 203: \t train loss: -0.5938 \t val error: 2.1928\n",
      "Iteration 204: \t train loss: -0.5976 \t val error: 2.1928\n",
      "Iteration 205: \t train loss: -0.6014 \t val error: 2.1928\n",
      "Iteration 206: \t train loss: -0.6052 \t val error: 2.1928\n",
      "Iteration 207: \t train loss: -0.6089 \t val error: 2.1928\n",
      "Iteration 208: \t train loss: -0.6127 \t val error: 2.1928\n",
      "Iteration 209: \t train loss: -0.6165 \t val error: 2.1928\n",
      "Iteration 210: \t train loss: -0.6202 \t val error: 2.1928\n",
      "Iteration 211: \t train loss: -0.6239 \t val error: 2.1928\n",
      "Iteration 212: \t train loss: -0.6277 \t val error: 2.1928\n",
      "Iteration 213: \t train loss: -0.6314 \t val error: 2.1928\n",
      "Iteration 214: \t train loss: -0.6351 \t val error: 2.1928\n",
      "Iteration 215: \t train loss: -0.6388 \t val error: 2.1928\n",
      "Iteration 216: \t train loss: -0.6426 \t val error: 2.1928\n",
      "Iteration 217: \t train loss: -0.6463 \t val error: 2.1854\n",
      "Iteration 218: \t train loss: -0.6500 \t val error: 2.1854\n",
      "Iteration 219: \t train loss: -0.6537 \t val error: 2.1854\n",
      "Iteration 220: \t train loss: -0.6573 \t val error: 2.1854\n",
      "Iteration 221: \t train loss: -0.6610 \t val error: 2.1854\n",
      "Iteration 222: \t train loss: -0.6647 \t val error: 2.1854\n",
      "Iteration 223: \t train loss: -0.6684 \t val error: 2.1854\n",
      "Iteration 224: \t train loss: -0.6720 \t val error: 2.1854\n",
      "Iteration 225: \t train loss: -0.6757 \t val error: 2.1854\n",
      "Iteration 226: \t train loss: -0.6793 \t val error: 2.1854\n",
      "Iteration 227: \t train loss: -0.6830 \t val error: 2.1854\n",
      "Iteration 228: \t train loss: -0.6866 \t val error: 2.1854\n",
      "Iteration 229: \t train loss: -0.6902 \t val error: 2.1854\n",
      "Iteration 230: \t train loss: -0.6939 \t val error: 2.1854\n",
      "Iteration 231: \t train loss: -0.6975 \t val error: 2.1854\n",
      "Iteration 232: \t train loss: -0.7011 \t val error: 2.1854\n",
      "Iteration 233: \t train loss: -0.7047 \t val error: 2.1854\n",
      "Iteration 234: \t train loss: -0.7083 \t val error: 2.1854\n",
      "Iteration 235: \t train loss: -0.7119 \t val error: 2.1854\n",
      "Iteration 236: \t train loss: -0.7155 \t val error: 2.1854\n",
      "Iteration 237: \t train loss: -0.7191 \t val error: 2.1854\n",
      "Iteration 238: \t train loss: -0.7227 \t val error: 2.1854\n",
      "Iteration 239: \t train loss: -0.7262 \t val error: 2.1854\n",
      "Iteration 240: \t train loss: -0.7298 \t val error: 2.1854\n",
      "Iteration 241: \t train loss: -0.7334 \t val error: 2.1854\n",
      "Iteration 242: \t train loss: -0.7369 \t val error: 2.1854\n",
      "Iteration 243: \t train loss: -0.7405 \t val error: 2.1854\n",
      "Iteration 244: \t train loss: -0.7440 \t val error: 2.1854\n",
      "Iteration 245: \t train loss: -0.7475 \t val error: 2.1854\n",
      "Iteration 246: \t train loss: -0.7511 \t val error: 2.1854\n",
      "Iteration 247: \t train loss: -0.7546 \t val error: 2.1854\n",
      "Iteration 248: \t train loss: -0.7581 \t val error: 2.1854\n",
      "Iteration 249: \t train loss: -0.7616 \t val error: 2.1854\n",
      "Iteration 250: \t train loss: -0.7651 \t val error: 2.1854\n",
      "Iteration 251: \t train loss: -0.7686 \t val error: 2.1854\n",
      "Iteration 252: \t train loss: -0.7721 \t val error: 2.1854\n",
      "Iteration 253: \t train loss: -0.7756 \t val error: 2.1854\n",
      "Iteration 254: \t train loss: -0.7791 \t val error: 2.1854\n",
      "Iteration 255: \t train loss: -0.7826 \t val error: 2.1854\n",
      "Iteration 256: \t train loss: -0.7861 \t val error: 2.1854\n",
      "Iteration 257: \t train loss: -0.7895 \t val error: 2.1854\n",
      "Iteration 258: \t train loss: -0.7930 \t val error: 2.1854\n",
      "Iteration 259: \t train loss: -0.7964 \t val error: 2.1854\n",
      "Iteration 260: \t train loss: -0.7999 \t val error: 2.1854\n",
      "Iteration 261: \t train loss: -0.8033 \t val error: 2.1854\n",
      "Iteration 262: \t train loss: -0.8068 \t val error: 2.1854\n",
      "Iteration 263: \t train loss: -0.8102 \t val error: 2.1853\n",
      "Iteration 264: \t train loss: -0.8136 \t val error: 2.1852\n",
      "Iteration 265: \t train loss: -0.8171 \t val error: 2.1852\n",
      "Iteration 266: \t train loss: -0.8205 \t val error: 2.1851\n",
      "Iteration 267: \t train loss: -0.8239 \t val error: 2.1850\n",
      "Iteration 268: \t train loss: -0.8273 \t val error: 2.1849\n",
      "Iteration 269: \t train loss: -0.8307 \t val error: 2.1848\n",
      "Iteration 270: \t train loss: -0.8341 \t val error: 2.1847\n",
      "Iteration 271: \t train loss: -0.8375 \t val error: 2.1847\n",
      "Iteration 272: \t train loss: -0.8409 \t val error: 2.1847\n",
      "Iteration 273: \t train loss: -0.8442 \t val error: 2.1847\n",
      "Iteration 274: \t train loss: -0.8476 \t val error: 2.1847\n",
      "Iteration 275: \t train loss: -0.8510 \t val error: 2.1847\n",
      "Iteration 276: \t train loss: -0.8543 \t val error: 2.1847\n",
      "Iteration 277: \t train loss: -0.8577 \t val error: 2.1847\n",
      "Iteration 278: \t train loss: -0.8610 \t val error: 2.1847\n",
      "Iteration 279: \t train loss: -0.8644 \t val error: 2.1847\n",
      "Iteration 280: \t train loss: -0.8677 \t val error: 2.1847\n",
      "Iteration 281: \t train loss: -0.8710 \t val error: 2.1847\n",
      "Iteration 282: \t train loss: -0.8744 \t val error: 2.1847\n",
      "Iteration 283: \t train loss: -0.8777 \t val error: 2.1847\n",
      "Iteration 284: \t train loss: -0.8810 \t val error: 2.1843\n",
      "Iteration 285: \t train loss: -0.8843 \t val error: 2.1840\n",
      "Iteration 286: \t train loss: -0.8876 \t val error: 2.1836\n",
      "Iteration 287: \t train loss: -0.8909 \t val error: 2.1833\n",
      "Iteration 288: \t train loss: -0.8942 \t val error: 2.1829\n",
      "Iteration 289: \t train loss: -0.8975 \t val error: 2.1826\n",
      "Iteration 290: \t train loss: -0.9008 \t val error: 2.1822\n",
      "Iteration 291: \t train loss: -0.9041 \t val error: 2.1819\n",
      "Iteration 292: \t train loss: -0.9073 \t val error: 2.1816\n",
      "Iteration 293: \t train loss: -0.9106 \t val error: 2.1812\n",
      "Iteration 294: \t train loss: -0.9139 \t val error: 2.1809\n",
      "Iteration 295: \t train loss: -0.9171 \t val error: 2.1805\n",
      "Iteration 296: \t train loss: -0.9204 \t val error: 2.1802\n",
      "Iteration 297: \t train loss: -0.9236 \t val error: 2.1799\n",
      "Iteration 298: \t train loss: -0.9268 \t val error: 2.1795\n",
      "Iteration 299: \t train loss: -0.9301 \t val error: 2.1792\n",
      "Iteration 300: \t train loss: -0.9333 \t val error: 2.1789\n",
      "Iteration 301: \t train loss: -0.9365 \t val error: 2.1785\n",
      "Iteration 302: \t train loss: -0.9397 \t val error: 2.1782\n",
      "Iteration 303: \t train loss: -0.9430 \t val error: 2.1773\n",
      "Iteration 304: \t train loss: -0.9462 \t val error: 2.1762\n",
      "Iteration 305: \t train loss: -0.9494 \t val error: 2.1751\n",
      "Iteration 306: \t train loss: -0.9526 \t val error: 2.1743\n",
      "Iteration 307: \t train loss: -0.9558 \t val error: 2.1735\n",
      "Iteration 308: \t train loss: -0.9589 \t val error: 2.1727\n",
      "Iteration 309: \t train loss: -0.9621 \t val error: 2.1719\n",
      "Iteration 310: \t train loss: -0.9653 \t val error: 2.1711\n",
      "Iteration 311: \t train loss: -0.9685 \t val error: 2.1710\n",
      "Iteration 312: \t train loss: -0.9716 \t val error: 2.1710\n",
      "Iteration 313: \t train loss: -0.9748 \t val error: 2.1722\n",
      "Iteration 314: \t train loss: -0.9779 \t val error: 2.1734\n",
      "Iteration 315: \t train loss: -0.9811 \t val error: 2.1746\n",
      "Iteration 316: \t train loss: -0.9842 \t val error: 2.1758\n",
      "Iteration 317: \t train loss: -0.9874 \t val error: 2.1770\n",
      "Iteration 318: \t train loss: -0.9905 \t val error: 2.1774\n",
      "Iteration 319: \t train loss: -0.9936 \t val error: 2.1774\n",
      "Iteration 320: \t train loss: -0.9968 \t val error: 2.1774\n",
      "Iteration 321: \t train loss: -0.9999 \t val error: 2.1774\n",
      "Iteration 322: \t train loss: -1.0030 \t val error: 2.1774\n",
      "Iteration 323: \t train loss: -1.0061 \t val error: 2.1774\n",
      "Iteration 324: \t train loss: -1.0092 \t val error: 2.1774\n",
      "Iteration 325: \t train loss: -1.0123 \t val error: 2.1774\n",
      "Iteration 326: \t train loss: -1.0154 \t val error: 2.1774\n",
      "Iteration 327: \t train loss: -1.0185 \t val error: 2.1774\n",
      "Iteration 328: \t train loss: -1.0215 \t val error: 2.1774\n",
      "Iteration 329: \t train loss: -1.0246 \t val error: 2.1774\n",
      "Iteration 330: \t train loss: -1.0277 \t val error: 2.1774\n",
      "Iteration 331: \t train loss: -1.0308 \t val error: 2.1774\n",
      "Iteration 332: \t train loss: -1.0338 \t val error: 2.1774\n",
      "Iteration 333: \t train loss: -1.0369 \t val error: 2.1848\n",
      "Iteration 334: \t train loss: -1.0399 \t val error: 2.1848\n",
      "Iteration 335: \t train loss: -1.0430 \t val error: 2.1848\n",
      "Iteration 336: \t train loss: -1.0460 \t val error: 2.1848\n",
      "Iteration 337: \t train loss: -1.0490 \t val error: 2.1848\n",
      "Iteration 338: \t train loss: -1.0521 \t val error: 2.1848\n",
      "Iteration 339: \t train loss: -1.0551 \t val error: 2.1848\n",
      "Iteration 340: \t train loss: -1.0581 \t val error: 2.1848\n",
      "Iteration 341: \t train loss: -1.0611 \t val error: 2.1848\n",
      "Iteration 342: \t train loss: -1.0641 \t val error: 2.1848\n",
      "Iteration 343: \t train loss: -1.0672 \t val error: 2.1848\n",
      "Iteration 344: \t train loss: -1.0702 \t val error: 2.1848\n",
      "Iteration 345: \t train loss: -1.0731 \t val error: 2.1848\n",
      "Iteration 346: \t train loss: -1.0761 \t val error: 2.1848\n",
      "Iteration 347: \t train loss: -1.0791 \t val error: 2.1848\n",
      "Iteration 348: \t train loss: -1.0821 \t val error: 2.1849\n",
      "Iteration 349: \t train loss: -1.0851 \t val error: 2.1855\n",
      "Iteration 350: \t train loss: -1.0880 \t val error: 2.1860\n",
      "Iteration 351: \t train loss: -1.0910 \t val error: 2.1865\n",
      "Iteration 352: \t train loss: -1.0940 \t val error: 2.1870\n",
      "Iteration 353: \t train loss: -1.0969 \t val error: 2.1875\n",
      "Iteration 354: \t train loss: -1.0999 \t val error: 2.1880\n",
      "Iteration 355: \t train loss: -1.1028 \t val error: 2.1885\n",
      "Iteration 356: \t train loss: -1.1058 \t val error: 2.1890\n",
      "Iteration 357: \t train loss: -1.1087 \t val error: 2.1895\n",
      "Iteration 358: \t train loss: -1.1116 \t val error: 2.1900\n",
      "Iteration 359: \t train loss: -1.1146 \t val error: 2.1905\n",
      "Iteration 360: \t train loss: -1.1175 \t val error: 2.1910\n",
      "Iteration 361: \t train loss: -1.1204 \t val error: 2.1913\n",
      "Iteration 362: \t train loss: -1.1233 \t val error: 2.1913\n",
      "Iteration 363: \t train loss: -1.1262 \t val error: 2.1913\n",
      "Iteration 364: \t train loss: -1.1291 \t val error: 2.1913\n",
      "Iteration 365: \t train loss: -1.1320 \t val error: 2.1913\n",
      "Iteration 366: \t train loss: -1.1349 \t val error: 2.1913\n",
      "Iteration 367: \t train loss: -1.1378 \t val error: 2.1913\n",
      "Iteration 368: \t train loss: -1.1407 \t val error: 2.1913\n",
      "Iteration 369: \t train loss: -1.1435 \t val error: 2.1913\n",
      "Iteration 370: \t train loss: -1.1464 \t val error: 2.1913\n",
      "Iteration 371: \t train loss: -1.1493 \t val error: 2.1913\n",
      "Iteration 372: \t train loss: -1.1521 \t val error: 2.1913\n",
      "Iteration 373: \t train loss: -1.1550 \t val error: 2.1913\n",
      "Iteration 374: \t train loss: -1.1579 \t val error: 2.1913\n",
      "Iteration 375: \t train loss: -1.1607 \t val error: 2.1913\n",
      "Iteration 376: \t train loss: -1.1636 \t val error: 2.1913\n",
      "Iteration 377: \t train loss: -1.1664 \t val error: 2.1913\n",
      "Iteration 378: \t train loss: -1.1692 \t val error: 2.1913\n",
      "Iteration 379: \t train loss: -1.1721 \t val error: 2.1913\n",
      "Iteration 380: \t train loss: -1.1749 \t val error: 2.1913\n",
      "Iteration 381: \t train loss: -1.1777 \t val error: 2.1911\n",
      "Iteration 382: \t train loss: -1.1805 \t val error: 2.1909\n",
      "Iteration 383: \t train loss: -1.1833 \t val error: 2.1907\n",
      "Iteration 384: \t train loss: -1.1861 \t val error: 2.1905\n",
      "Iteration 385: \t train loss: -1.1889 \t val error: 2.1905\n",
      "Iteration 386: \t train loss: -1.1917 \t val error: 2.1905\n",
      "Iteration 387: \t train loss: -1.1945 \t val error: 2.1905\n",
      "Iteration 388: \t train loss: -1.1973 \t val error: 2.1905\n",
      "Iteration 389: \t train loss: -1.2001 \t val error: 2.1905\n",
      "Iteration 390: \t train loss: -1.2029 \t val error: 2.1905\n",
      "Iteration 391: \t train loss: -1.2056 \t val error: 2.1905\n",
      "Iteration 392: \t train loss: -1.2084 \t val error: 2.1905\n",
      "Iteration 393: \t train loss: -1.2112 \t val error: 2.1904\n",
      "Iteration 394: \t train loss: -1.2139 \t val error: 2.1901\n",
      "Iteration 395: \t train loss: -1.2167 \t val error: 2.1898\n",
      "Iteration 396: \t train loss: -1.2194 \t val error: 2.1895\n",
      "Iteration 397: \t train loss: -1.2222 \t val error: 2.1891\n",
      "Iteration 398: \t train loss: -1.2249 \t val error: 2.1888\n",
      "Iteration 399: \t train loss: -1.2277 \t val error: 2.1885\n",
      "Iteration 400: \t train loss: -1.2304 \t val error: 2.1882\n",
      "Iteration 401: \t train loss: -1.2331 \t val error: 2.1878\n",
      "Iteration 402: \t train loss: -1.2358 \t val error: 2.1875\n",
      "Iteration 403: \t train loss: -1.2386 \t val error: 2.1872\n",
      "Iteration 404: \t train loss: -1.2413 \t val error: 2.1871\n",
      "Iteration 405: \t train loss: -1.2440 \t val error: 2.1871\n",
      "Iteration 406: \t train loss: -1.2467 \t val error: 2.1871\n",
      "Iteration 407: \t train loss: -1.2494 \t val error: 2.1871\n",
      "Iteration 408: \t train loss: -1.2521 \t val error: 2.1871\n",
      "Iteration 409: \t train loss: -1.2548 \t val error: 2.1871\n",
      "Iteration 410: \t train loss: -1.2575 \t val error: 2.1871\n",
      "Iteration 411: \t train loss: -1.2601 \t val error: 2.1871\n",
      "Iteration 412: \t train loss: -1.2628 \t val error: 2.1871\n",
      "Iteration 413: \t train loss: -1.2655 \t val error: 2.1871\n",
      "Iteration 414: \t train loss: -1.2682 \t val error: 2.1868\n",
      "Iteration 415: \t train loss: -1.2708 \t val error: 2.1862\n",
      "Iteration 416: \t train loss: -1.2735 \t val error: 2.1856\n",
      "Iteration 417: \t train loss: -1.2761 \t val error: 2.1850\n",
      "Iteration 418: \t train loss: -1.2788 \t val error: 2.1844\n",
      "Iteration 419: \t train loss: -1.2814 \t val error: 2.1837\n",
      "Iteration 420: \t train loss: -1.2841 \t val error: 2.1831\n",
      "Iteration 421: \t train loss: -1.2867 \t val error: 2.1827\n",
      "Iteration 422: \t train loss: -1.2894 \t val error: 2.1827\n",
      "Iteration 423: \t train loss: -1.2920 \t val error: 2.1827\n",
      "Iteration 424: \t train loss: -1.2946 \t val error: 2.1827\n",
      "Iteration 425: \t train loss: -1.2972 \t val error: 2.1833\n",
      "Iteration 426: \t train loss: -1.2998 \t val error: 2.1841\n",
      "Iteration 427: \t train loss: -1.3025 \t val error: 2.1848\n",
      "Iteration 428: \t train loss: -1.3051 \t val error: 2.1855\n",
      "Iteration 429: \t train loss: -1.3077 \t val error: 2.1863\n",
      "Iteration 430: \t train loss: -1.3103 \t val error: 2.1870\n",
      "Iteration 431: \t train loss: -1.3129 \t val error: 2.1871\n",
      "Iteration 432: \t train loss: -1.3155 \t val error: 2.1871\n",
      "Iteration 433: \t train loss: -1.3180 \t val error: 2.1871\n",
      "Iteration 434: \t train loss: -1.3206 \t val error: 2.1871\n",
      "Iteration 435: \t train loss: -1.3232 \t val error: 2.1871\n",
      "Iteration 436: \t train loss: -1.3258 \t val error: 2.1871\n",
      "Iteration 437: \t train loss: -1.3283 \t val error: 2.1871\n",
      "Iteration 438: \t train loss: -1.3309 \t val error: 2.1871\n",
      "Iteration 439: \t train loss: -1.3335 \t val error: 2.1871\n",
      "Iteration 440: \t train loss: -1.3360 \t val error: 2.1873\n",
      "Iteration 441: \t train loss: -1.3386 \t val error: 2.1876\n",
      "Iteration 442: \t train loss: -1.3411 \t val error: 2.1952\n",
      "Iteration 443: \t train loss: -1.3437 \t val error: 2.1954\n",
      "Iteration 444: \t train loss: -1.3462 \t val error: 2.1957\n",
      "Iteration 445: \t train loss: -1.3487 \t val error: 2.1959\n",
      "Iteration 446: \t train loss: -1.3513 \t val error: 2.1961\n",
      "Iteration 447: \t train loss: -1.3538 \t val error: 2.1964\n",
      "Iteration 448: \t train loss: -1.3563 \t val error: 2.1966\n",
      "Iteration 449: \t train loss: -1.3588 \t val error: 2.1969\n",
      "Iteration 450: \t train loss: -1.3613 \t val error: 2.1971\n",
      "Iteration 451: \t train loss: -1.3638 \t val error: 2.1973\n",
      "Iteration 452: \t train loss: -1.3663 \t val error: 2.1967\n",
      "Iteration 453: \t train loss: -1.3688 \t val error: 2.1953\n",
      "Iteration 454: \t train loss: -1.3713 \t val error: 2.1944\n",
      "Iteration 455: \t train loss: -1.3738 \t val error: 2.1944\n",
      "Iteration 456: \t train loss: -1.3763 \t val error: 2.1944\n",
      "Iteration 457: \t train loss: -1.3788 \t val error: 2.1944\n",
      "Iteration 458: \t train loss: -1.3813 \t val error: 2.1944\n",
      "Iteration 459: \t train loss: -1.3838 \t val error: 2.1944\n",
      "Iteration 460: \t train loss: -1.3862 \t val error: 2.1944\n",
      "Iteration 461: \t train loss: -1.3887 \t val error: 2.1944\n",
      "Iteration 462: \t train loss: -1.3912 \t val error: 2.1944\n",
      "Iteration 463: \t train loss: -1.3936 \t val error: 2.1944\n",
      "Iteration 464: \t train loss: -1.3961 \t val error: 2.1944\n",
      "Iteration 465: \t train loss: -1.3985 \t val error: 2.1944\n",
      "Iteration 466: \t train loss: -1.4010 \t val error: 2.1944\n",
      "Iteration 467: \t train loss: -1.4034 \t val error: 2.1944\n",
      "Iteration 468: \t train loss: -1.4058 \t val error: 2.1944\n",
      "Iteration 469: \t train loss: -1.4083 \t val error: 2.1944\n",
      "Iteration 470: \t train loss: -1.4107 \t val error: 2.1944\n",
      "Iteration 471: \t train loss: -1.4131 \t val error: 2.1944\n",
      "Iteration 472: \t train loss: -1.4156 \t val error: 2.1944\n",
      "Iteration 473: \t train loss: -1.4180 \t val error: 2.1944\n",
      "Iteration 474: \t train loss: -1.4204 \t val error: 2.1944\n",
      "Iteration 475: \t train loss: -1.4228 \t val error: 2.1944\n",
      "Iteration 476: \t train loss: -1.4252 \t val error: 2.1944\n",
      "Iteration 477: \t train loss: -1.4276 \t val error: 2.1944\n",
      "Iteration 478: \t train loss: -1.4300 \t val error: 2.1944\n",
      "Iteration 479: \t train loss: -1.4324 \t val error: 2.1944\n",
      "Iteration 480: \t train loss: -1.4348 \t val error: 2.1944\n",
      "Iteration 481: \t train loss: -1.4372 \t val error: 2.1944\n",
      "Iteration 482: \t train loss: -1.4395 \t val error: 2.1944\n",
      "Iteration 483: \t train loss: -1.4419 \t val error: 2.1944\n",
      "Iteration 484: \t train loss: -1.4443 \t val error: 2.1944\n",
      "Iteration 485: \t train loss: -1.4467 \t val error: 2.1944\n",
      "Iteration 486: \t train loss: -1.4490 \t val error: 2.1944\n",
      "Iteration 487: \t train loss: -1.4514 \t val error: 2.1944\n",
      "Iteration 488: \t train loss: -1.4538 \t val error: 2.1944\n",
      "Iteration 489: \t train loss: -1.4561 \t val error: 2.1944\n",
      "Iteration 490: \t train loss: -1.4585 \t val error: 2.1944\n",
      "Iteration 491: \t train loss: -1.4608 \t val error: 2.1944\n",
      "Iteration 492: \t train loss: -1.4631 \t val error: 2.1944\n",
      "Iteration 493: \t train loss: -1.4655 \t val error: 2.1944\n",
      "Iteration 494: \t train loss: -1.4678 \t val error: 2.1944\n",
      "Iteration 495: \t train loss: -1.4701 \t val error: 2.1944\n",
      "Iteration 496: \t train loss: -1.4725 \t val error: 2.1944\n",
      "Iteration 497: \t train loss: -1.4748 \t val error: 2.1944\n",
      "Iteration 498: \t train loss: -1.4771 \t val error: 2.1944\n",
      "Iteration 499: \t train loss: -1.4794 \t val error: 2.1944\n",
      "Iteration 500: \t train loss: -1.4817 \t val error: 2.1944\n",
      "Iteration 501: \t train loss: -1.4840 \t val error: 2.1944\n",
      "Iteration 502: \t train loss: -1.4863 \t val error: 2.1944\n",
      "Iteration 503: \t train loss: -1.4886 \t val error: 2.1944\n",
      "Iteration 504: \t train loss: -1.4909 \t val error: 2.1944\n",
      "Iteration 505: \t train loss: -1.4932 \t val error: 2.1944\n",
      "Iteration 506: \t train loss: -1.4955 \t val error: 2.1944\n",
      "Iteration 507: \t train loss: -1.4978 \t val error: 2.1944\n",
      "Iteration 508: \t train loss: -1.5001 \t val error: 2.1944\n",
      "Iteration 509: \t train loss: -1.5024 \t val error: 2.1944\n",
      "Iteration 510: \t train loss: -1.5046 \t val error: 2.1944\n",
      "Iteration 511: \t train loss: -1.5069 \t val error: 2.1944\n",
      "Iteration 512: \t train loss: -1.5092 \t val error: 2.1944\n",
      "Iteration 513: \t train loss: -1.5114 \t val error: 2.1944\n",
      "Iteration 514: \t train loss: -1.5137 \t val error: 2.1944\n",
      "Iteration 515: \t train loss: -1.5159 \t val error: 2.1944\n",
      "Iteration 516: \t train loss: -1.5182 \t val error: 2.1944\n",
      "Iteration 517: \t train loss: -1.5204 \t val error: 2.1944\n",
      "Iteration 518: \t train loss: -1.5227 \t val error: 2.1944\n",
      "Iteration 519: \t train loss: -1.5249 \t val error: 2.1944\n",
      "Iteration 520: \t train loss: -1.5271 \t val error: 2.1944\n",
      "Iteration 521: \t train loss: -1.5294 \t val error: 2.1944\n",
      "Iteration 522: \t train loss: -1.5316 \t val error: 2.1944\n",
      "Iteration 523: \t train loss: -1.5338 \t val error: 2.1944\n",
      "Iteration 524: \t train loss: -1.5360 \t val error: 2.1944\n",
      "Iteration 525: \t train loss: -1.5383 \t val error: 2.1944\n",
      "Iteration 526: \t train loss: -1.5405 \t val error: 2.1944\n",
      "Iteration 527: \t train loss: -1.5427 \t val error: 2.1944\n",
      "Iteration 528: \t train loss: -1.5449 \t val error: 2.1944\n",
      "Iteration 529: \t train loss: -1.5471 \t val error: 2.1944\n",
      "Iteration 530: \t train loss: -1.5493 \t val error: 2.1944\n",
      "Iteration 531: \t train loss: -1.5515 \t val error: 2.1944\n",
      "Iteration 532: \t train loss: -1.5537 \t val error: 2.1944\n",
      "Iteration 533: \t train loss: -1.5559 \t val error: 2.1944\n",
      "Iteration 534: \t train loss: -1.5580 \t val error: 2.1944\n",
      "Iteration 535: \t train loss: -1.5602 \t val error: 2.1944\n",
      "Iteration 536: \t train loss: -1.5624 \t val error: 2.1944\n",
      "Iteration 537: \t train loss: -1.5646 \t val error: 2.1944\n",
      "Iteration 538: \t train loss: -1.5667 \t val error: 2.1944\n",
      "Iteration 539: \t train loss: -1.5689 \t val error: 2.1944\n",
      "Iteration 540: \t train loss: -1.5711 \t val error: 2.1944\n",
      "Iteration 541: \t train loss: -1.5732 \t val error: 2.1944\n",
      "Iteration 542: \t train loss: -1.5754 \t val error: 2.1944\n",
      "Iteration 543: \t train loss: -1.5775 \t val error: 2.1944\n",
      "Iteration 544: \t train loss: -1.5797 \t val error: 2.1943\n",
      "Iteration 545: \t train loss: -1.5818 \t val error: 2.1943\n",
      "Iteration 546: \t train loss: -1.5839 \t val error: 2.1943\n",
      "Iteration 547: \t train loss: -1.5861 \t val error: 2.1943\n",
      "Iteration 548: \t train loss: -1.5882 \t val error: 2.1943\n",
      "Iteration 549: \t train loss: -1.5903 \t val error: 2.1943\n",
      "Iteration 550: \t train loss: -1.5925 \t val error: 2.1943\n",
      "Iteration 551: \t train loss: -1.5946 \t val error: 2.1943\n",
      "Iteration 552: \t train loss: -1.5967 \t val error: 2.1942\n",
      "Iteration 553: \t train loss: -1.5988 \t val error: 2.1942\n",
      "Iteration 554: \t train loss: -1.6009 \t val error: 2.1942\n",
      "Iteration 555: \t train loss: -1.6030 \t val error: 2.1942\n",
      "Iteration 556: \t train loss: -1.6051 \t val error: 2.1942\n",
      "Iteration 557: \t train loss: -1.6072 \t val error: 2.1942\n",
      "Iteration 558: \t train loss: -1.6093 \t val error: 2.1942\n",
      "Iteration 559: \t train loss: -1.6114 \t val error: 2.1942\n",
      "Iteration 560: \t train loss: -1.6135 \t val error: 2.1941\n",
      "Iteration 561: \t train loss: -1.6156 \t val error: 2.1941\n",
      "Iteration 562: \t train loss: -1.6177 \t val error: 2.1941\n",
      "Iteration 563: \t train loss: -1.6198 \t val error: 2.1941\n",
      "Iteration 564: \t train loss: -1.6218 \t val error: 2.1941\n",
      "Iteration 565: \t train loss: -1.6239 \t val error: 2.1941\n",
      "Iteration 566: \t train loss: -1.6260 \t val error: 2.1941\n",
      "Iteration 567: \t train loss: -1.6280 \t val error: 2.1941\n",
      "Iteration 568: \t train loss: -1.6301 \t val error: 2.1940\n",
      "Iteration 569: \t train loss: -1.6322 \t val error: 2.1940\n",
      "Iteration 570: \t train loss: -1.6342 \t val error: 2.1940\n",
      "Iteration 571: \t train loss: -1.6363 \t val error: 2.1940\n",
      "Iteration 572: \t train loss: -1.6383 \t val error: 2.1940\n",
      "Iteration 573: \t train loss: -1.6404 \t val error: 2.1940\n",
      "Iteration 574: \t train loss: -1.6424 \t val error: 2.1940\n",
      "Iteration 575: \t train loss: -1.6444 \t val error: 2.1940\n",
      "Iteration 576: \t train loss: -1.6465 \t val error: 2.1940\n",
      "Iteration 577: \t train loss: -1.6485 \t val error: 2.1939\n",
      "Iteration 578: \t train loss: -1.6505 \t val error: 2.1939\n",
      "Iteration 579: \t train loss: -1.6525 \t val error: 2.1939\n",
      "Iteration 580: \t train loss: -1.6546 \t val error: 2.1939\n",
      "Iteration 581: \t train loss: -1.6566 \t val error: 2.1939\n",
      "Iteration 582: \t train loss: -1.6586 \t val error: 2.1939\n",
      "Iteration 583: \t train loss: -1.6606 \t val error: 2.1939\n",
      "Iteration 584: \t train loss: -1.6626 \t val error: 2.1939\n",
      "Iteration 585: \t train loss: -1.6646 \t val error: 2.1939\n",
      "Iteration 586: \t train loss: -1.6666 \t val error: 2.1938\n",
      "Iteration 587: \t train loss: -1.6686 \t val error: 2.1938\n",
      "Iteration 588: \t train loss: -1.6706 \t val error: 2.1938\n",
      "Iteration 589: \t train loss: -1.6726 \t val error: 2.1938\n",
      "Iteration 590: \t train loss: -1.6746 \t val error: 2.1938\n",
      "Iteration 591: \t train loss: -1.6766 \t val error: 2.1938\n",
      "Iteration 592: \t train loss: -1.6786 \t val error: 2.1938\n",
      "Iteration 593: \t train loss: -1.6805 \t val error: 2.1938\n",
      "Iteration 594: \t train loss: -1.6825 \t val error: 2.1938\n",
      "Iteration 595: \t train loss: -1.6845 \t val error: 2.1937\n",
      "Iteration 596: \t train loss: -1.6864 \t val error: 2.1937\n",
      "Iteration 597: \t train loss: -1.6884 \t val error: 2.1937\n",
      "Iteration 598: \t train loss: -1.6904 \t val error: 2.1937\n",
      "Iteration 599: \t train loss: -1.6923 \t val error: 2.1937\n",
      "Iteration 600: \t train loss: -1.6943 \t val error: 2.1937\n",
      "Iteration 601: \t train loss: -1.6962 \t val error: 2.1937\n",
      "Iteration 602: \t train loss: -1.6982 \t val error: 2.1937\n",
      "Iteration 603: \t train loss: -1.7001 \t val error: 2.1937\n",
      "Iteration 604: \t train loss: -1.7021 \t val error: 2.1937\n",
      "Iteration 605: \t train loss: -1.7040 \t val error: 2.1936\n",
      "Iteration 606: \t train loss: -1.7059 \t val error: 2.1936\n",
      "Iteration 607: \t train loss: -1.7079 \t val error: 2.1936\n",
      "Iteration 608: \t train loss: -1.7098 \t val error: 2.1936\n",
      "Iteration 609: \t train loss: -1.7117 \t val error: 2.1936\n",
      "Iteration 610: \t train loss: -1.7136 \t val error: 2.1936\n",
      "Iteration 611: \t train loss: -1.7155 \t val error: 2.1936\n",
      "Iteration 612: \t train loss: -1.7175 \t val error: 2.1936\n",
      "Iteration 613: \t train loss: -1.7194 \t val error: 2.1936\n",
      "Iteration 614: \t train loss: -1.7213 \t val error: 2.1936\n",
      "Iteration 615: \t train loss: -1.7232 \t val error: 2.1935\n",
      "Iteration 616: \t train loss: -1.7251 \t val error: 2.1935\n",
      "Iteration 617: \t train loss: -1.7270 \t val error: 2.1935\n",
      "Iteration 618: \t train loss: -1.7289 \t val error: 2.1935\n",
      "Iteration 619: \t train loss: -1.7308 \t val error: 2.1935\n",
      "Iteration 620: \t train loss: -1.7327 \t val error: 2.1935\n",
      "Iteration 621: \t train loss: -1.7345 \t val error: 2.1935\n",
      "Iteration 622: \t train loss: -1.7364 \t val error: 2.1935\n",
      "Iteration 623: \t train loss: -1.7383 \t val error: 2.1935\n",
      "Iteration 624: \t train loss: -1.7402 \t val error: 2.1935\n",
      "Iteration 625: \t train loss: -1.7421 \t val error: 2.1934\n",
      "Iteration 626: \t train loss: -1.7439 \t val error: 2.1934\n",
      "Iteration 627: \t train loss: -1.7458 \t val error: 2.1934\n",
      "Iteration 628: \t train loss: -1.7477 \t val error: 2.1934\n",
      "Iteration 629: \t train loss: -1.7495 \t val error: 2.1934\n",
      "Iteration 630: \t train loss: -1.7514 \t val error: 2.1934\n",
      "Iteration 631: \t train loss: -1.7532 \t val error: 2.1934\n",
      "Iteration 632: \t train loss: -1.7551 \t val error: 2.1934\n",
      "Iteration 633: \t train loss: -1.7569 \t val error: 2.1934\n",
      "Iteration 634: \t train loss: -1.7588 \t val error: 2.1934\n",
      "Iteration 635: \t train loss: -1.7606 \t val error: 2.1934\n",
      "Iteration 636: \t train loss: -1.7625 \t val error: 2.1934\n",
      "Iteration 637: \t train loss: -1.7643 \t val error: 2.1933\n",
      "Iteration 638: \t train loss: -1.7661 \t val error: 2.1933\n",
      "Iteration 639: \t train loss: -1.7680 \t val error: 2.1933\n",
      "Iteration 640: \t train loss: -1.7698 \t val error: 2.1933\n",
      "Iteration 641: \t train loss: -1.7716 \t val error: 2.1933\n",
      "Iteration 642: \t train loss: -1.7734 \t val error: 2.1933\n",
      "Iteration 643: \t train loss: -1.7752 \t val error: 2.1933\n",
      "Iteration 644: \t train loss: -1.7771 \t val error: 2.1933\n",
      "Iteration 645: \t train loss: -1.7789 \t val error: 2.1933\n",
      "Iteration 646: \t train loss: -1.7807 \t val error: 2.1933\n",
      "Iteration 647: \t train loss: -1.7825 \t val error: 2.1933\n",
      "Iteration 648: \t train loss: -1.7843 \t val error: 2.1932\n",
      "Iteration 649: \t train loss: -1.7861 \t val error: 2.1932\n",
      "Iteration 650: \t train loss: -1.7879 \t val error: 2.1932\n",
      "Iteration 651: \t train loss: -1.7897 \t val error: 2.1932\n",
      "Iteration 652: \t train loss: -1.7915 \t val error: 2.1932\n",
      "Iteration 653: \t train loss: -1.7933 \t val error: 2.1932\n",
      "Iteration 654: \t train loss: -1.7950 \t val error: 2.1932\n",
      "Iteration 655: \t train loss: -1.7968 \t val error: 2.1932\n",
      "Iteration 656: \t train loss: -1.7986 \t val error: 2.1932\n",
      "Iteration 657: \t train loss: -1.8004 \t val error: 2.1932\n",
      "Iteration 658: \t train loss: -1.8021 \t val error: 2.1932\n",
      "Iteration 659: \t train loss: -1.8039 \t val error: 2.1932\n",
      "Iteration 660: \t train loss: -1.8057 \t val error: 2.1932\n",
      "Iteration 661: \t train loss: -1.8074 \t val error: 2.1931\n",
      "Iteration 662: \t train loss: -1.8092 \t val error: 2.1931\n",
      "Iteration 663: \t train loss: -1.8110 \t val error: 2.1931\n",
      "Iteration 664: \t train loss: -1.8127 \t val error: 2.1931\n",
      "Iteration 665: \t train loss: -1.8145 \t val error: 2.1931\n",
      "Iteration 666: \t train loss: -1.8162 \t val error: 2.1931\n",
      "Iteration 667: \t train loss: -1.8180 \t val error: 2.1931\n",
      "Iteration 668: \t train loss: -1.8197 \t val error: 2.1931\n",
      "Iteration 669: \t train loss: -1.8214 \t val error: 2.1857\n",
      "Iteration 670: \t train loss: -1.8232 \t val error: 2.1857\n",
      "Iteration 671: \t train loss: -1.8249 \t val error: 2.1857\n",
      "Iteration 672: \t train loss: -1.8266 \t val error: 2.1857\n",
      "Iteration 673: \t train loss: -1.8284 \t val error: 2.1857\n",
      "Iteration 674: \t train loss: -1.8301 \t val error: 2.1857\n",
      "Iteration 675: \t train loss: -1.8318 \t val error: 2.1857\n",
      "Iteration 676: \t train loss: -1.8335 \t val error: 2.1857\n",
      "Iteration 677: \t train loss: -1.8353 \t val error: 2.1857\n",
      "Iteration 678: \t train loss: -1.8370 \t val error: 2.1857\n",
      "Iteration 679: \t train loss: -1.8387 \t val error: 2.1857\n",
      "Iteration 680: \t train loss: -1.8404 \t val error: 2.1856\n",
      "Iteration 681: \t train loss: -1.8421 \t val error: 2.1856\n",
      "Iteration 682: \t train loss: -1.8438 \t val error: 2.1856\n",
      "Iteration 683: \t train loss: -1.8455 \t val error: 2.1856\n",
      "Iteration 684: \t train loss: -1.8472 \t val error: 2.1856\n",
      "Iteration 685: \t train loss: -1.8489 \t val error: 2.1856\n",
      "Iteration 686: \t train loss: -1.8506 \t val error: 2.1856\n",
      "Iteration 687: \t train loss: -1.8523 \t val error: 2.1856\n",
      "Iteration 688: \t train loss: -1.8540 \t val error: 2.1856\n",
      "Iteration 689: \t train loss: -1.8556 \t val error: 2.1856\n",
      "Iteration 690: \t train loss: -1.8573 \t val error: 2.1856\n",
      "Iteration 691: \t train loss: -1.8590 \t val error: 2.1856\n",
      "Iteration 692: \t train loss: -1.8607 \t val error: 2.1856\n",
      "Iteration 693: \t train loss: -1.8623 \t val error: 2.1856\n",
      "Iteration 694: \t train loss: -1.8640 \t val error: 2.1855\n",
      "Iteration 695: \t train loss: -1.8657 \t val error: 2.1855\n",
      "Iteration 696: \t train loss: -1.8673 \t val error: 2.1855\n",
      "Iteration 697: \t train loss: -1.8690 \t val error: 2.1855\n",
      "Iteration 698: \t train loss: -1.8707 \t val error: 2.1855\n",
      "Iteration 699: \t train loss: -1.8723 \t val error: 2.1855\n",
      "Iteration 700: \t train loss: -1.8740 \t val error: 2.1855\n",
      "Iteration 701: \t train loss: -1.8756 \t val error: 2.1855\n",
      "Iteration 702: \t train loss: -1.8773 \t val error: 2.1855\n",
      "Iteration 703: \t train loss: -1.8789 \t val error: 2.1855\n",
      "Iteration 704: \t train loss: -1.8805 \t val error: 2.1855\n",
      "Iteration 705: \t train loss: -1.8822 \t val error: 2.1855\n",
      "Iteration 706: \t train loss: -1.8838 \t val error: 2.1855\n",
      "Iteration 707: \t train loss: -1.8854 \t val error: 2.1855\n",
      "Iteration 708: \t train loss: -1.8871 \t val error: 2.1855\n",
      "Iteration 709: \t train loss: -1.8887 \t val error: 2.1855\n",
      "Iteration 710: \t train loss: -1.8903 \t val error: 2.1854\n",
      "Iteration 711: \t train loss: -1.8919 \t val error: 2.1854\n",
      "Iteration 712: \t train loss: -1.8936 \t val error: 2.1854\n",
      "Iteration 713: \t train loss: -1.8952 \t val error: 2.1854\n",
      "Iteration 714: \t train loss: -1.8968 \t val error: 2.1854\n",
      "Iteration 715: \t train loss: -1.8984 \t val error: 2.1854\n",
      "Iteration 716: \t train loss: -1.9000 \t val error: 2.1854\n",
      "Iteration 717: \t train loss: -1.9016 \t val error: 2.1854\n",
      "Iteration 718: \t train loss: -1.9032 \t val error: 2.1854\n",
      "Iteration 719: \t train loss: -1.9048 \t val error: 2.1854\n",
      "Iteration 720: \t train loss: -1.9064 \t val error: 2.1854\n",
      "Iteration 721: \t train loss: -1.9080 \t val error: 2.1854\n",
      "Iteration 722: \t train loss: -1.9096 \t val error: 2.1854\n",
      "Iteration 723: \t train loss: -1.9112 \t val error: 2.1854\n",
      "Iteration 724: \t train loss: -1.9128 \t val error: 2.1854\n",
      "Iteration 725: \t train loss: -1.9144 \t val error: 2.1854\n",
      "Iteration 726: \t train loss: -1.9159 \t val error: 2.1854\n",
      "Iteration 727: \t train loss: -1.9175 \t val error: 2.1853\n",
      "Iteration 728: \t train loss: -1.9191 \t val error: 2.1853\n",
      "Iteration 729: \t train loss: -1.9207 \t val error: 2.1853\n",
      "Iteration 730: \t train loss: -1.9222 \t val error: 2.1853\n",
      "Iteration 731: \t train loss: -1.9238 \t val error: 2.1853\n",
      "Iteration 732: \t train loss: -1.9254 \t val error: 2.1853\n",
      "Iteration 733: \t train loss: -1.9269 \t val error: 2.1853\n",
      "Iteration 734: \t train loss: -1.9285 \t val error: 2.1853\n",
      "Iteration 735: \t train loss: -1.9301 \t val error: 2.1853\n",
      "Iteration 736: \t train loss: -1.9316 \t val error: 2.1853\n",
      "Iteration 737: \t train loss: -1.9332 \t val error: 2.1853\n",
      "Iteration 738: \t train loss: -1.9347 \t val error: 2.1853\n",
      "Iteration 739: \t train loss: -1.9363 \t val error: 2.1853\n",
      "Iteration 740: \t train loss: -1.9378 \t val error: 2.1853\n",
      "Iteration 741: \t train loss: -1.9393 \t val error: 2.1853\n",
      "Iteration 742: \t train loss: -1.9409 \t val error: 2.1853\n",
      "Iteration 743: \t train loss: -1.9424 \t val error: 2.1853\n",
      "Iteration 744: \t train loss: -1.9440 \t val error: 2.1853\n",
      "Iteration 745: \t train loss: -1.9455 \t val error: 2.1852\n",
      "Iteration 746: \t train loss: -1.9470 \t val error: 2.1852\n",
      "Iteration 747: \t train loss: -1.9485 \t val error: 2.1852\n",
      "Iteration 748: \t train loss: -1.9501 \t val error: 2.1852\n",
      "Iteration 749: \t train loss: -1.9516 \t val error: 2.1852\n",
      "Iteration 750: \t train loss: -1.9531 \t val error: 2.1852\n",
      "Iteration 751: \t train loss: -1.9546 \t val error: 2.1852\n",
      "Iteration 752: \t train loss: -1.9561 \t val error: 2.1852\n",
      "Iteration 753: \t train loss: -1.9576 \t val error: 2.1852\n",
      "Iteration 754: \t train loss: -1.9591 \t val error: 2.1852\n",
      "Iteration 755: \t train loss: -1.9607 \t val error: 2.1852\n",
      "Iteration 756: \t train loss: -1.9622 \t val error: 2.1852\n",
      "Iteration 757: \t train loss: -1.9637 \t val error: 2.1852\n",
      "Iteration 758: \t train loss: -1.9652 \t val error: 2.1852\n",
      "Iteration 759: \t train loss: -1.9667 \t val error: 2.1852\n",
      "Iteration 760: \t train loss: -1.9681 \t val error: 2.1852\n",
      "Iteration 761: \t train loss: -1.9696 \t val error: 2.1852\n",
      "Iteration 762: \t train loss: -1.9711 \t val error: 2.1852\n",
      "Iteration 763: \t train loss: -1.9726 \t val error: 2.1852\n",
      "Iteration 764: \t train loss: -1.9741 \t val error: 2.1852\n",
      "Iteration 765: \t train loss: -1.9756 \t val error: 2.1852\n",
      "Iteration 766: \t train loss: -1.9771 \t val error: 2.1851\n",
      "Iteration 767: \t train loss: -1.9785 \t val error: 2.1851\n",
      "Iteration 768: \t train loss: -1.9800 \t val error: 2.1851\n",
      "Iteration 769: \t train loss: -1.9815 \t val error: 2.1851\n",
      "Iteration 770: \t train loss: -1.9829 \t val error: 2.1851\n",
      "Iteration 771: \t train loss: -1.9844 \t val error: 2.1851\n",
      "Iteration 772: \t train loss: -1.9859 \t val error: 2.1851\n",
      "Iteration 773: \t train loss: -1.9873 \t val error: 2.1851\n",
      "Iteration 774: \t train loss: -1.9888 \t val error: 2.1851\n",
      "Iteration 775: \t train loss: -1.9903 \t val error: 2.1851\n",
      "Iteration 776: \t train loss: -1.9917 \t val error: 2.1851\n",
      "Iteration 777: \t train loss: -1.9932 \t val error: 2.1851\n",
      "Iteration 778: \t train loss: -1.9946 \t val error: 2.1851\n",
      "Iteration 779: \t train loss: -1.9961 \t val error: 2.1851\n",
      "Iteration 780: \t train loss: -1.9975 \t val error: 2.1851\n",
      "Iteration 781: \t train loss: -1.9989 \t val error: 2.1851\n",
      "Iteration 782: \t train loss: -2.0004 \t val error: 2.1851\n",
      "Iteration 783: \t train loss: -2.0018 \t val error: 2.1851\n",
      "Iteration 784: \t train loss: -2.0032 \t val error: 2.1851\n",
      "Iteration 785: \t train loss: -2.0047 \t val error: 2.1851\n",
      "Iteration 786: \t train loss: -2.0061 \t val error: 2.1851\n",
      "Iteration 787: \t train loss: -2.0075 \t val error: 2.1851\n",
      "Iteration 788: \t train loss: -2.0090 \t val error: 2.1851\n",
      "Iteration 789: \t train loss: -2.0104 \t val error: 2.1850\n",
      "Iteration 790: \t train loss: -2.0118 \t val error: 2.1850\n",
      "Iteration 791: \t train loss: -2.0132 \t val error: 2.1850\n",
      "Iteration 792: \t train loss: -2.0146 \t val error: 2.1850\n",
      "Iteration 793: \t train loss: -2.0161 \t val error: 2.1850\n",
      "Iteration 794: \t train loss: -2.0175 \t val error: 2.1850\n",
      "Iteration 795: \t train loss: -2.0189 \t val error: 2.1850\n",
      "Iteration 796: \t train loss: -2.0203 \t val error: 2.1850\n",
      "Iteration 797: \t train loss: -2.0217 \t val error: 2.1850\n",
      "Iteration 798: \t train loss: -2.0231 \t val error: 2.1850\n",
      "Iteration 799: \t train loss: -2.0245 \t val error: 2.1850\n",
      "Iteration 800: \t train loss: -2.0259 \t val error: 2.1850\n",
      "Iteration 801: \t train loss: -2.0273 \t val error: 2.1850\n",
      "Iteration 802: \t train loss: -2.0287 \t val error: 2.1850\n",
      "Iteration 803: \t train loss: -2.0301 \t val error: 2.1850\n",
      "Iteration 804: \t train loss: -2.0314 \t val error: 2.1850\n",
      "Iteration 805: \t train loss: -2.0328 \t val error: 2.1850\n",
      "Iteration 806: \t train loss: -2.0342 \t val error: 2.1850\n",
      "Iteration 807: \t train loss: -2.0356 \t val error: 2.1850\n",
      "Iteration 808: \t train loss: -2.0370 \t val error: 2.1850\n",
      "Iteration 809: \t train loss: -2.0383 \t val error: 2.1850\n",
      "Iteration 810: \t train loss: -2.0397 \t val error: 2.1850\n",
      "Iteration 811: \t train loss: -2.0411 \t val error: 2.1850\n",
      "Iteration 812: \t train loss: -2.0425 \t val error: 2.1850\n",
      "Iteration 813: \t train loss: -2.0438 \t val error: 2.1850\n",
      "Iteration 814: \t train loss: -2.0452 \t val error: 2.1850\n",
      "Iteration 815: \t train loss: -2.0465 \t val error: 2.1850\n",
      "Iteration 816: \t train loss: -2.0479 \t val error: 2.1849\n",
      "Iteration 817: \t train loss: -2.0493 \t val error: 2.1849\n",
      "Iteration 818: \t train loss: -2.0506 \t val error: 2.1849\n",
      "Iteration 819: \t train loss: -2.0520 \t val error: 2.1849\n",
      "Iteration 820: \t train loss: -2.0533 \t val error: 2.1849\n",
      "Iteration 821: \t train loss: -2.0547 \t val error: 2.1849\n",
      "Iteration 822: \t train loss: -2.0560 \t val error: 2.1849\n",
      "Iteration 823: \t train loss: -2.0574 \t val error: 2.1849\n",
      "Iteration 824: \t train loss: -2.0587 \t val error: 2.1849\n",
      "Iteration 825: \t train loss: -2.0600 \t val error: 2.1849\n",
      "Iteration 826: \t train loss: -2.0614 \t val error: 2.1848\n",
      "Iteration 827: \t train loss: -2.0627 \t val error: 2.1848\n",
      "Iteration 828: \t train loss: -2.0640 \t val error: 2.1848\n",
      "Iteration 829: \t train loss: -2.0654 \t val error: 2.1848\n",
      "Iteration 830: \t train loss: -2.0667 \t val error: 2.1847\n",
      "Iteration 831: \t train loss: -2.0680 \t val error: 2.1847\n",
      "Iteration 832: \t train loss: -2.0693 \t val error: 2.1847\n",
      "Iteration 833: \t train loss: -2.0707 \t val error: 2.1847\n",
      "Iteration 834: \t train loss: -2.0720 \t val error: 2.1847\n",
      "Iteration 835: \t train loss: -2.0733 \t val error: 2.1846\n",
      "Iteration 836: \t train loss: -2.0746 \t val error: 2.1846\n",
      "Iteration 837: \t train loss: -2.0759 \t val error: 2.1846\n",
      "Iteration 838: \t train loss: -2.0772 \t val error: 2.1846\n",
      "Iteration 839: \t train loss: -2.0786 \t val error: 2.1846\n",
      "Iteration 840: \t train loss: -2.0799 \t val error: 2.1845\n",
      "Iteration 841: \t train loss: -2.0812 \t val error: 2.1845\n",
      "Iteration 842: \t train loss: -2.0825 \t val error: 2.1845\n",
      "Iteration 843: \t train loss: -2.0838 \t val error: 2.1845\n",
      "Iteration 844: \t train loss: -2.0851 \t val error: 2.1844\n",
      "Iteration 845: \t train loss: -2.0864 \t val error: 2.1844\n",
      "Iteration 846: \t train loss: -2.0876 \t val error: 2.1844\n",
      "Iteration 847: \t train loss: -2.0889 \t val error: 2.1844\n",
      "Iteration 848: \t train loss: -2.0902 \t val error: 2.1844\n",
      "Iteration 849: \t train loss: -2.0915 \t val error: 2.1843\n",
      "Iteration 850: \t train loss: -2.0928 \t val error: 2.1843\n",
      "Iteration 851: \t train loss: -2.0941 \t val error: 2.1843\n",
      "Iteration 852: \t train loss: -2.0954 \t val error: 2.1843\n",
      "Iteration 853: \t train loss: -2.0966 \t val error: 2.1843\n",
      "Iteration 854: \t train loss: -2.0979 \t val error: 2.1842\n",
      "Iteration 855: \t train loss: -2.0992 \t val error: 2.1842\n",
      "Iteration 856: \t train loss: -2.1005 \t val error: 2.1842\n",
      "Iteration 857: \t train loss: -2.1017 \t val error: 2.1842\n",
      "Iteration 858: \t train loss: -2.1030 \t val error: 2.1841\n",
      "Iteration 859: \t train loss: -2.1043 \t val error: 2.1841\n",
      "Iteration 860: \t train loss: -2.1055 \t val error: 2.1841\n",
      "Iteration 861: \t train loss: -2.1068 \t val error: 2.1841\n",
      "Iteration 862: \t train loss: -2.1080 \t val error: 2.1841\n",
      "Iteration 863: \t train loss: -2.1093 \t val error: 2.1841\n",
      "Iteration 864: \t train loss: -2.1105 \t val error: 2.1841\n",
      "Iteration 865: \t train loss: -2.1118 \t val error: 2.1841\n",
      "Iteration 866: \t train loss: -2.1131 \t val error: 2.1840\n",
      "Iteration 867: \t train loss: -2.1143 \t val error: 2.1840\n",
      "Iteration 868: \t train loss: -2.1155 \t val error: 2.1840\n",
      "Iteration 869: \t train loss: -2.1168 \t val error: 2.1840\n",
      "Iteration 870: \t train loss: -2.1180 \t val error: 2.1840\n",
      "Iteration 871: \t train loss: -2.1193 \t val error: 2.1840\n",
      "Iteration 872: \t train loss: -2.1205 \t val error: 2.1840\n",
      "Iteration 873: \t train loss: -2.1217 \t val error: 2.1840\n",
      "Iteration 874: \t train loss: -2.1230 \t val error: 2.1840\n",
      "Iteration 875: \t train loss: -2.1242 \t val error: 2.1840\n",
      "Iteration 876: \t train loss: -2.1254 \t val error: 2.1840\n",
      "Iteration 877: \t train loss: -2.1267 \t val error: 2.1840\n",
      "Iteration 878: \t train loss: -2.1279 \t val error: 2.1840\n",
      "Iteration 879: \t train loss: -2.1291 \t val error: 2.1914\n",
      "Iteration 880: \t train loss: -2.1303 \t val error: 2.1914\n",
      "Iteration 881: \t train loss: -2.1316 \t val error: 2.1914\n",
      "Iteration 882: \t train loss: -2.1328 \t val error: 2.1914\n",
      "Iteration 883: \t train loss: -2.1340 \t val error: 2.1914\n",
      "Iteration 884: \t train loss: -2.1352 \t val error: 2.1914\n",
      "Iteration 885: \t train loss: -2.1364 \t val error: 2.1914\n",
      "Iteration 886: \t train loss: -2.1376 \t val error: 2.1914\n",
      "Iteration 887: \t train loss: -2.1388 \t val error: 2.1914\n",
      "Iteration 888: \t train loss: -2.1400 \t val error: 2.1914\n",
      "Iteration 889: \t train loss: -2.1412 \t val error: 2.1914\n",
      "Iteration 890: \t train loss: -2.1424 \t val error: 2.1913\n",
      "Iteration 891: \t train loss: -2.1436 \t val error: 2.1913\n",
      "Iteration 892: \t train loss: -2.1448 \t val error: 2.1913\n",
      "Iteration 893: \t train loss: -2.1460 \t val error: 2.1913\n",
      "Iteration 894: \t train loss: -2.1472 \t val error: 2.1913\n",
      "Iteration 895: \t train loss: -2.1484 \t val error: 2.1913\n",
      "Iteration 896: \t train loss: -2.1496 \t val error: 2.1913\n",
      "Iteration 897: \t train loss: -2.1508 \t val error: 2.1913\n",
      "Iteration 898: \t train loss: -2.1520 \t val error: 2.1913\n",
      "Iteration 899: \t train loss: -2.1532 \t val error: 2.1913\n",
      "Iteration 900: \t train loss: -2.1543 \t val error: 2.1913\n",
      "Iteration 901: \t train loss: -2.1555 \t val error: 2.1913\n",
      "Iteration 902: \t train loss: -2.1567 \t val error: 2.1913\n",
      "Iteration 903: \t train loss: -2.1579 \t val error: 2.1913\n",
      "Iteration 904: \t train loss: -2.1590 \t val error: 2.1913\n",
      "Iteration 905: \t train loss: -2.1602 \t val error: 2.1913\n",
      "Iteration 906: \t train loss: -2.1614 \t val error: 2.1913\n",
      "Iteration 907: \t train loss: -2.1625 \t val error: 2.1913\n",
      "Iteration 908: \t train loss: -2.1637 \t val error: 2.1913\n",
      "Iteration 909: \t train loss: -2.1649 \t val error: 2.1913\n",
      "Iteration 910: \t train loss: -2.1660 \t val error: 2.1913\n",
      "Iteration 911: \t train loss: -2.1672 \t val error: 2.1913\n",
      "Iteration 912: \t train loss: -2.1684 \t val error: 2.1913\n",
      "Iteration 913: \t train loss: -2.1695 \t val error: 2.1913\n",
      "Iteration 914: \t train loss: -2.1707 \t val error: 2.1913\n",
      "Iteration 915: \t train loss: -2.1718 \t val error: 2.1913\n",
      "Iteration 916: \t train loss: -2.1730 \t val error: 2.1913\n",
      "Iteration 917: \t train loss: -2.1741 \t val error: 2.1913\n",
      "Iteration 918: \t train loss: -2.1753 \t val error: 2.1913\n",
      "Iteration 919: \t train loss: -2.1764 \t val error: 2.1913\n",
      "Iteration 920: \t train loss: -2.1775 \t val error: 2.1913\n",
      "Iteration 921: \t train loss: -2.1787 \t val error: 2.1913\n",
      "Iteration 922: \t train loss: -2.1798 \t val error: 2.1913\n",
      "Iteration 923: \t train loss: -2.1810 \t val error: 2.1913\n",
      "Iteration 924: \t train loss: -2.1821 \t val error: 2.1913\n",
      "Iteration 925: \t train loss: -2.1832 \t val error: 2.1915\n",
      "Iteration 926: \t train loss: -2.1844 \t val error: 2.1918\n",
      "Iteration 927: \t train loss: -2.1855 \t val error: 2.1921\n",
      "Iteration 928: \t train loss: -2.1866 \t val error: 2.1925\n",
      "Iteration 929: \t train loss: -2.1877 \t val error: 2.1928\n",
      "Iteration 930: \t train loss: -2.1889 \t val error: 2.1931\n",
      "Iteration 931: \t train loss: -2.1900 \t val error: 2.1934\n",
      "Iteration 932: \t train loss: -2.1911 \t val error: 2.1937\n",
      "Iteration 933: \t train loss: -2.1922 \t val error: 2.1940\n",
      "Iteration 934: \t train loss: -2.1933 \t val error: 2.1943\n",
      "Iteration 935: \t train loss: -2.1944 \t val error: 2.1946\n",
      "Iteration 936: \t train loss: -2.1956 \t val error: 2.1949\n",
      "Iteration 937: \t train loss: -2.1967 \t val error: 2.1952\n",
      "Iteration 938: \t train loss: -2.1978 \t val error: 2.1955\n",
      "Iteration 939: \t train loss: -2.1989 \t val error: 2.1956\n",
      "Iteration 940: \t train loss: -2.2000 \t val error: 2.1956\n",
      "Iteration 941: \t train loss: -2.2011 \t val error: 2.1956\n",
      "Iteration 942: \t train loss: -2.2022 \t val error: 2.1956\n",
      "Iteration 943: \t train loss: -2.2033 \t val error: 2.1956\n",
      "Iteration 944: \t train loss: -2.2044 \t val error: 2.1956\n",
      "Iteration 945: \t train loss: -2.2055 \t val error: 2.1956\n",
      "Iteration 946: \t train loss: -2.2066 \t val error: 2.1956\n",
      "Iteration 947: \t train loss: -2.2077 \t val error: 2.1956\n",
      "Iteration 948: \t train loss: -2.2088 \t val error: 2.1956\n",
      "Iteration 949: \t train loss: -2.2098 \t val error: 2.1956\n",
      "Iteration 950: \t train loss: -2.2109 \t val error: 2.1956\n",
      "Iteration 951: \t train loss: -2.2120 \t val error: 2.1956\n",
      "Iteration 952: \t train loss: -2.2131 \t val error: 2.1956\n",
      "Iteration 953: \t train loss: -2.2142 \t val error: 2.1956\n",
      "Iteration 954: \t train loss: -2.2153 \t val error: 2.1956\n",
      "Iteration 955: \t train loss: -2.2163 \t val error: 2.1956\n",
      "Iteration 956: \t train loss: -2.2174 \t val error: 2.1956\n",
      "Iteration 957: \t train loss: -2.2185 \t val error: 2.1956\n",
      "Iteration 958: \t train loss: -2.2196 \t val error: 2.1956\n",
      "Iteration 959: \t train loss: -2.2206 \t val error: 2.1956\n",
      "Iteration 960: \t train loss: -2.2217 \t val error: 2.1956\n",
      "Iteration 961: \t train loss: -2.2228 \t val error: 2.1956\n",
      "Iteration 962: \t train loss: -2.2238 \t val error: 2.1956\n",
      "Iteration 963: \t train loss: -2.2249 \t val error: 2.1956\n",
      "Iteration 964: \t train loss: -2.2259 \t val error: 2.1956\n",
      "Iteration 965: \t train loss: -2.2270 \t val error: 2.1956\n",
      "Iteration 966: \t train loss: -2.2281 \t val error: 2.1956\n",
      "Iteration 967: \t train loss: -2.2291 \t val error: 2.1956\n",
      "Iteration 968: \t train loss: -2.2302 \t val error: 2.1956\n",
      "Iteration 969: \t train loss: -2.2312 \t val error: 2.1956\n",
      "Iteration 970: \t train loss: -2.2323 \t val error: 2.1956\n",
      "Iteration 971: \t train loss: -2.2333 \t val error: 2.1956\n",
      "Iteration 972: \t train loss: -2.2344 \t val error: 2.1956\n",
      "Iteration 973: \t train loss: -2.2354 \t val error: 2.1956\n",
      "Iteration 974: \t train loss: -2.2365 \t val error: 2.1956\n",
      "Iteration 975: \t train loss: -2.2375 \t val error: 2.1956\n",
      "Iteration 976: \t train loss: -2.2385 \t val error: 2.1956\n",
      "Iteration 977: \t train loss: -2.2396 \t val error: 2.1956\n",
      "Iteration 978: \t train loss: -2.2406 \t val error: 2.1956\n",
      "Iteration 979: \t train loss: -2.2417 \t val error: 2.1956\n",
      "Iteration 980: \t train loss: -2.2427 \t val error: 2.1956\n",
      "Iteration 981: \t train loss: -2.2437 \t val error: 2.1956\n",
      "Iteration 982: \t train loss: -2.2447 \t val error: 2.1956\n",
      "Iteration 983: \t train loss: -2.2458 \t val error: 2.1956\n",
      "Iteration 984: \t train loss: -2.2468 \t val error: 2.1956\n",
      "Iteration 985: \t train loss: -2.2478 \t val error: 2.1956\n",
      "Iteration 986: \t train loss: -2.2488 \t val error: 2.1956\n",
      "Iteration 987: \t train loss: -2.2499 \t val error: 2.1955\n",
      "Iteration 988: \t train loss: -2.2509 \t val error: 2.1955\n",
      "Iteration 989: \t train loss: -2.2519 \t val error: 2.1955\n",
      "Iteration 990: \t train loss: -2.2529 \t val error: 2.1955\n",
      "Iteration 991: \t train loss: -2.2539 \t val error: 2.1955\n",
      "Iteration 992: \t train loss: -2.2549 \t val error: 2.1955\n",
      "Iteration 993: \t train loss: -2.2560 \t val error: 2.1955\n",
      "Iteration 994: \t train loss: -2.2570 \t val error: 2.1955\n",
      "Iteration 995: \t train loss: -2.2580 \t val error: 2.1955\n",
      "Iteration 996: \t train loss: -2.2590 \t val error: 2.1955\n",
      "Iteration 997: \t train loss: -2.2600 \t val error: 2.1955\n",
      "Iteration 998: \t train loss: -2.2610 \t val error: 2.1955\n",
      "Iteration 999: \t train loss: -2.2620 \t val error: 2.1955\n",
      "Iteration 1000: \t train loss: -2.2630 \t val error: 2.1955\n",
      "Iteration 1001: \t train loss: -2.2640 \t val error: 2.1955\n",
      "Iteration 1002: \t train loss: -2.2650 \t val error: 2.1955\n",
      "Iteration 1003: \t train loss: -2.2660 \t val error: 2.1955\n",
      "Iteration 1004: \t train loss: -2.2670 \t val error: 2.1955\n",
      "Iteration 1005: \t train loss: -2.2680 \t val error: 2.1955\n",
      "Iteration 1006: \t train loss: -2.2689 \t val error: 2.1955\n",
      "Iteration 1007: \t train loss: -2.2699 \t val error: 2.1955\n",
      "Iteration 1008: \t train loss: -2.2709 \t val error: 2.1955\n",
      "Iteration 1009: \t train loss: -2.2719 \t val error: 2.1955\n",
      "Iteration 1010: \t train loss: -2.2729 \t val error: 2.1955\n",
      "Iteration 1011: \t train loss: -2.2739 \t val error: 2.1955\n",
      "Iteration 1012: \t train loss: -2.2748 \t val error: 2.1955\n",
      "Iteration 1013: \t train loss: -2.2758 \t val error: 2.1955\n",
      "Iteration 1014: \t train loss: -2.2768 \t val error: 2.1955\n",
      "Iteration 1015: \t train loss: -2.2778 \t val error: 2.1955\n",
      "Iteration 1016: \t train loss: -2.2787 \t val error: 2.1955\n",
      "Iteration 1017: \t train loss: -2.2797 \t val error: 2.1955\n",
      "Iteration 1018: \t train loss: -2.2807 \t val error: 2.1955\n",
      "Iteration 1019: \t train loss: -2.2817 \t val error: 2.1955\n",
      "Iteration 1020: \t train loss: -2.2826 \t val error: 2.1955\n",
      "Iteration 1021: \t train loss: -2.2836 \t val error: 2.1955\n",
      "Iteration 1022: \t train loss: -2.2845 \t val error: 2.1955\n",
      "Iteration 1023: \t train loss: -2.2855 \t val error: 2.1955\n",
      "Iteration 1024: \t train loss: -2.2865 \t val error: 2.1955\n",
      "Iteration 1025: \t train loss: -2.2874 \t val error: 2.1955\n",
      "Iteration 1026: \t train loss: -2.2884 \t val error: 2.1953\n",
      "Iteration 1027: \t train loss: -2.2893 \t val error: 2.1951\n",
      "Iteration 1028: \t train loss: -2.2903 \t val error: 2.1950\n",
      "Iteration 1029: \t train loss: -2.2912 \t val error: 2.1948\n",
      "Iteration 1030: \t train loss: -2.2922 \t val error: 2.1947\n",
      "Iteration 1031: \t train loss: -2.2931 \t val error: 2.1945\n",
      "Iteration 1032: \t train loss: -2.2941 \t val error: 2.1943\n",
      "Iteration 1033: \t train loss: -2.2950 \t val error: 2.1942\n",
      "Iteration 1034: \t train loss: -2.2960 \t val error: 2.1940\n",
      "Iteration 1035: \t train loss: -2.2969 \t val error: 2.1939\n",
      "Iteration 1036: \t train loss: -2.2979 \t val error: 2.1937\n",
      "Iteration 1037: \t train loss: -2.2988 \t val error: 2.1935\n",
      "Iteration 1038: \t train loss: -2.2997 \t val error: 2.1934\n",
      "Iteration 1039: \t train loss: -2.3007 \t val error: 2.1932\n",
      "Iteration 1040: \t train loss: -2.3016 \t val error: 2.1931\n",
      "Iteration 1041: \t train loss: -2.3025 \t val error: 2.1929\n",
      "Iteration 1042: \t train loss: -2.3035 \t val error: 2.1928\n",
      "Iteration 1043: \t train loss: -2.3044 \t val error: 2.1926\n",
      "Iteration 1044: \t train loss: -2.3053 \t val error: 2.1924\n",
      "Iteration 1045: \t train loss: -2.3063 \t val error: 2.1923\n",
      "Iteration 1046: \t train loss: -2.3072 \t val error: 2.1921\n",
      "Iteration 1047: \t train loss: -2.3081 \t val error: 2.1920\n",
      "Iteration 1048: \t train loss: -2.3090 \t val error: 2.1918\n",
      "Iteration 1049: \t train loss: -2.3099 \t val error: 2.1917\n",
      "Iteration 1050: \t train loss: -2.3109 \t val error: 2.1915\n",
      "Iteration 1051: \t train loss: -2.3118 \t val error: 2.1914\n",
      "Iteration 1052: \t train loss: -2.3127 \t val error: 2.1912\n",
      "Iteration 1053: \t train loss: -2.3136 \t val error: 2.1911\n",
      "Iteration 1054: \t train loss: -2.3145 \t val error: 2.1909\n",
      "Iteration 1055: \t train loss: -2.3154 \t val error: 2.1908\n",
      "Iteration 1056: \t train loss: -2.3163 \t val error: 2.1906\n",
      "Iteration 1057: \t train loss: -2.3172 \t val error: 2.1904\n",
      "Iteration 1058: \t train loss: -2.3182 \t val error: 2.1903\n",
      "Iteration 1059: \t train loss: -2.3191 \t val error: 2.1901\n",
      "Iteration 1060: \t train loss: -2.3200 \t val error: 2.1900\n",
      "Iteration 1061: \t train loss: -2.3209 \t val error: 2.1898\n",
      "Iteration 1062: \t train loss: -2.3218 \t val error: 2.1897\n",
      "Iteration 1063: \t train loss: -2.3227 \t val error: 2.1895\n",
      "Iteration 1064: \t train loss: -2.3236 \t val error: 2.1894\n",
      "Iteration 1065: \t train loss: -2.3245 \t val error: 2.1892\n",
      "Iteration 1066: \t train loss: -2.3254 \t val error: 2.1891\n",
      "Iteration 1067: \t train loss: -2.3262 \t val error: 2.1890\n",
      "Iteration 1068: \t train loss: -2.3271 \t val error: 2.1890\n",
      "Iteration 1069: \t train loss: -2.3280 \t val error: 2.1890\n",
      "Iteration 1070: \t train loss: -2.3289 \t val error: 2.1890\n",
      "Iteration 1071: \t train loss: -2.3298 \t val error: 2.1890\n",
      "Iteration 1072: \t train loss: -2.3307 \t val error: 2.1890\n",
      "Iteration 1073: \t train loss: -2.3316 \t val error: 2.1890\n",
      "Iteration 1074: \t train loss: -2.3325 \t val error: 2.1890\n",
      "Iteration 1075: \t train loss: -2.3333 \t val error: 2.1890\n",
      "Iteration 1076: \t train loss: -2.3342 \t val error: 2.1890\n",
      "Iteration 1077: \t train loss: -2.3351 \t val error: 2.1890\n",
      "Iteration 1078: \t train loss: -2.3360 \t val error: 2.1890\n",
      "Iteration 1079: \t train loss: -2.3368 \t val error: 2.1890\n",
      "Iteration 1080: \t train loss: -2.3377 \t val error: 2.1890\n",
      "Iteration 1081: \t train loss: -2.3386 \t val error: 2.1890\n",
      "Iteration 1082: \t train loss: -2.3395 \t val error: 2.1890\n",
      "Iteration 1083: \t train loss: -2.3403 \t val error: 2.1890\n",
      "Iteration 1084: \t train loss: -2.3412 \t val error: 2.1890\n",
      "Iteration 1085: \t train loss: -2.3421 \t val error: 2.1890\n",
      "Iteration 1086: \t train loss: -2.3429 \t val error: 2.1890\n",
      "Iteration 1087: \t train loss: -2.3438 \t val error: 2.1890\n",
      "Iteration 1088: \t train loss: -2.3447 \t val error: 2.1890\n",
      "Iteration 1089: \t train loss: -2.3455 \t val error: 2.1890\n",
      "Iteration 1090: \t train loss: -2.3464 \t val error: 2.1890\n",
      "Iteration 1091: \t train loss: -2.3472 \t val error: 2.1890\n",
      "Iteration 1092: \t train loss: -2.3481 \t val error: 2.1890\n",
      "Iteration 1093: \t train loss: -2.3490 \t val error: 2.1890\n",
      "Iteration 1094: \t train loss: -2.3498 \t val error: 2.1890\n",
      "Iteration 1095: \t train loss: -2.3507 \t val error: 2.1890\n",
      "Iteration 1096: \t train loss: -2.3515 \t val error: 2.1890\n",
      "Iteration 1097: \t train loss: -2.3524 \t val error: 2.1890\n",
      "Iteration 1098: \t train loss: -2.3532 \t val error: 2.1890\n",
      "Iteration 1099: \t train loss: -2.3541 \t val error: 2.1890\n",
      "Iteration 1100: \t train loss: -2.3549 \t val error: 2.1890\n",
      "Iteration 1101: \t train loss: -2.3557 \t val error: 2.1890\n",
      "Iteration 1102: \t train loss: -2.3566 \t val error: 2.1890\n",
      "Iteration 1103: \t train loss: -2.3574 \t val error: 2.1890\n",
      "Iteration 1104: \t train loss: -2.3583 \t val error: 2.1890\n",
      "Iteration 1105: \t train loss: -2.3591 \t val error: 2.1890\n",
      "Iteration 1106: \t train loss: -2.3599 \t val error: 2.1890\n",
      "Iteration 1107: \t train loss: -2.3608 \t val error: 2.1890\n",
      "Iteration 1108: \t train loss: -2.3616 \t val error: 2.1890\n",
      "Iteration 1109: \t train loss: -2.3624 \t val error: 2.1890\n",
      "Iteration 1110: \t train loss: -2.3633 \t val error: 2.1890\n",
      "Iteration 1111: \t train loss: -2.3641 \t val error: 2.1890\n",
      "Iteration 1112: \t train loss: -2.3649 \t val error: 2.1890\n",
      "Iteration 1113: \t train loss: -2.3658 \t val error: 2.1890\n",
      "Iteration 1114: \t train loss: -2.3666 \t val error: 2.1890\n",
      "Iteration 1115: \t train loss: -2.3674 \t val error: 2.1890\n",
      "Iteration 1116: \t train loss: -2.3682 \t val error: 2.1890\n",
      "Iteration 1117: \t train loss: -2.3691 \t val error: 2.1890\n",
      "Iteration 1118: \t train loss: -2.3699 \t val error: 2.1891\n",
      "Iteration 1119: \t train loss: -2.3707 \t val error: 2.1890\n",
      "Iteration 1120: \t train loss: -2.3715 \t val error: 2.1890\n",
      "Iteration 1121: \t train loss: -2.3723 \t val error: 2.1890\n",
      "Iteration 1122: \t train loss: -2.3731 \t val error: 2.1890\n",
      "Iteration 1123: \t train loss: -2.3740 \t val error: 2.1891\n",
      "Iteration 1124: \t train loss: -2.3748 \t val error: 2.1891\n",
      "Iteration 1125: \t train loss: -2.3756 \t val error: 2.1891\n",
      "Iteration 1126: \t train loss: -2.3764 \t val error: 2.1891\n",
      "Iteration 1127: \t train loss: -2.3772 \t val error: 2.1891\n",
      "Iteration 1128: \t train loss: -2.3780 \t val error: 2.1891\n",
      "Iteration 1129: \t train loss: -2.3788 \t val error: 2.1891\n",
      "Iteration 1130: \t train loss: -2.3796 \t val error: 2.1891\n",
      "Iteration 1131: \t train loss: -2.3804 \t val error: 2.1891\n",
      "Iteration 1132: \t train loss: -2.3812 \t val error: 2.1891\n",
      "Iteration 1133: \t train loss: -2.3820 \t val error: 2.1891\n",
      "Iteration 1134: \t train loss: -2.3828 \t val error: 2.1891\n",
      "Iteration 1135: \t train loss: -2.3836 \t val error: 2.1891\n",
      "Iteration 1136: \t train loss: -2.3844 \t val error: 2.1891\n",
      "Iteration 1137: \t train loss: -2.3852 \t val error: 2.1891\n",
      "Iteration 1138: \t train loss: -2.3860 \t val error: 2.1891\n",
      "Iteration 1139: \t train loss: -2.3868 \t val error: 2.1891\n",
      "Iteration 1140: \t train loss: -2.3876 \t val error: 2.1891\n",
      "Iteration 1141: \t train loss: -2.3884 \t val error: 2.1891\n",
      "Iteration 1142: \t train loss: -2.3892 \t val error: 2.1891\n",
      "Iteration 1143: \t train loss: -2.3899 \t val error: 2.1891\n",
      "Iteration 1144: \t train loss: -2.3907 \t val error: 2.1891\n",
      "Iteration 1145: \t train loss: -2.3915 \t val error: 2.1891\n",
      "Iteration 1146: \t train loss: -2.3923 \t val error: 2.1891\n",
      "Iteration 1147: \t train loss: -2.3931 \t val error: 2.1891\n",
      "Iteration 1148: \t train loss: -2.3939 \t val error: 2.1891\n",
      "Iteration 1149: \t train loss: -2.3946 \t val error: 2.1891\n",
      "Iteration 1150: \t train loss: -2.3954 \t val error: 2.1890\n",
      "Iteration 1151: \t train loss: -2.3962 \t val error: 2.1888\n",
      "Iteration 1152: \t train loss: -2.3970 \t val error: 2.1886\n",
      "Iteration 1153: \t train loss: -2.3977 \t val error: 2.1885\n",
      "Iteration 1154: \t train loss: -2.3985 \t val error: 2.1883\n",
      "Iteration 1155: \t train loss: -2.3993 \t val error: 2.1881\n",
      "Iteration 1156: \t train loss: -2.4000 \t val error: 2.1880\n",
      "Iteration 1157: \t train loss: -2.4008 \t val error: 2.1878\n",
      "Iteration 1158: \t train loss: -2.4016 \t val error: 2.1876\n",
      "Iteration 1159: \t train loss: -2.4023 \t val error: 2.1875\n",
      "Iteration 1160: \t train loss: -2.4031 \t val error: 2.1873\n",
      "Iteration 1161: \t train loss: -2.4039 \t val error: 2.1871\n",
      "Iteration 1162: \t train loss: -2.4046 \t val error: 2.1870\n",
      "Iteration 1163: \t train loss: -2.4054 \t val error: 2.1868\n",
      "Iteration 1164: \t train loss: -2.4062 \t val error: 2.1866\n",
      "Iteration 1165: \t train loss: -2.4069 \t val error: 2.1865\n",
      "Iteration 1166: \t train loss: -2.4077 \t val error: 2.1863\n",
      "Iteration 1167: \t train loss: -2.4084 \t val error: 2.1861\n",
      "Iteration 1168: \t train loss: -2.4092 \t val error: 2.1860\n",
      "Iteration 1169: \t train loss: -2.4099 \t val error: 2.1858\n",
      "Iteration 1170: \t train loss: -2.4107 \t val error: 2.1855\n",
      "Iteration 1171: \t train loss: -2.4114 \t val error: 2.1852\n",
      "Iteration 1172: \t train loss: -2.4122 \t val error: 2.1849\n",
      "Iteration 1173: \t train loss: -2.4129 \t val error: 2.1846\n",
      "Iteration 1174: \t train loss: -2.4137 \t val error: 2.1843\n",
      "Iteration 1175: \t train loss: -2.4144 \t val error: 2.1840\n",
      "Iteration 1176: \t train loss: -2.4152 \t val error: 2.1839\n",
      "Iteration 1177: \t train loss: -2.4159 \t val error: 2.1837\n",
      "Iteration 1178: \t train loss: -2.4167 \t val error: 2.1836\n",
      "Iteration 1179: \t train loss: -2.4174 \t val error: 2.1835\n",
      "Iteration 1180: \t train loss: -2.4181 \t val error: 2.1834\n",
      "Iteration 1181: \t train loss: -2.4189 \t val error: 2.1832\n",
      "Iteration 1182: \t train loss: -2.4196 \t val error: 2.1831\n",
      "Iteration 1183: \t train loss: -2.4204 \t val error: 2.1830\n",
      "Iteration 1184: \t train loss: -2.4211 \t val error: 2.1829\n",
      "Iteration 1185: \t train loss: -2.4218 \t val error: 2.1828\n",
      "Iteration 1186: \t train loss: -2.4226 \t val error: 2.1827\n",
      "Iteration 1187: \t train loss: -2.4233 \t val error: 2.1825\n",
      "Iteration 1188: \t train loss: -2.4240 \t val error: 2.1824\n",
      "Iteration 1189: \t train loss: -2.4247 \t val error: 2.1823\n",
      "Iteration 1190: \t train loss: -2.4255 \t val error: 2.1822\n",
      "Iteration 1191: \t train loss: -2.4262 \t val error: 2.1821\n",
      "Iteration 1192: \t train loss: -2.4269 \t val error: 2.1819\n",
      "Iteration 1193: \t train loss: -2.4276 \t val error: 2.1818\n",
      "Iteration 1194: \t train loss: -2.4284 \t val error: 2.1817\n",
      "Iteration 1195: \t train loss: -2.4291 \t val error: 2.1816\n",
      "Iteration 1196: \t train loss: -2.4298 \t val error: 2.1815\n",
      "Iteration 1197: \t train loss: -2.4305 \t val error: 2.1813\n",
      "Iteration 1198: \t train loss: -2.4312 \t val error: 2.1812\n",
      "Iteration 1199: \t train loss: -2.4320 \t val error: 2.1811\n",
      "Iteration 1200: \t train loss: -2.4327 \t val error: 2.1810\n",
      "Iteration 1201: \t train loss: -2.4334 \t val error: 2.1809\n",
      "Iteration 1202: \t train loss: -2.4341 \t val error: 2.1808\n",
      "Iteration 1203: \t train loss: -2.4348 \t val error: 2.1806\n",
      "Iteration 1204: \t train loss: -2.4355 \t val error: 2.1805\n",
      "Iteration 1205: \t train loss: -2.4362 \t val error: 2.1805\n",
      "Iteration 1206: \t train loss: -2.4369 \t val error: 2.1805\n",
      "Iteration 1207: \t train loss: -2.4377 \t val error: 2.1805\n",
      "Iteration 1208: \t train loss: -2.4384 \t val error: 2.1805\n",
      "Iteration 1209: \t train loss: -2.4391 \t val error: 2.1805\n",
      "Iteration 1210: \t train loss: -2.4398 \t val error: 2.1805\n",
      "Iteration 1211: \t train loss: -2.4405 \t val error: 2.1805\n",
      "Iteration 1212: \t train loss: -2.4412 \t val error: 2.1805\n",
      "Iteration 1213: \t train loss: -2.4419 \t val error: 2.1805\n",
      "Iteration 1214: \t train loss: -2.4426 \t val error: 2.1805\n",
      "Iteration 1215: \t train loss: -2.4433 \t val error: 2.1805\n",
      "Iteration 1216: \t train loss: -2.4440 \t val error: 2.1805\n",
      "Iteration 1217: \t train loss: -2.4447 \t val error: 2.1805\n",
      "Iteration 1218: \t train loss: -2.4454 \t val error: 2.1805\n",
      "Iteration 1219: \t train loss: -2.4460 \t val error: 2.1805\n",
      "Iteration 1220: \t train loss: -2.4467 \t val error: 2.1805\n",
      "Iteration 1221: \t train loss: -2.4474 \t val error: 2.1805\n",
      "Iteration 1222: \t train loss: -2.4481 \t val error: 2.1805\n",
      "Iteration 1223: \t train loss: -2.4488 \t val error: 2.1805\n",
      "Iteration 1224: \t train loss: -2.4495 \t val error: 2.1805\n",
      "Iteration 1225: \t train loss: -2.4502 \t val error: 2.1805\n",
      "Iteration 1226: \t train loss: -2.4509 \t val error: 2.1805\n",
      "Iteration 1227: \t train loss: -2.4515 \t val error: 2.1805\n",
      "Iteration 1228: \t train loss: -2.4522 \t val error: 2.1805\n",
      "Iteration 1229: \t train loss: -2.4529 \t val error: 2.1805\n",
      "Iteration 1230: \t train loss: -2.4536 \t val error: 2.1805\n",
      "Iteration 1231: \t train loss: -2.4543 \t val error: 2.1805\n",
      "Iteration 1232: \t train loss: -2.4549 \t val error: 2.1805\n",
      "Iteration 1233: \t train loss: -2.4556 \t val error: 2.1805\n",
      "Iteration 1234: \t train loss: -2.4563 \t val error: 2.1805\n",
      "Iteration 1235: \t train loss: -2.4570 \t val error: 2.1805\n",
      "Iteration 1236: \t train loss: -2.4577 \t val error: 2.1805\n",
      "Iteration 1237: \t train loss: -2.4583 \t val error: 2.1805\n",
      "Iteration 1238: \t train loss: -2.4590 \t val error: 2.1805\n",
      "Iteration 1239: \t train loss: -2.4597 \t val error: 2.1805\n",
      "Iteration 1240: \t train loss: -2.4603 \t val error: 2.1805\n",
      "Iteration 1241: \t train loss: -2.4610 \t val error: 2.1805\n",
      "Iteration 1242: \t train loss: -2.4617 \t val error: 2.1805\n",
      "Iteration 1243: \t train loss: -2.4623 \t val error: 2.1805\n",
      "Iteration 1244: \t train loss: -2.4630 \t val error: 2.1805\n",
      "Iteration 1245: \t train loss: -2.4637 \t val error: 2.1805\n",
      "Iteration 1246: \t train loss: -2.4643 \t val error: 2.1805\n",
      "Iteration 1247: \t train loss: -2.4650 \t val error: 2.1805\n",
      "Iteration 1248: \t train loss: -2.4656 \t val error: 2.1805\n",
      "Iteration 1249: \t train loss: -2.4663 \t val error: 2.1805\n",
      "Iteration 1250: \t train loss: -2.4670 \t val error: 2.1805\n",
      "Iteration 1251: \t train loss: -2.4676 \t val error: 2.1805\n",
      "Iteration 1252: \t train loss: -2.4683 \t val error: 2.1805\n",
      "Iteration 1253: \t train loss: -2.4689 \t val error: 2.1805\n",
      "Iteration 1254: \t train loss: -2.4696 \t val error: 2.1805\n",
      "Iteration 1255: \t train loss: -2.4702 \t val error: 2.1805\n",
      "Iteration 1256: \t train loss: -2.4709 \t val error: 2.1805\n",
      "Iteration 1257: \t train loss: -2.4715 \t val error: 2.1805\n",
      "Iteration 1258: \t train loss: -2.4722 \t val error: 2.1805\n",
      "Iteration 1259: \t train loss: -2.4728 \t val error: 2.1805\n",
      "Iteration 1260: \t train loss: -2.4735 \t val error: 2.1805\n",
      "Iteration 1261: \t train loss: -2.4741 \t val error: 2.1805\n",
      "Iteration 1262: \t train loss: -2.4748 \t val error: 2.1805\n",
      "Iteration 1263: \t train loss: -2.4754 \t val error: 2.1805\n",
      "Iteration 1264: \t train loss: -2.4761 \t val error: 2.1805\n",
      "Iteration 1265: \t train loss: -2.4767 \t val error: 2.1805\n",
      "Iteration 1266: \t train loss: -2.4773 \t val error: 2.1805\n",
      "Iteration 1267: \t train loss: -2.4780 \t val error: 2.1805\n",
      "Iteration 1268: \t train loss: -2.4786 \t val error: 2.1805\n",
      "Iteration 1269: \t train loss: -2.4793 \t val error: 2.1805\n",
      "Iteration 1270: \t train loss: -2.4799 \t val error: 2.1805\n",
      "Iteration 1271: \t train loss: -2.4805 \t val error: 2.1805\n",
      "Iteration 1272: \t train loss: -2.4812 \t val error: 2.1805\n",
      "Iteration 1273: \t train loss: -2.4818 \t val error: 2.1805\n",
      "Iteration 1274: \t train loss: -2.4824 \t val error: 2.1805\n",
      "Iteration 1275: \t train loss: -2.4831 \t val error: 2.1805\n",
      "Iteration 1276: \t train loss: -2.4837 \t val error: 2.1805\n",
      "Iteration 1277: \t train loss: -2.4843 \t val error: 2.1805\n",
      "Iteration 1278: \t train loss: -2.4850 \t val error: 2.1805\n",
      "Iteration 1279: \t train loss: -2.4856 \t val error: 2.1805\n",
      "Iteration 1280: \t train loss: -2.4862 \t val error: 2.1805\n",
      "Iteration 1281: \t train loss: -2.4868 \t val error: 2.1805\n",
      "Iteration 1282: \t train loss: -2.4875 \t val error: 2.1805\n",
      "Iteration 1283: \t train loss: -2.4881 \t val error: 2.1805\n",
      "Iteration 1284: \t train loss: -2.4887 \t val error: 2.1805\n",
      "Iteration 1285: \t train loss: -2.4893 \t val error: 2.1805\n",
      "Iteration 1286: \t train loss: -2.4899 \t val error: 2.1805\n",
      "Iteration 1287: \t train loss: -2.4906 \t val error: 2.1805\n",
      "Iteration 1288: \t train loss: -2.4912 \t val error: 2.1805\n",
      "Iteration 1289: \t train loss: -2.4918 \t val error: 2.1805\n",
      "Iteration 1290: \t train loss: -2.4924 \t val error: 2.1805\n",
      "Iteration 1291: \t train loss: -2.4930 \t val error: 2.1805\n",
      "Iteration 1292: \t train loss: -2.4936 \t val error: 2.1805\n",
      "Iteration 1293: \t train loss: -2.4943 \t val error: 2.1805\n",
      "Iteration 1294: \t train loss: -2.4949 \t val error: 2.1805\n",
      "Iteration 1295: \t train loss: -2.4955 \t val error: 2.1805\n",
      "Iteration 1296: \t train loss: -2.4961 \t val error: 2.1805\n",
      "Iteration 1297: \t train loss: -2.4967 \t val error: 2.1806\n",
      "Iteration 1298: \t train loss: -2.4973 \t val error: 2.1805\n",
      "Iteration 1299: \t train loss: -2.4979 \t val error: 2.1806\n",
      "Iteration 1300: \t train loss: -2.4985 \t val error: 2.1806\n",
      "Iteration 1301: \t train loss: -2.4991 \t val error: 2.1806\n",
      "Iteration 1302: \t train loss: -2.4997 \t val error: 2.1806\n",
      "Iteration 1303: \t train loss: -2.5003 \t val error: 2.1806\n",
      "Iteration 1304: \t train loss: -2.5009 \t val error: 2.1806\n",
      "Iteration 1305: \t train loss: -2.5015 \t val error: 2.1806\n",
      "Iteration 1306: \t train loss: -2.5021 \t val error: 2.1806\n",
      "Iteration 1307: \t train loss: -2.5027 \t val error: 2.1806\n",
      "Iteration 1308: \t train loss: -2.5033 \t val error: 2.1806\n",
      "Iteration 1309: \t train loss: -2.5039 \t val error: 2.1806\n",
      "Iteration 1310: \t train loss: -2.5045 \t val error: 2.1806\n",
      "Iteration 1311: \t train loss: -2.5051 \t val error: 2.1806\n",
      "Iteration 1312: \t train loss: -2.5057 \t val error: 2.1806\n",
      "Iteration 1313: \t train loss: -2.5063 \t val error: 2.1806\n",
      "Iteration 1314: \t train loss: -2.5069 \t val error: 2.1806\n",
      "Iteration 1315: \t train loss: -2.5075 \t val error: 2.1806\n",
      "Iteration 1316: \t train loss: -2.5081 \t val error: 2.1806\n",
      "Iteration 1317: \t train loss: -2.5087 \t val error: 2.1806\n",
      "Iteration 1318: \t train loss: -2.5092 \t val error: 2.1806\n",
      "Iteration 1319: \t train loss: -2.5098 \t val error: 2.1806\n",
      "Iteration 1320: \t train loss: -2.5104 \t val error: 2.1806\n",
      "Iteration 1321: \t train loss: -2.5110 \t val error: 2.1806\n",
      "Iteration 1322: \t train loss: -2.5116 \t val error: 2.1806\n",
      "Iteration 1323: \t train loss: -2.5122 \t val error: 2.1806\n",
      "Iteration 1324: \t train loss: -2.5127 \t val error: 2.1806\n",
      "Iteration 1325: \t train loss: -2.5133 \t val error: 2.1806\n",
      "Iteration 1326: \t train loss: -2.5139 \t val error: 2.1806\n",
      "Iteration 1327: \t train loss: -2.5145 \t val error: 2.1806\n",
      "Iteration 1328: \t train loss: -2.5151 \t val error: 2.1806\n",
      "Iteration 1329: \t train loss: -2.5156 \t val error: 2.1806\n",
      "Iteration 1330: \t train loss: -2.5162 \t val error: 2.1806\n",
      "Iteration 1331: \t train loss: -2.5168 \t val error: 2.1806\n",
      "Iteration 1332: \t train loss: -2.5174 \t val error: 2.1806\n",
      "Iteration 1333: \t train loss: -2.5179 \t val error: 2.1806\n",
      "Iteration 1334: \t train loss: -2.5185 \t val error: 2.1806\n",
      "Iteration 1335: \t train loss: -2.5191 \t val error: 2.1806\n",
      "Iteration 1336: \t train loss: -2.5197 \t val error: 2.1806\n",
      "Iteration 1337: \t train loss: -2.5202 \t val error: 2.1806\n",
      "Iteration 1338: \t train loss: -2.5208 \t val error: 2.1806\n",
      "Iteration 1339: \t train loss: -2.5214 \t val error: 2.1806\n",
      "Iteration 1340: \t train loss: -2.5219 \t val error: 2.1806\n",
      "Iteration 1341: \t train loss: -2.5225 \t val error: 2.1806\n",
      "Iteration 1342: \t train loss: -2.5231 \t val error: 2.1806\n",
      "Iteration 1343: \t train loss: -2.5236 \t val error: 2.1806\n",
      "Iteration 1344: \t train loss: -2.5242 \t val error: 2.1806\n",
      "Iteration 1345: \t train loss: -2.5247 \t val error: 2.1806\n",
      "Iteration 1346: \t train loss: -2.5253 \t val error: 2.1806\n",
      "Iteration 1347: \t train loss: -2.5259 \t val error: 2.1806\n",
      "Iteration 1348: \t train loss: -2.5264 \t val error: 2.1806\n",
      "Iteration 1349: \t train loss: -2.5270 \t val error: 2.1806\n",
      "Iteration 1350: \t train loss: -2.5275 \t val error: 2.1806\n",
      "Iteration 1351: \t train loss: -2.5281 \t val error: 2.1806\n",
      "Iteration 1352: \t train loss: -2.5287 \t val error: 2.1806\n",
      "Iteration 1353: \t train loss: -2.5292 \t val error: 2.1806\n",
      "Iteration 1354: \t train loss: -2.5298 \t val error: 2.1806\n",
      "Iteration 1355: \t train loss: -2.5303 \t val error: 2.1806\n",
      "Iteration 1356: \t train loss: -2.5309 \t val error: 2.1806\n",
      "Iteration 1357: \t train loss: -2.5314 \t val error: 2.1806\n",
      "Iteration 1358: \t train loss: -2.5320 \t val error: 2.1806\n",
      "Iteration 1359: \t train loss: -2.5325 \t val error: 2.1806\n",
      "Iteration 1360: \t train loss: -2.5331 \t val error: 2.1806\n",
      "Iteration 1361: \t train loss: -2.5336 \t val error: 2.1806\n",
      "Iteration 1362: \t train loss: -2.5342 \t val error: 2.1806\n",
      "Iteration 1363: \t train loss: -2.5347 \t val error: 2.1806\n",
      "Iteration 1364: \t train loss: -2.5352 \t val error: 2.1806\n",
      "Iteration 1365: \t train loss: -2.5358 \t val error: 2.1806\n",
      "Iteration 1366: \t train loss: -2.5363 \t val error: 2.1806\n",
      "Iteration 1367: \t train loss: -2.5369 \t val error: 2.1806\n",
      "Iteration 1368: \t train loss: -2.5374 \t val error: 2.1806\n",
      "Iteration 1369: \t train loss: -2.5380 \t val error: 2.1806\n",
      "Iteration 1370: \t train loss: -2.5385 \t val error: 2.1806\n",
      "Iteration 1371: \t train loss: -2.5390 \t val error: 2.1806\n",
      "Iteration 1372: \t train loss: -2.5396 \t val error: 2.1806\n",
      "Iteration 1373: \t train loss: -2.5401 \t val error: 2.1806\n",
      "Iteration 1374: \t train loss: -2.5406 \t val error: 2.1806\n",
      "Iteration 1375: \t train loss: -2.5412 \t val error: 2.1806\n",
      "Iteration 1376: \t train loss: -2.5417 \t val error: 2.1806\n",
      "Iteration 1377: \t train loss: -2.5422 \t val error: 2.1806\n",
      "Iteration 1378: \t train loss: -2.5428 \t val error: 2.1806\n",
      "Iteration 1379: \t train loss: -2.5433 \t val error: 2.1806\n",
      "Iteration 1380: \t train loss: -2.5438 \t val error: 2.1806\n",
      "Iteration 1381: \t train loss: -2.5444 \t val error: 2.1806\n",
      "Iteration 1382: \t train loss: -2.5449 \t val error: 2.1807\n",
      "Iteration 1383: \t train loss: -2.5454 \t val error: 2.1807\n",
      "Iteration 1384: \t train loss: -2.5459 \t val error: 2.1807\n",
      "Iteration 1385: \t train loss: -2.5465 \t val error: 2.1807\n",
      "Iteration 1386: \t train loss: -2.5470 \t val error: 2.1807\n",
      "Iteration 1387: \t train loss: -2.5475 \t val error: 2.1807\n",
      "Iteration 1388: \t train loss: -2.5480 \t val error: 2.1807\n",
      "Iteration 1389: \t train loss: -2.5486 \t val error: 2.1807\n",
      "Iteration 1390: \t train loss: -2.5491 \t val error: 2.1807\n",
      "Iteration 1391: \t train loss: -2.5496 \t val error: 2.1807\n",
      "Iteration 1392: \t train loss: -2.5501 \t val error: 2.1807\n",
      "Iteration 1393: \t train loss: -2.5506 \t val error: 2.1807\n",
      "Iteration 1394: \t train loss: -2.5512 \t val error: 2.1807\n",
      "Iteration 1395: \t train loss: -2.5517 \t val error: 2.1807\n",
      "Iteration 1396: \t train loss: -2.5522 \t val error: 2.1807\n",
      "Iteration 1397: \t train loss: -2.5527 \t val error: 2.1807\n",
      "Iteration 1398: \t train loss: -2.5532 \t val error: 2.1807\n",
      "Iteration 1399: \t train loss: -2.5537 \t val error: 2.1807\n",
      "Iteration 1400: \t train loss: -2.5543 \t val error: 2.1807\n",
      "Iteration 1401: \t train loss: -2.5548 \t val error: 2.1807\n",
      "Iteration 1402: \t train loss: -2.5553 \t val error: 2.1807\n",
      "Iteration 1403: \t train loss: -2.5558 \t val error: 2.1807\n",
      "Iteration 1404: \t train loss: -2.5563 \t val error: 2.1807\n",
      "Iteration 1405: \t train loss: -2.5568 \t val error: 2.1807\n",
      "Iteration 1406: \t train loss: -2.5573 \t val error: 2.1807\n",
      "Iteration 1407: \t train loss: -2.5578 \t val error: 2.1807\n",
      "Iteration 1408: \t train loss: -2.5583 \t val error: 2.1807\n",
      "Iteration 1409: \t train loss: -2.5588 \t val error: 2.1807\n",
      "Iteration 1410: \t train loss: -2.5593 \t val error: 2.1807\n",
      "Iteration 1411: \t train loss: -2.5598 \t val error: 2.1807\n",
      "Iteration 1412: \t train loss: -2.5603 \t val error: 2.1807\n",
      "Iteration 1413: \t train loss: -2.5608 \t val error: 2.1807\n",
      "Iteration 1414: \t train loss: -2.5613 \t val error: 2.1807\n",
      "Iteration 1415: \t train loss: -2.5618 \t val error: 2.1807\n",
      "Iteration 1416: \t train loss: -2.5623 \t val error: 2.1807\n",
      "Iteration 1417: \t train loss: -2.5628 \t val error: 2.1807\n",
      "Iteration 1418: \t train loss: -2.5633 \t val error: 2.1807\n",
      "Iteration 1419: \t train loss: -2.5638 \t val error: 2.1807\n",
      "Iteration 1420: \t train loss: -2.5643 \t val error: 2.1807\n",
      "Iteration 1421: \t train loss: -2.5648 \t val error: 2.1807\n",
      "Iteration 1422: \t train loss: -2.5653 \t val error: 2.1807\n",
      "Iteration 1423: \t train loss: -2.5658 \t val error: 2.1807\n",
      "Iteration 1424: \t train loss: -2.5663 \t val error: 2.1807\n",
      "Iteration 1425: \t train loss: -2.5668 \t val error: 2.1807\n",
      "Iteration 1426: \t train loss: -2.5673 \t val error: 2.1807\n",
      "Iteration 1427: \t train loss: -2.5678 \t val error: 2.1807\n",
      "Iteration 1428: \t train loss: -2.5683 \t val error: 2.1807\n",
      "Iteration 1429: \t train loss: -2.5688 \t val error: 2.1807\n",
      "Iteration 1430: \t train loss: -2.5692 \t val error: 2.1807\n",
      "Iteration 1431: \t train loss: -2.5697 \t val error: 2.1807\n",
      "Iteration 1432: \t train loss: -2.5702 \t val error: 2.1807\n",
      "Iteration 1433: \t train loss: -2.5707 \t val error: 2.1807\n",
      "Iteration 1434: \t train loss: -2.5712 \t val error: 2.1807\n",
      "Iteration 1435: \t train loss: -2.5717 \t val error: 2.1807\n",
      "Iteration 1436: \t train loss: -2.5722 \t val error: 2.1807\n",
      "Iteration 1437: \t train loss: -2.5726 \t val error: 2.1807\n",
      "Iteration 1438: \t train loss: -2.5731 \t val error: 2.1807\n",
      "Iteration 1439: \t train loss: -2.5736 \t val error: 2.1807\n",
      "Iteration 1440: \t train loss: -2.5741 \t val error: 2.1807\n",
      "Iteration 1441: \t train loss: -2.5746 \t val error: 2.1807\n",
      "Iteration 1442: \t train loss: -2.5750 \t val error: 2.1807\n",
      "Iteration 1443: \t train loss: -2.5755 \t val error: 2.1807\n",
      "Iteration 1444: \t train loss: -2.5760 \t val error: 2.1807\n",
      "Iteration 1445: \t train loss: -2.5765 \t val error: 2.1807\n",
      "Iteration 1446: \t train loss: -2.5769 \t val error: 2.1807\n",
      "Iteration 1447: \t train loss: -2.5774 \t val error: 2.1807\n",
      "Iteration 1448: \t train loss: -2.5779 \t val error: 2.1807\n",
      "Iteration 1449: \t train loss: -2.5784 \t val error: 2.1807\n",
      "Iteration 1450: \t train loss: -2.5788 \t val error: 2.1807\n",
      "Iteration 1451: \t train loss: -2.5793 \t val error: 2.1807\n",
      "Iteration 1452: \t train loss: -2.5798 \t val error: 2.1807\n",
      "Iteration 1453: \t train loss: -2.5802 \t val error: 2.1807\n",
      "Iteration 1454: \t train loss: -2.5807 \t val error: 2.1807\n",
      "Iteration 1455: \t train loss: -2.5812 \t val error: 2.1807\n",
      "Iteration 1456: \t train loss: -2.5816 \t val error: 2.1807\n",
      "Iteration 1457: \t train loss: -2.5821 \t val error: 2.1807\n",
      "Iteration 1458: \t train loss: -2.5826 \t val error: 2.1807\n",
      "Iteration 1459: \t train loss: -2.5830 \t val error: 2.1807\n",
      "Iteration 1460: \t train loss: -2.5835 \t val error: 2.1807\n",
      "Iteration 1461: \t train loss: -2.5840 \t val error: 2.1808\n",
      "Iteration 1462: \t train loss: -2.5844 \t val error: 2.1808\n",
      "Iteration 1463: \t train loss: -2.5849 \t val error: 2.1808\n",
      "Iteration 1464: \t train loss: -2.5854 \t val error: 2.1808\n",
      "Iteration 1465: \t train loss: -2.5858 \t val error: 2.1808\n",
      "Iteration 1466: \t train loss: -2.5863 \t val error: 2.1808\n",
      "Iteration 1467: \t train loss: -2.5867 \t val error: 2.1808\n",
      "Iteration 1468: \t train loss: -2.5872 \t val error: 2.1808\n",
      "Iteration 1469: \t train loss: -2.5876 \t val error: 2.1808\n",
      "Iteration 1470: \t train loss: -2.5881 \t val error: 2.1808\n",
      "Iteration 1471: \t train loss: -2.5886 \t val error: 2.1808\n",
      "Iteration 1472: \t train loss: -2.5890 \t val error: 2.1808\n",
      "Iteration 1473: \t train loss: -2.5895 \t val error: 2.1808\n",
      "Iteration 1474: \t train loss: -2.5899 \t val error: 2.1808\n",
      "Iteration 1475: \t train loss: -2.5904 \t val error: 2.1808\n",
      "Iteration 1476: \t train loss: -2.5908 \t val error: 2.1808\n",
      "Iteration 1477: \t train loss: -2.5913 \t val error: 2.1808\n",
      "Iteration 1478: \t train loss: -2.5917 \t val error: 2.1808\n",
      "Iteration 1479: \t train loss: -2.5922 \t val error: 2.1808\n",
      "Iteration 1480: \t train loss: -2.5926 \t val error: 2.1808\n",
      "Iteration 1481: \t train loss: -2.5931 \t val error: 2.1808\n",
      "Iteration 1482: \t train loss: -2.5935 \t val error: 2.1808\n",
      "Iteration 1483: \t train loss: -2.5940 \t val error: 2.1808\n",
      "Iteration 1484: \t train loss: -2.5944 \t val error: 2.1808\n",
      "Iteration 1485: \t train loss: -2.5949 \t val error: 2.1808\n",
      "Iteration 1486: \t train loss: -2.5953 \t val error: 2.1808\n",
      "Iteration 1487: \t train loss: -2.5958 \t val error: 2.1808\n",
      "Iteration 1488: \t train loss: -2.5962 \t val error: 2.1808\n",
      "Iteration 1489: \t train loss: -2.5966 \t val error: 2.1808\n",
      "Iteration 1490: \t train loss: -2.5971 \t val error: 2.1808\n",
      "Iteration 1491: \t train loss: -2.5975 \t val error: 2.1808\n",
      "Iteration 1492: \t train loss: -2.5980 \t val error: 2.1808\n",
      "Iteration 1493: \t train loss: -2.5984 \t val error: 2.1808\n",
      "Iteration 1494: \t train loss: -2.5988 \t val error: 2.1808\n",
      "Iteration 1495: \t train loss: -2.5993 \t val error: 2.1808\n",
      "Iteration 1496: \t train loss: -2.5997 \t val error: 2.1808\n",
      "Iteration 1497: \t train loss: -2.6001 \t val error: 2.1808\n",
      "Iteration 1498: \t train loss: -2.6006 \t val error: 2.1808\n",
      "Iteration 1499: \t train loss: -2.6010 \t val error: 2.1808\n",
      "Iteration 1500: \t train loss: -2.6015 \t val error: 2.1808\n",
      "Iteration 1501: \t train loss: -2.6019 \t val error: 2.1808\n",
      "Iteration 1502: \t train loss: -2.6023 \t val error: 2.1808\n",
      "Iteration 1503: \t train loss: -2.6028 \t val error: 2.1808\n",
      "Iteration 1504: \t train loss: -2.6032 \t val error: 2.1808\n",
      "Iteration 1505: \t train loss: -2.6036 \t val error: 2.1808\n",
      "Iteration 1506: \t train loss: -2.6040 \t val error: 2.1808\n",
      "Iteration 1507: \t train loss: -2.6045 \t val error: 2.1808\n",
      "Iteration 1508: \t train loss: -2.6049 \t val error: 2.1808\n",
      "Iteration 1509: \t train loss: -2.6053 \t val error: 2.1808\n",
      "Iteration 1510: \t train loss: -2.6058 \t val error: 2.1808\n",
      "Iteration 1511: \t train loss: -2.6062 \t val error: 2.1808\n",
      "Iteration 1512: \t train loss: -2.6066 \t val error: 2.1808\n",
      "Iteration 1513: \t train loss: -2.6070 \t val error: 2.1808\n",
      "Iteration 1514: \t train loss: -2.6075 \t val error: 2.1808\n",
      "Iteration 1515: \t train loss: -2.6079 \t val error: 2.1808\n",
      "Iteration 1516: \t train loss: -2.6083 \t val error: 2.1808\n",
      "Iteration 1517: \t train loss: -2.6087 \t val error: 2.1808\n",
      "Iteration 1518: \t train loss: -2.6091 \t val error: 2.1808\n",
      "Iteration 1519: \t train loss: -2.6096 \t val error: 2.1808\n",
      "Iteration 1520: \t train loss: -2.6100 \t val error: 2.1808\n",
      "Iteration 1521: \t train loss: -2.6104 \t val error: 2.1808\n",
      "Iteration 1522: \t train loss: -2.6108 \t val error: 2.1808\n",
      "Iteration 1523: \t train loss: -2.6112 \t val error: 2.1808\n",
      "Iteration 1524: \t train loss: -2.6117 \t val error: 2.1808\n",
      "Iteration 1525: \t train loss: -2.6121 \t val error: 2.1808\n",
      "Iteration 1526: \t train loss: -2.6125 \t val error: 2.1808\n",
      "Iteration 1527: \t train loss: -2.6129 \t val error: 2.1808\n",
      "Iteration 1528: \t train loss: -2.6133 \t val error: 2.1808\n",
      "Iteration 1529: \t train loss: -2.6137 \t val error: 2.1808\n",
      "Iteration 1530: \t train loss: -2.6141 \t val error: 2.1808\n",
      "Iteration 1531: \t train loss: -2.6146 \t val error: 2.1808\n",
      "Iteration 1532: \t train loss: -2.6150 \t val error: 2.1808\n",
      "Iteration 1533: \t train loss: -2.6154 \t val error: 2.1808\n",
      "Iteration 1534: \t train loss: -2.6158 \t val error: 2.1808\n",
      "Iteration 1535: \t train loss: -2.6162 \t val error: 2.1808\n",
      "Iteration 1536: \t train loss: -2.6166 \t val error: 2.1808\n",
      "Iteration 1537: \t train loss: -2.6170 \t val error: 2.1808\n",
      "Iteration 1538: \t train loss: -2.6174 \t val error: 2.1808\n",
      "Iteration 1539: \t train loss: -2.6178 \t val error: 2.1808\n",
      "Iteration 1540: \t train loss: -2.6182 \t val error: 2.1809\n",
      "Iteration 1541: \t train loss: -2.6186 \t val error: 2.1809\n",
      "Iteration 1542: \t train loss: -2.6191 \t val error: 2.1809\n",
      "Iteration 1543: \t train loss: -2.6195 \t val error: 2.1809\n",
      "Iteration 1544: \t train loss: -2.6199 \t val error: 2.1809\n",
      "Iteration 1545: \t train loss: -2.6203 \t val error: 2.1809\n",
      "Iteration 1546: \t train loss: -2.6207 \t val error: 2.1809\n",
      "Iteration 1547: \t train loss: -2.6211 \t val error: 2.1809\n",
      "Iteration 1548: \t train loss: -2.6215 \t val error: 2.1809\n",
      "Iteration 1549: \t train loss: -2.6219 \t val error: 2.1809\n",
      "Iteration 1550: \t train loss: -2.6223 \t val error: 2.1809\n",
      "Iteration 1551: \t train loss: -2.6227 \t val error: 2.1809\n",
      "Iteration 1552: \t train loss: -2.6231 \t val error: 2.1809\n",
      "Iteration 1553: \t train loss: -2.6235 \t val error: 2.1809\n",
      "Iteration 1554: \t train loss: -2.6239 \t val error: 2.1809\n",
      "Iteration 1555: \t train loss: -2.6243 \t val error: 2.1809\n",
      "Iteration 1556: \t train loss: -2.6247 \t val error: 2.1809\n",
      "Iteration 1557: \t train loss: -2.6250 \t val error: 2.1809\n",
      "Iteration 1558: \t train loss: -2.6254 \t val error: 2.1809\n",
      "Iteration 1559: \t train loss: -2.6258 \t val error: 2.1809\n",
      "Iteration 1560: \t train loss: -2.6262 \t val error: 2.1809\n",
      "Iteration 1561: \t train loss: -2.6266 \t val error: 2.1809\n",
      "Iteration 1562: \t train loss: -2.6270 \t val error: 2.1809\n",
      "Iteration 1563: \t train loss: -2.6274 \t val error: 2.1809\n",
      "Iteration 1564: \t train loss: -2.6278 \t val error: 2.1809\n",
      "Iteration 1565: \t train loss: -2.6282 \t val error: 2.1809\n",
      "Iteration 1566: \t train loss: -2.6286 \t val error: 2.1809\n",
      "Iteration 1567: \t train loss: -2.6290 \t val error: 2.1809\n",
      "Iteration 1568: \t train loss: -2.6294 \t val error: 2.1809\n",
      "Iteration 1569: \t train loss: -2.6297 \t val error: 2.1809\n",
      "Iteration 1570: \t train loss: -2.6301 \t val error: 2.1809\n",
      "Iteration 1571: \t train loss: -2.6305 \t val error: 2.1809\n",
      "Iteration 1572: \t train loss: -2.6309 \t val error: 2.1809\n",
      "Iteration 1573: \t train loss: -2.6313 \t val error: 2.1809\n",
      "Iteration 1574: \t train loss: -2.6317 \t val error: 2.1809\n",
      "Iteration 1575: \t train loss: -2.6320 \t val error: 2.1809\n",
      "Iteration 1576: \t train loss: -2.6324 \t val error: 2.1809\n",
      "Iteration 1577: \t train loss: -2.6328 \t val error: 2.1809\n",
      "Iteration 1578: \t train loss: -2.6332 \t val error: 2.1809\n",
      "Iteration 1579: \t train loss: -2.6336 \t val error: 2.1809\n",
      "Iteration 1580: \t train loss: -2.6340 \t val error: 2.1809\n",
      "Iteration 1581: \t train loss: -2.6343 \t val error: 2.1809\n",
      "Iteration 1582: \t train loss: -2.6347 \t val error: 2.1809\n",
      "Iteration 1583: \t train loss: -2.6351 \t val error: 2.1809\n",
      "Iteration 1584: \t train loss: -2.6355 \t val error: 2.1809\n",
      "Iteration 1585: \t train loss: -2.6358 \t val error: 2.1809\n",
      "Iteration 1586: \t train loss: -2.6362 \t val error: 2.1809\n",
      "Iteration 1587: \t train loss: -2.6366 \t val error: 2.1809\n",
      "Iteration 1588: \t train loss: -2.6370 \t val error: 2.1809\n",
      "Iteration 1589: \t train loss: -2.6374 \t val error: 2.1809\n",
      "Iteration 1590: \t train loss: -2.6377 \t val error: 2.1809\n",
      "Iteration 1591: \t train loss: -2.6381 \t val error: 2.1809\n",
      "Iteration 1592: \t train loss: -2.6385 \t val error: 2.1809\n",
      "Iteration 1593: \t train loss: -2.6388 \t val error: 2.1809\n",
      "Iteration 1594: \t train loss: -2.6392 \t val error: 2.1809\n",
      "Iteration 1595: \t train loss: -2.6396 \t val error: 2.1809\n",
      "Iteration 1596: \t train loss: -2.6400 \t val error: 2.1809\n",
      "Iteration 1597: \t train loss: -2.6403 \t val error: 2.1809\n",
      "Iteration 1598: \t train loss: -2.6407 \t val error: 2.1809\n",
      "Iteration 1599: \t train loss: -2.6411 \t val error: 2.1809\n",
      "Iteration 1600: \t train loss: -2.6414 \t val error: 2.1809\n",
      "Iteration 1601: \t train loss: -2.6418 \t val error: 2.1809\n",
      "Iteration 1602: \t train loss: -2.6422 \t val error: 2.1809\n",
      "Iteration 1603: \t train loss: -2.6425 \t val error: 2.1809\n",
      "Iteration 1604: \t train loss: -2.6429 \t val error: 2.1809\n",
      "Iteration 1605: \t train loss: -2.6433 \t val error: 2.1809\n",
      "Iteration 1606: \t train loss: -2.6436 \t val error: 2.1809\n",
      "Iteration 1607: \t train loss: -2.6440 \t val error: 2.1809\n",
      "Iteration 1608: \t train loss: -2.6444 \t val error: 2.1809\n",
      "Iteration 1609: \t train loss: -2.6447 \t val error: 2.1809\n",
      "Iteration 1610: \t train loss: -2.6451 \t val error: 2.1809\n",
      "Iteration 1611: \t train loss: -2.6454 \t val error: 2.1809\n",
      "Iteration 1612: \t train loss: -2.6458 \t val error: 2.1809\n",
      "Iteration 1613: \t train loss: -2.6462 \t val error: 2.1809\n",
      "Iteration 1614: \t train loss: -2.6465 \t val error: 2.1809\n",
      "Iteration 1615: \t train loss: -2.6469 \t val error: 2.1809\n",
      "Iteration 1616: \t train loss: -2.6472 \t val error: 2.1809\n",
      "Iteration 1617: \t train loss: -2.6476 \t val error: 2.1809\n",
      "Iteration 1618: \t train loss: -2.6479 \t val error: 2.1809\n",
      "Iteration 1619: \t train loss: -2.6483 \t val error: 2.1810\n",
      "Iteration 1620: \t train loss: -2.6487 \t val error: 2.1810\n",
      "Iteration 1621: \t train loss: -2.6490 \t val error: 2.1810\n",
      "Iteration 1622: \t train loss: -2.6494 \t val error: 2.1810\n",
      "Iteration 1623: \t train loss: -2.6497 \t val error: 2.1810\n",
      "Iteration 1624: \t train loss: -2.6501 \t val error: 2.1810\n",
      "Iteration 1625: \t train loss: -2.6504 \t val error: 2.1810\n",
      "Iteration 1626: \t train loss: -2.6508 \t val error: 2.1810\n",
      "Iteration 1627: \t train loss: -2.6511 \t val error: 2.1736\n",
      "Iteration 1628: \t train loss: -2.6515 \t val error: 2.1736\n",
      "Iteration 1629: \t train loss: -2.6518 \t val error: 2.1736\n",
      "Iteration 1630: \t train loss: -2.6522 \t val error: 2.1736\n",
      "Iteration 1631: \t train loss: -2.6525 \t val error: 2.1736\n",
      "Iteration 1632: \t train loss: -2.6529 \t val error: 2.1736\n",
      "Iteration 1633: \t train loss: -2.6532 \t val error: 2.1736\n",
      "Iteration 1634: \t train loss: -2.6536 \t val error: 2.1736\n",
      "Iteration 1635: \t train loss: -2.6539 \t val error: 2.1736\n",
      "Iteration 1636: \t train loss: -2.6543 \t val error: 2.1736\n",
      "Iteration 1637: \t train loss: -2.6546 \t val error: 2.1736\n",
      "Iteration 1638: \t train loss: -2.6550 \t val error: 2.1736\n",
      "Iteration 1639: \t train loss: -2.6553 \t val error: 2.1736\n",
      "Iteration 1640: \t train loss: -2.6557 \t val error: 2.1736\n",
      "Iteration 1641: \t train loss: -2.6560 \t val error: 2.1736\n",
      "Iteration 1642: \t train loss: -2.6563 \t val error: 2.1736\n",
      "Iteration 1643: \t train loss: -2.6567 \t val error: 2.1736\n",
      "Iteration 1644: \t train loss: -2.6570 \t val error: 2.1736\n",
      "Iteration 1645: \t train loss: -2.6574 \t val error: 2.1736\n",
      "Iteration 1646: \t train loss: -2.6577 \t val error: 2.1736\n",
      "Iteration 1647: \t train loss: -2.6580 \t val error: 2.1736\n",
      "Iteration 1648: \t train loss: -2.6584 \t val error: 2.1736\n",
      "Iteration 1649: \t train loss: -2.6587 \t val error: 2.1736\n",
      "Iteration 1650: \t train loss: -2.6591 \t val error: 2.1736\n",
      "Iteration 1651: \t train loss: -2.6594 \t val error: 2.1736\n",
      "Iteration 1652: \t train loss: -2.6597 \t val error: 2.1736\n",
      "Iteration 1653: \t train loss: -2.6601 \t val error: 2.1736\n",
      "Iteration 1654: \t train loss: -2.6604 \t val error: 2.1736\n",
      "Iteration 1655: \t train loss: -2.6607 \t val error: 2.1736\n",
      "Iteration 1656: \t train loss: -2.6611 \t val error: 2.1736\n",
      "Iteration 1657: \t train loss: -2.6614 \t val error: 2.1736\n",
      "Iteration 1658: \t train loss: -2.6618 \t val error: 2.1736\n",
      "Iteration 1659: \t train loss: -2.6621 \t val error: 2.1736\n",
      "Iteration 1660: \t train loss: -2.6624 \t val error: 2.1736\n",
      "Iteration 1661: \t train loss: -2.6628 \t val error: 2.1736\n",
      "Iteration 1662: \t train loss: -2.6631 \t val error: 2.1736\n",
      "Iteration 1663: \t train loss: -2.6634 \t val error: 2.1737\n",
      "Iteration 1664: \t train loss: -2.6637 \t val error: 2.1737\n",
      "Iteration 1665: \t train loss: -2.6641 \t val error: 2.1737\n",
      "Iteration 1666: \t train loss: -2.6644 \t val error: 2.1737\n",
      "Iteration 1667: \t train loss: -2.6647 \t val error: 2.1737\n",
      "Iteration 1668: \t train loss: -2.6651 \t val error: 2.1737\n",
      "Iteration 1669: \t train loss: -2.6654 \t val error: 2.1737\n",
      "Iteration 1670: \t train loss: -2.6657 \t val error: 2.1737\n",
      "Iteration 1671: \t train loss: -2.6660 \t val error: 2.1737\n",
      "Iteration 1672: \t train loss: -2.6664 \t val error: 2.1737\n",
      "Iteration 1673: \t train loss: -2.6667 \t val error: 2.1737\n",
      "Iteration 1674: \t train loss: -2.6670 \t val error: 2.1737\n",
      "Iteration 1675: \t train loss: -2.6673 \t val error: 2.1737\n",
      "Iteration 1676: \t train loss: -2.6677 \t val error: 2.1737\n",
      "Iteration 1677: \t train loss: -2.6680 \t val error: 2.1737\n",
      "Iteration 1678: \t train loss: -2.6683 \t val error: 2.1737\n",
      "Iteration 1679: \t train loss: -2.6686 \t val error: 2.1737\n",
      "Iteration 1680: \t train loss: -2.6690 \t val error: 2.1737\n",
      "Iteration 1681: \t train loss: -2.6693 \t val error: 2.1737\n",
      "Iteration 1682: \t train loss: -2.6696 \t val error: 2.1737\n",
      "Iteration 1683: \t train loss: -2.6699 \t val error: 2.1737\n",
      "Iteration 1684: \t train loss: -2.6702 \t val error: 2.1737\n",
      "Iteration 1685: \t train loss: -2.6706 \t val error: 2.1737\n",
      "Iteration 1686: \t train loss: -2.6709 \t val error: 2.1737\n",
      "Iteration 1687: \t train loss: -2.6712 \t val error: 2.1737\n",
      "Iteration 1688: \t train loss: -2.6715 \t val error: 2.1737\n",
      "Iteration 1689: \t train loss: -2.6718 \t val error: 2.1737\n",
      "Iteration 1690: \t train loss: -2.6722 \t val error: 2.1737\n",
      "Iteration 1691: \t train loss: -2.6725 \t val error: 2.1738\n",
      "Iteration 1692: \t train loss: -2.6728 \t val error: 2.1738\n",
      "Iteration 1693: \t train loss: -2.6731 \t val error: 2.1738\n",
      "Iteration 1694: \t train loss: -2.6734 \t val error: 2.1738\n",
      "Iteration 1695: \t train loss: -2.6737 \t val error: 2.1738\n",
      "Iteration 1696: \t train loss: -2.6740 \t val error: 2.1738\n",
      "Iteration 1697: \t train loss: -2.6744 \t val error: 2.1739\n",
      "Iteration 1698: \t train loss: -2.6747 \t val error: 2.1739\n",
      "Iteration 1699: \t train loss: -2.6750 \t val error: 2.1739\n",
      "Iteration 1700: \t train loss: -2.6753 \t val error: 2.1739\n",
      "Iteration 1701: \t train loss: -2.6756 \t val error: 2.1739\n",
      "Iteration 1702: \t train loss: -2.6759 \t val error: 2.1739\n",
      "Iteration 1703: \t train loss: -2.6762 \t val error: 2.1739\n",
      "Iteration 1704: \t train loss: -2.6765 \t val error: 2.1740\n",
      "Iteration 1705: \t train loss: -2.6768 \t val error: 2.1740\n",
      "Iteration 1706: \t train loss: -2.6772 \t val error: 2.1740\n",
      "Iteration 1707: \t train loss: -2.6775 \t val error: 2.1740\n",
      "Iteration 1708: \t train loss: -2.6778 \t val error: 2.1740\n",
      "Iteration 1709: \t train loss: -2.6781 \t val error: 2.1740\n",
      "Iteration 1710: \t train loss: -2.6784 \t val error: 2.1741\n",
      "Iteration 1711: \t train loss: -2.6787 \t val error: 2.1741\n",
      "Iteration 1712: \t train loss: -2.6790 \t val error: 2.1741\n",
      "Iteration 1713: \t train loss: -2.6793 \t val error: 2.1741\n",
      "Iteration 1714: \t train loss: -2.6796 \t val error: 2.1741\n",
      "Iteration 1715: \t train loss: -2.6799 \t val error: 2.1741\n",
      "Iteration 1716: \t train loss: -2.6802 \t val error: 2.1741\n",
      "Iteration 1717: \t train loss: -2.6805 \t val error: 2.1742\n",
      "Iteration 1718: \t train loss: -2.6808 \t val error: 2.1742\n",
      "Iteration 1719: \t train loss: -2.6811 \t val error: 2.1742\n",
      "Iteration 1720: \t train loss: -2.6814 \t val error: 2.1742\n",
      "Iteration 1721: \t train loss: -2.6817 \t val error: 2.1742\n",
      "Iteration 1722: \t train loss: -2.6820 \t val error: 2.1742\n",
      "Iteration 1723: \t train loss: -2.6823 \t val error: 2.1742\n",
      "Iteration 1724: \t train loss: -2.6826 \t val error: 2.1743\n",
      "Iteration 1725: \t train loss: -2.6829 \t val error: 2.1743\n",
      "Iteration 1726: \t train loss: -2.6832 \t val error: 2.1743\n",
      "Iteration 1727: \t train loss: -2.6835 \t val error: 2.1743\n",
      "Iteration 1728: \t train loss: -2.6838 \t val error: 2.1743\n",
      "Iteration 1729: \t train loss: -2.6841 \t val error: 2.1743\n",
      "Iteration 1730: \t train loss: -2.6844 \t val error: 2.1743\n",
      "Iteration 1731: \t train loss: -2.6847 \t val error: 2.1744\n",
      "Iteration 1732: \t train loss: -2.6850 \t val error: 2.1744\n",
      "Iteration 1733: \t train loss: -2.6853 \t val error: 2.1744\n",
      "Iteration 1734: \t train loss: -2.6856 \t val error: 2.1744\n",
      "Iteration 1735: \t train loss: -2.6859 \t val error: 2.1744\n",
      "Iteration 1736: \t train loss: -2.6862 \t val error: 2.1744\n",
      "Iteration 1737: \t train loss: -2.6865 \t val error: 2.1745\n",
      "Iteration 1738: \t train loss: -2.6868 \t val error: 2.1745\n",
      "Iteration 1739: \t train loss: -2.6871 \t val error: 2.1745\n",
      "Iteration 1740: \t train loss: -2.6873 \t val error: 2.1745\n",
      "Iteration 1741: \t train loss: -2.6876 \t val error: 2.1745\n",
      "Iteration 1742: \t train loss: -2.6879 \t val error: 2.1745\n",
      "Iteration 1743: \t train loss: -2.6882 \t val error: 2.1745\n",
      "Iteration 1744: \t train loss: -2.6885 \t val error: 2.1745\n",
      "Iteration 1745: \t train loss: -2.6888 \t val error: 2.1745\n",
      "Iteration 1746: \t train loss: -2.6891 \t val error: 2.1745\n",
      "Iteration 1747: \t train loss: -2.6894 \t val error: 2.1745\n",
      "Iteration 1748: \t train loss: -2.6897 \t val error: 2.1745\n",
      "Iteration 1749: \t train loss: -2.6900 \t val error: 2.1745\n",
      "Iteration 1750: \t train loss: -2.6902 \t val error: 2.1745\n",
      "Iteration 1751: \t train loss: -2.6905 \t val error: 2.1745\n",
      "Iteration 1752: \t train loss: -2.6908 \t val error: 2.1745\n",
      "Iteration 1753: \t train loss: -2.6911 \t val error: 2.1745\n",
      "Iteration 1754: \t train loss: -2.6914 \t val error: 2.1745\n",
      "Iteration 1755: \t train loss: -2.6917 \t val error: 2.1745\n",
      "Iteration 1756: \t train loss: -2.6919 \t val error: 2.1745\n",
      "Iteration 1757: \t train loss: -2.6922 \t val error: 2.1745\n",
      "Iteration 1758: \t train loss: -2.6925 \t val error: 2.1745\n",
      "Iteration 1759: \t train loss: -2.6928 \t val error: 2.1745\n",
      "Iteration 1760: \t train loss: -2.6931 \t val error: 2.1745\n",
      "Iteration 1761: \t train loss: -2.6934 \t val error: 2.1745\n",
      "Iteration 1762: \t train loss: -2.6936 \t val error: 2.1745\n",
      "Iteration 1763: \t train loss: -2.6939 \t val error: 2.1745\n",
      "Iteration 1764: \t train loss: -2.6942 \t val error: 2.1745\n",
      "Iteration 1765: \t train loss: -2.6945 \t val error: 2.1745\n",
      "Iteration 1766: \t train loss: -2.6948 \t val error: 2.1745\n",
      "Iteration 1767: \t train loss: -2.6950 \t val error: 2.1745\n",
      "Iteration 1768: \t train loss: -2.6953 \t val error: 2.1745\n",
      "Iteration 1769: \t train loss: -2.6956 \t val error: 2.1745\n",
      "Iteration 1770: \t train loss: -2.6959 \t val error: 2.1745\n",
      "Iteration 1771: \t train loss: -2.6962 \t val error: 2.1745\n",
      "Iteration 1772: \t train loss: -2.6964 \t val error: 2.1745\n",
      "Iteration 1773: \t train loss: -2.6967 \t val error: 2.1745\n",
      "Iteration 1774: \t train loss: -2.6970 \t val error: 2.1745\n",
      "Iteration 1775: \t train loss: -2.6973 \t val error: 2.1745\n",
      "Iteration 1776: \t train loss: -2.6975 \t val error: 2.1745\n",
      "Iteration 1777: \t train loss: -2.6978 \t val error: 2.1745\n",
      "Iteration 1778: \t train loss: -2.6981 \t val error: 2.1745\n",
      "Iteration 1779: \t train loss: -2.6984 \t val error: 2.1745\n",
      "Iteration 1780: \t train loss: -2.6986 \t val error: 2.1745\n",
      "Iteration 1781: \t train loss: -2.6989 \t val error: 2.1745\n",
      "Iteration 1782: \t train loss: -2.6992 \t val error: 2.1745\n",
      "Iteration 1783: \t train loss: -2.6994 \t val error: 2.1745\n",
      "Iteration 1784: \t train loss: -2.6997 \t val error: 2.1745\n",
      "Iteration 1785: \t train loss: -2.7000 \t val error: 2.1745\n",
      "Iteration 1786: \t train loss: -2.7003 \t val error: 2.1745\n",
      "Iteration 1787: \t train loss: -2.7005 \t val error: 2.1746\n",
      "Iteration 1788: \t train loss: -2.7008 \t val error: 2.1746\n",
      "Iteration 1789: \t train loss: -2.7011 \t val error: 2.1746\n",
      "Iteration 1790: \t train loss: -2.7013 \t val error: 2.1746\n",
      "Iteration 1791: \t train loss: -2.7016 \t val error: 2.1746\n",
      "Iteration 1792: \t train loss: -2.7019 \t val error: 2.1746\n",
      "Iteration 1793: \t train loss: -2.7021 \t val error: 2.1746\n",
      "Iteration 1794: \t train loss: -2.7024 \t val error: 2.1746\n",
      "Iteration 1795: \t train loss: -2.7027 \t val error: 2.1746\n",
      "Iteration 1796: \t train loss: -2.7029 \t val error: 2.1746\n",
      "Iteration 1797: \t train loss: -2.7032 \t val error: 2.1746\n",
      "Iteration 1798: \t train loss: -2.7035 \t val error: 2.1746\n",
      "Iteration 1799: \t train loss: -2.7037 \t val error: 2.1746\n",
      "Iteration 1800: \t train loss: -2.7040 \t val error: 2.1746\n",
      "Iteration 1801: \t train loss: -2.7043 \t val error: 2.1746\n",
      "Iteration 1802: \t train loss: -2.7045 \t val error: 2.1746\n",
      "Iteration 1803: \t train loss: -2.7048 \t val error: 2.1746\n",
      "Iteration 1804: \t train loss: -2.7050 \t val error: 2.1746\n",
      "Iteration 1805: \t train loss: -2.7053 \t val error: 2.1746\n",
      "Iteration 1806: \t train loss: -2.7056 \t val error: 2.1746\n",
      "Iteration 1807: \t train loss: -2.7058 \t val error: 2.1746\n",
      "Iteration 1808: \t train loss: -2.7061 \t val error: 2.1746\n",
      "Iteration 1809: \t train loss: -2.7063 \t val error: 2.1746\n",
      "Iteration 1810: \t train loss: -2.7066 \t val error: 2.1746\n",
      "Iteration 1811: \t train loss: -2.7069 \t val error: 2.1746\n",
      "Iteration 1812: \t train loss: -2.7071 \t val error: 2.1746\n",
      "Iteration 1813: \t train loss: -2.7074 \t val error: 2.1746\n",
      "Iteration 1814: \t train loss: -2.7076 \t val error: 2.1746\n",
      "Iteration 1815: \t train loss: -2.7079 \t val error: 2.1746\n",
      "Iteration 1816: \t train loss: -2.7082 \t val error: 2.1746\n",
      "Iteration 1817: \t train loss: -2.7084 \t val error: 2.1746\n",
      "Iteration 1818: \t train loss: -2.7087 \t val error: 2.1746\n",
      "Iteration 1819: \t train loss: -2.7089 \t val error: 2.1746\n",
      "Iteration 1820: \t train loss: -2.7092 \t val error: 2.1746\n",
      "Iteration 1821: \t train loss: -2.7094 \t val error: 2.1746\n",
      "Iteration 1822: \t train loss: -2.7097 \t val error: 2.1746\n",
      "Iteration 1823: \t train loss: -2.7099 \t val error: 2.1746\n",
      "Iteration 1824: \t train loss: -2.7102 \t val error: 2.1746\n",
      "Iteration 1825: \t train loss: -2.7105 \t val error: 2.1746\n",
      "Iteration 1826: \t train loss: -2.7107 \t val error: 2.1746\n",
      "Iteration 1827: \t train loss: -2.7110 \t val error: 2.1746\n",
      "Iteration 1828: \t train loss: -2.7112 \t val error: 2.1746\n",
      "Iteration 1829: \t train loss: -2.7115 \t val error: 2.1746\n",
      "Iteration 1830: \t train loss: -2.7117 \t val error: 2.1746\n",
      "Iteration 1831: \t train loss: -2.7120 \t val error: 2.1746\n",
      "Iteration 1832: \t train loss: -2.7122 \t val error: 2.1746\n",
      "Iteration 1833: \t train loss: -2.7125 \t val error: 2.1746\n",
      "Iteration 1834: \t train loss: -2.7127 \t val error: 2.1746\n",
      "Iteration 1835: \t train loss: -2.7130 \t val error: 2.1746\n",
      "Iteration 1836: \t train loss: -2.7132 \t val error: 2.1746\n",
      "Iteration 1837: \t train loss: -2.7135 \t val error: 2.1746\n",
      "Iteration 1838: \t train loss: -2.7137 \t val error: 2.1746\n",
      "Iteration 1839: \t train loss: -2.7140 \t val error: 2.1746\n",
      "Iteration 1840: \t train loss: -2.7142 \t val error: 2.1746\n",
      "Iteration 1841: \t train loss: -2.7144 \t val error: 2.1746\n",
      "Iteration 1842: \t train loss: -2.7147 \t val error: 2.1746\n",
      "Iteration 1843: \t train loss: -2.7149 \t val error: 2.1746\n",
      "Iteration 1844: \t train loss: -2.7152 \t val error: 2.1746\n",
      "Iteration 1845: \t train loss: -2.7154 \t val error: 2.1746\n",
      "Iteration 1846: \t train loss: -2.7157 \t val error: 2.1746\n",
      "Iteration 1847: \t train loss: -2.7159 \t val error: 2.1746\n",
      "Iteration 1848: \t train loss: -2.7162 \t val error: 2.1746\n",
      "Iteration 1849: \t train loss: -2.7164 \t val error: 2.1746\n",
      "Iteration 1850: \t train loss: -2.7167 \t val error: 2.1746\n",
      "Iteration 1851: \t train loss: -2.7169 \t val error: 2.1746\n",
      "Iteration 1852: \t train loss: -2.7171 \t val error: 2.1746\n",
      "Iteration 1853: \t train loss: -2.7174 \t val error: 2.1746\n",
      "Iteration 1854: \t train loss: -2.7176 \t val error: 2.1746\n",
      "Iteration 1855: \t train loss: -2.7179 \t val error: 2.1746\n",
      "Iteration 1856: \t train loss: -2.7181 \t val error: 2.1746\n",
      "Iteration 1857: \t train loss: -2.7183 \t val error: 2.1746\n",
      "Iteration 1858: \t train loss: -2.7186 \t val error: 2.1746\n",
      "Iteration 1859: \t train loss: -2.7188 \t val error: 2.1746\n",
      "Iteration 1860: \t train loss: -2.7191 \t val error: 2.1746\n",
      "Iteration 1861: \t train loss: -2.7193 \t val error: 2.1746\n",
      "Iteration 1862: \t train loss: -2.7195 \t val error: 2.1746\n",
      "Iteration 1863: \t train loss: -2.7198 \t val error: 2.1746\n",
      "Iteration 1864: \t train loss: -2.7200 \t val error: 2.1746\n",
      "Iteration 1865: \t train loss: -2.7202 \t val error: 2.1746\n",
      "Iteration 1866: \t train loss: -2.7205 \t val error: 2.1746\n",
      "Iteration 1867: \t train loss: -2.7207 \t val error: 2.1746\n",
      "Iteration 1868: \t train loss: -2.7210 \t val error: 2.1746\n",
      "Iteration 1869: \t train loss: -2.7212 \t val error: 2.1746\n",
      "Iteration 1870: \t train loss: -2.7214 \t val error: 2.1746\n",
      "Iteration 1871: \t train loss: -2.7217 \t val error: 2.1746\n",
      "Iteration 1872: \t train loss: -2.7219 \t val error: 2.1746\n",
      "Iteration 1873: \t train loss: -2.7221 \t val error: 2.1746\n",
      "Iteration 1874: \t train loss: -2.7224 \t val error: 2.1746\n",
      "Iteration 1875: \t train loss: -2.7226 \t val error: 2.1746\n",
      "Iteration 1876: \t train loss: -2.7228 \t val error: 2.1746\n",
      "Iteration 1877: \t train loss: -2.7231 \t val error: 2.1746\n",
      "Iteration 1878: \t train loss: -2.7233 \t val error: 2.1746\n",
      "Iteration 1879: \t train loss: -2.7235 \t val error: 2.1746\n",
      "Iteration 1880: \t train loss: -2.7238 \t val error: 2.1746\n",
      "Iteration 1881: \t train loss: -2.7240 \t val error: 2.1746\n",
      "Iteration 1882: \t train loss: -2.7242 \t val error: 2.1746\n",
      "Iteration 1883: \t train loss: -2.7245 \t val error: 2.1746\n",
      "Iteration 1884: \t train loss: -2.7247 \t val error: 2.1747\n",
      "Iteration 1885: \t train loss: -2.7249 \t val error: 2.1747\n",
      "Iteration 1886: \t train loss: -2.7251 \t val error: 2.1747\n",
      "Iteration 1887: \t train loss: -2.7254 \t val error: 2.1747\n",
      "Iteration 1888: \t train loss: -2.7256 \t val error: 2.1747\n",
      "Iteration 1889: \t train loss: -2.7258 \t val error: 2.1747\n",
      "Iteration 1890: \t train loss: -2.7261 \t val error: 2.1747\n",
      "Iteration 1891: \t train loss: -2.7263 \t val error: 2.1747\n",
      "Iteration 1892: \t train loss: -2.7265 \t val error: 2.1747\n",
      "Iteration 1893: \t train loss: -2.7267 \t val error: 2.1747\n",
      "Iteration 1894: \t train loss: -2.7270 \t val error: 2.1747\n",
      "Iteration 1895: \t train loss: -2.7272 \t val error: 2.1747\n",
      "Iteration 1896: \t train loss: -2.7274 \t val error: 2.1747\n",
      "Iteration 1897: \t train loss: -2.7276 \t val error: 2.1747\n",
      "Iteration 1898: \t train loss: -2.7279 \t val error: 2.1747\n",
      "Iteration 1899: \t train loss: -2.7281 \t val error: 2.1747\n",
      "Iteration 1900: \t train loss: -2.7283 \t val error: 2.1747\n",
      "Iteration 1901: \t train loss: -2.7285 \t val error: 2.1747\n",
      "Iteration 1902: \t train loss: -2.7288 \t val error: 2.1747\n",
      "Iteration 1903: \t train loss: -2.7290 \t val error: 2.1747\n",
      "Iteration 1904: \t train loss: -2.7292 \t val error: 2.1747\n",
      "Iteration 1905: \t train loss: -2.7294 \t val error: 2.1747\n",
      "Iteration 1906: \t train loss: -2.7296 \t val error: 2.1747\n",
      "Iteration 1907: \t train loss: -2.7299 \t val error: 2.1747\n",
      "Iteration 1908: \t train loss: -2.7301 \t val error: 2.1747\n",
      "Iteration 1909: \t train loss: -2.7303 \t val error: 2.1747\n",
      "Iteration 1910: \t train loss: -2.7305 \t val error: 2.1747\n",
      "Iteration 1911: \t train loss: -2.7307 \t val error: 2.1747\n",
      "Iteration 1912: \t train loss: -2.7310 \t val error: 2.1747\n",
      "Iteration 1913: \t train loss: -2.7312 \t val error: 2.1747\n",
      "Iteration 1914: \t train loss: -2.7314 \t val error: 2.1747\n",
      "Iteration 1915: \t train loss: -2.7316 \t val error: 2.1747\n",
      "Iteration 1916: \t train loss: -2.7318 \t val error: 2.1747\n",
      "Iteration 1917: \t train loss: -2.7321 \t val error: 2.1747\n",
      "Iteration 1918: \t train loss: -2.7323 \t val error: 2.1747\n",
      "Iteration 1919: \t train loss: -2.7325 \t val error: 2.1747\n",
      "Iteration 1920: \t train loss: -2.7327 \t val error: 2.1747\n",
      "Iteration 1921: \t train loss: -2.7329 \t val error: 2.1747\n",
      "Iteration 1922: \t train loss: -2.7331 \t val error: 2.1747\n",
      "Iteration 1923: \t train loss: -2.7334 \t val error: 2.1747\n",
      "Iteration 1924: \t train loss: -2.7336 \t val error: 2.1747\n",
      "Iteration 1925: \t train loss: -2.7338 \t val error: 2.1747\n",
      "Iteration 1926: \t train loss: -2.7340 \t val error: 2.1747\n",
      "Iteration 1927: \t train loss: -2.7342 \t val error: 2.1747\n",
      "Iteration 1928: \t train loss: -2.7344 \t val error: 2.1747\n",
      "Iteration 1929: \t train loss: -2.7346 \t val error: 2.1747\n",
      "Iteration 1930: \t train loss: -2.7348 \t val error: 2.1747\n",
      "Iteration 1931: \t train loss: -2.7351 \t val error: 2.1747\n",
      "Iteration 1932: \t train loss: -2.7353 \t val error: 2.1747\n",
      "Iteration 1933: \t train loss: -2.7355 \t val error: 2.1747\n",
      "Iteration 1934: \t train loss: -2.7357 \t val error: 2.1747\n",
      "Iteration 1935: \t train loss: -2.7359 \t val error: 2.1747\n",
      "Iteration 1936: \t train loss: -2.7361 \t val error: 2.1747\n",
      "Iteration 1937: \t train loss: -2.7363 \t val error: 2.1747\n",
      "Iteration 1938: \t train loss: -2.7365 \t val error: 2.1747\n",
      "Iteration 1939: \t train loss: -2.7367 \t val error: 2.1747\n",
      "Iteration 1940: \t train loss: -2.7370 \t val error: 2.1747\n",
      "Iteration 1941: \t train loss: -2.7372 \t val error: 2.1747\n",
      "Iteration 1942: \t train loss: -2.7374 \t val error: 2.1747\n",
      "Iteration 1943: \t train loss: -2.7376 \t val error: 2.1747\n",
      "Iteration 1944: \t train loss: -2.7378 \t val error: 2.1747\n",
      "Iteration 1945: \t train loss: -2.7380 \t val error: 2.1747\n",
      "Iteration 1946: \t train loss: -2.7382 \t val error: 2.1747\n",
      "Iteration 1947: \t train loss: -2.7384 \t val error: 2.1747\n",
      "Iteration 1948: \t train loss: -2.7386 \t val error: 2.1747\n",
      "Iteration 1949: \t train loss: -2.7388 \t val error: 2.1747\n",
      "Iteration 1950: \t train loss: -2.7390 \t val error: 2.1747\n",
      "Iteration 1951: \t train loss: -2.7392 \t val error: 2.1747\n",
      "Iteration 1952: \t train loss: -2.7394 \t val error: 2.1747\n",
      "Iteration 1953: \t train loss: -2.7397 \t val error: 2.1747\n",
      "Iteration 1954: \t train loss: -2.7399 \t val error: 2.1747\n",
      "Iteration 1955: \t train loss: -2.7401 \t val error: 2.1747\n",
      "Iteration 1956: \t train loss: -2.7403 \t val error: 2.1747\n",
      "Iteration 1957: \t train loss: -2.7405 \t val error: 2.1747\n",
      "Iteration 1958: \t train loss: -2.7407 \t val error: 2.1746\n",
      "Iteration 1959: \t train loss: -2.7409 \t val error: 2.1746\n",
      "Iteration 1960: \t train loss: -2.7411 \t val error: 2.1746\n",
      "Iteration 1961: \t train loss: -2.7413 \t val error: 2.1746\n",
      "Iteration 1962: \t train loss: -2.7415 \t val error: 2.1745\n",
      "Iteration 1963: \t train loss: -2.7417 \t val error: 2.1745\n",
      "Iteration 1964: \t train loss: -2.7419 \t val error: 2.1745\n",
      "Iteration 1965: \t train loss: -2.7421 \t val error: 2.1745\n",
      "Iteration 1966: \t train loss: -2.7423 \t val error: 2.1745\n",
      "Iteration 1967: \t train loss: -2.7425 \t val error: 2.1744\n",
      "Iteration 1968: \t train loss: -2.7427 \t val error: 2.1744\n",
      "Iteration 1969: \t train loss: -2.7429 \t val error: 2.1744\n",
      "Iteration 1970: \t train loss: -2.7431 \t val error: 2.1744\n",
      "Iteration 1971: \t train loss: -2.7433 \t val error: 2.1743\n",
      "Iteration 1972: \t train loss: -2.7435 \t val error: 2.1743\n",
      "Iteration 1973: \t train loss: -2.7437 \t val error: 2.1743\n",
      "Iteration 1974: \t train loss: -2.7439 \t val error: 2.1743\n",
      "Iteration 1975: \t train loss: -2.7441 \t val error: 2.1743\n",
      "Iteration 1976: \t train loss: -2.7443 \t val error: 2.1742\n",
      "Iteration 1977: \t train loss: -2.7445 \t val error: 2.1742\n",
      "Iteration 1978: \t train loss: -2.7447 \t val error: 2.1742\n",
      "Iteration 1979: \t train loss: -2.7449 \t val error: 2.1742\n",
      "Iteration 1980: \t train loss: -2.7451 \t val error: 2.1742\n",
      "Iteration 1981: \t train loss: -2.7453 \t val error: 2.1741\n",
      "Iteration 1982: \t train loss: -2.7455 \t val error: 2.1741\n",
      "Iteration 1983: \t train loss: -2.7456 \t val error: 2.1741\n",
      "Iteration 1984: \t train loss: -2.7458 \t val error: 2.1741\n",
      "Iteration 1985: \t train loss: -2.7460 \t val error: 2.1740\n",
      "Iteration 1986: \t train loss: -2.7462 \t val error: 2.1740\n",
      "Iteration 1987: \t train loss: -2.7464 \t val error: 2.1740\n",
      "Iteration 1988: \t train loss: -2.7466 \t val error: 2.1740\n",
      "Iteration 1989: \t train loss: -2.7468 \t val error: 2.1740\n",
      "Iteration 1990: \t train loss: -2.7470 \t val error: 2.1740\n",
      "Iteration 1991: \t train loss: -2.7472 \t val error: 2.1740\n",
      "Iteration 1992: \t train loss: -2.7474 \t val error: 2.1740\n",
      "Iteration 1993: \t train loss: -2.7476 \t val error: 2.1740\n",
      "Iteration 1994: \t train loss: -2.7478 \t val error: 2.1740\n",
      "Iteration 1995: \t train loss: -2.7480 \t val error: 2.1740\n",
      "Iteration 1996: \t train loss: -2.7482 \t val error: 2.1740\n",
      "Iteration 1997: \t train loss: -2.7483 \t val error: 2.1740\n",
      "Iteration 1998: \t train loss: -2.7485 \t val error: 2.1740\n",
      "Iteration 1999: \t train loss: -2.7487 \t val error: 2.1740\n"
     ]
    }
   ],
   "source": [
    "model = NpGlm()\n",
    "model.fit(X_train_encoded, Y_train, T_train, max_iter=max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.1981837101504116\n"
     ]
    }
   ],
   "source": [
    "MAE = model.evaluate(X_test_encoded, Y_test, T_test)\n",
    "print(f'MAE: {MAE}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e90db5e7aef54a6dac2efaa87854a72c05ec4ea3931347a9f50bf19135a908d6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
